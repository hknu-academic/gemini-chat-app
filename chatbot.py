import streamlit as st
import pandas as pd
from streamlit_option_menu import option_menu 
from datetime import datetime
import os
from dotenv import load_dotenv  # ì„¤ì¹˜ í•„ìš”
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity
import numpy as np
import uuid
import re
from google import genai

# === [AI ì„¤ì •] Gemini API ì—°ê²° ===

load_dotenv()

GEMINI_API_KEY = os.getenv("GEMINI_API_KEY")
if not GEMINI_API_KEY:
    st.error("âš ï¸ GEMINI_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤!")
    st.info("í”„ë¡œì íŠ¸ í´ë”ì— .env íŒŒì¼ì„ ë§Œë“¤ê³  API í‚¤ë¥¼ ì €ì¥í•˜ì„¸ìš”.")
    st.stop()

client = genai.Client(api_key=GEMINI_API_KEY)  # <--- Client ê°ì²´ ìƒì„± ë°©ì‹ìœ¼ë¡œ ë³€ê²½

# === í˜ì´ì§€ ì„¤ì • (ê°€ì¥ ë¨¼ì € ì‹¤í–‰ë˜ì–´ì•¼ í•¨) ===
st.set_page_config(
    page_title="ë‹¤ì „ê³µ ì•ˆë‚´ AIì±—ë´‡",
    page_icon="ğŸ“",
    layout="wide",
)

# === ìë™ ìŠ¤í¬ë¡¤ í•¨ìˆ˜ (ë§ˆì§€ë§‰ ë§í’ì„  ì¶”ì  ë°©ì‹ + Focus) ===
def scroll_to_bottom():
    # ë§¤ë²ˆ ìƒˆë¡œìš´ IDë¡œ ê°•ì œ ì‹¤í–‰ ìœ ë„
    unique_id = str(uuid.uuid4())
    
    js = f"""
    <script>
        // Random ID to force update: {unique_id}
        
        function scrollIntoView() {{
            // 1. ë§í’ì„  ìš”ì†Œë“¤ì„ ë‹¤ ì°¾ìŠµë‹ˆë‹¤.
            var messages = window.parent.document.querySelectorAll('[data-testid="stChatMessage"]');
            
            if (messages.length > 0) {{
                // 2. ê°€ì¥ ë§ˆì§€ë§‰ ë§í’ì„ ì„ ê°€ì ¸ì˜µë‹ˆë‹¤.
                var lastMessage = messages[messages.length - 1];
                
                // 3. ê·¸ ë§í’ì„ ì´ ë³´ì´ë„ë¡ í™”ë©´ì„ ë¶€ë“œëŸ½ê²Œ ë‚´ë¦½ë‹ˆë‹¤.
                lastMessage.scrollIntoView({{behavior: "smooth", block: "end"}});
            }} else {{
                // ë§í’ì„ ì„ ëª» ì°¾ìœ¼ë©´ ê¸°ì¡´ ë°©ì‹ìœ¼ë¡œ ì»¨í…Œì´ë„ˆ ìŠ¤í¬ë¡¤ ì‹œë„
                var container = window.parent.document.querySelector('[data-testid="stAppViewContainer"]');
                if (container) container.scrollTop = container.scrollHeight;
            }}
        }}

        // í™”ë©´ ë Œë”ë§ ì‹œê°„ì„ ê³ ë ¤í•´ ì¡°ê¸ˆ ë„‰ë„‰íˆ ê¸°ë‹¤ë ¸ë‹¤ê°€ ì‹¤í–‰
        setTimeout(scrollIntoView, 300);
        setTimeout(scrollIntoView, 500);
    </script>
    """
    st.components.v1.html(js, height=0)

# ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
if 'chat_history' not in st.session_state:
    st.session_state.chat_history = []
if 'scroll_to_bottom' not in st.session_state:
    st.session_state.scroll_to_bottom = False
if 'user_info' not in st.session_state:
    st.session_state.user_info = {}
if 'feedback_data' not in st.session_state:
    st.session_state.feedback_data = []
if 'show_feedback' not in st.session_state:
    st.session_state.show_feedback = {}
if 'is_admin' not in st.session_state:
    st.session_state.is_admin = False
if "scroll_count" not in st.session_state:
    st.session_state.scroll_count = 0
if 'show_calculator' not in st.session_state:
    st.session_state.show_calculator = False

def initialize_session_state():
    """ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”"""
    defaults = {
        'chat_history': [],
        'user_info': {},
        'feedback_data': [],
        'is_admin': False
    }
    for key, value in defaults.items():
        if key not in st.session_state:
            st.session_state[key] = value

# === ë°ì´í„° ë¡œë“œ í•¨ìˆ˜ ===
@st.cache_data
def load_all_data():
    """ëª¨ë“  ì—‘ì…€ ë°ì´í„°ë¥¼ ë¡œë“œí•˜ì—¬ ë”•ì…”ë„ˆë¦¬ë¡œ ë°˜í™˜"""
    data = {}
    try:
        data['programs'] = load_programs()
        data['faq'] = load_faq()
        data['curriculum'] = load_curriculum_mapping()
        data['courses'] = load_courses()
        data['keywords'] = load_keywords()
        data['grad_req'] = load_graduation_requirements()
        data['primary_req'] = load_primary_requirements()
        data['majors'] = load_majors_info()
    except Exception as e:
        st.error(f"ë°ì´í„° ë¡œë“œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
    return data

@st.cache_data
def load_programs():
    """ì œë„ ì •ë³´ ë¡œë“œ"""
    try:
        df = pd.read_excel('data/programs.xlsx')
        programs = {}
        for _, row in df.iterrows():
            programs[row['ì œë„ëª…']] = {
                'description': row['ì„¤ëª…'],
                'credits_general': row['ì´ìˆ˜í•™ì (êµì–‘)'] if pd.notna(row.get('ì´ìˆ˜í•™ì (êµì–‘)')) else '-',
                'credits_primary': row['ì›ì „ê³µ ì´ìˆ˜í•™ì '] if pd.notna(row.get('ì›ì „ê³µ ì´ìˆ˜í•™ì ')) else '-',
                'credits_multi': row['ë‹¤ì „ê³µ ì´ìˆ˜í•™ì '] if pd.notna(row.get('ë‹¤ì „ê³µ ì´ìˆ˜í•™ì ')) else '-',
                'graduation_certification': row['ì¡¸ì—…ì¸ì¦'] if pd.notna(row.get('ì¡¸ì—…ì¸ì¦')) else '-',
                'graduation_exam': row['ì¡¸ì—…ì‹œí—˜'] if pd.notna(row.get('ì¡¸ì—…ì‹œí—˜')) else '-',
                'qualification': row['ì‹ ì²­ìê²©'],
                'degree': row['í•™ìœ„ê¸° í‘œê¸°'],
                'difficulty': 'â˜…' * int(row['ë‚œì´ë„']) + 'â˜†' * (5 - int(row['ë‚œì´ë„'])),
                'features': row['íŠ¹ì§•'].split(',') if pd.notna(row.get('íŠ¹ì§•')) else [],
                'notes': row['ê¸°íƒ€'] if pd.notna(row.get('ê¸°íƒ€')) else ''
            }
        return programs
    except FileNotFoundError:
        st.warning("âš ï¸ data/programs.xlsx íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ìƒ˜í”Œ ë°ì´í„°ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.")
        return get_sample_programs()
    except Exception as e:
        st.error(f"âŒ ë°ì´í„° ë¡œë“œ ì˜¤ë¥˜: {e}")
        return get_sample_programs()

@st.cache_data
def load_faq():
    """FAQ ë¡œë“œ"""
    try:
        df = pd.read_excel('data/faq.xlsx')
        return df.to_dict('records')
    except FileNotFoundError:
        st.warning("âš ï¸ data/faq.xlsx íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ìƒ˜í”Œ ë°ì´í„°ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.")
        return get_sample_faq()
    except Exception as e:
        st.error(f"âŒ FAQ ë¡œë“œ ì˜¤ë¥˜: {e}")
        return get_sample_faq()

@st.cache_data
def load_curriculum_mapping():
    """ì´ìˆ˜ì²´ê³„ë„ ì´ë¯¸ì§€ ë§¤í•‘ ë¡œë“œ"""
    try:
        df = pd.read_excel('data/curriculum_mapping.xlsx')
        return df
    except FileNotFoundError:
        st.warning("âš ï¸ data/curriculum_mapping.xlsx íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return pd.DataFrame(columns=['ì „ê³µëª…', 'ì œë„ìœ í˜•', 'íŒŒì¼ëª…'])
    except Exception as e:
        st.error(f"âŒ ë§¤í•‘ ë°ì´í„° ë¡œë“œ ì˜¤ë¥˜: {e}")
        return pd.DataFrame(columns=['ì „ê³µëª…', 'ì œë„ìœ í˜•', 'íŒŒì¼ëª…'])

@st.cache_data
def load_courses():
    """ê³¼ëª© ì •ë³´ ë¡œë“œ"""
    try:
        df = pd.read_excel('data/courses.xlsx')
        return df
    except FileNotFoundError:
        return pd.DataFrame(columns=['ì „ê³µëª…', 'ì œë„ìœ í˜•', 'í•™ë…„', 'í•™ê¸°', 'ì´ìˆ˜êµ¬ë¶„', 'ê³¼ëª©ëª…', 'í•™ì '])
    except Exception as e:
        st.error(f"âŒ ê³¼ëª© ë°ì´í„° ë¡œë“œ ì˜¤ë¥˜: {e}")
        return pd.DataFrame(columns=['ì „ê³µëª…', 'ì œë„ìœ í˜•', 'í•™ë…„', 'í•™ê¸°', 'ì´ìˆ˜êµ¬ë¶„', 'ê³¼ëª©ëª…', 'í•™ì '])

@st.cache_data
def load_keywords():
    """í‚¤ì›Œë“œ ë§¤í•‘ ë¡œë“œ"""
    try:
        df = pd.read_excel('data/keywords.xlsx')
        return df.to_dict('records')
    except FileNotFoundError:
        st.warning("âš ï¸ data/keywords.xlsx íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ê¸°ë³¸ í‚¤ì›Œë“œë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.")
        return get_default_keywords()
    except Exception as e:
        st.error(f"âŒ í‚¤ì›Œë“œ ë¡œë“œ ì˜¤ë¥˜: {e}")
        return get_default_keywords()

@st.cache_data
def load_graduation_requirements():
    """ì¡¸ì—…ìš”ê±´(ê¸°ì¤€í•™ë²ˆë³„ í•™ì ) ë¡œë“œ"""
    try:
        df = pd.read_excel('data/graduation_requirements.xlsx')
        return df
    except FileNotFoundError:
        return pd.DataFrame()
    except Exception as e:
        st.error(f"âŒ ì¡¸ì—…ìš”ê±´ ë¡œë“œ ì˜¤ë¥˜: {e}")
        return pd.DataFrame()

@st.cache_data
def load_primary_requirements():
    """ë³¸ì „ê³µ ì´ìˆ˜ìš”ê±´ ë°ì´í„° ë¡œë“œ"""
    try:
        df = pd.read_excel('data/primary_requirements.xlsx')
        if not df.empty:
            cols = ['ì „ê³µëª…', 'êµ¬ë¶„']
            for col in cols:
                if col in df.columns:
                    df[col] = df[col].astype(str).str.strip()
        return df
    except:
        return pd.DataFrame()

@st.cache_data
def load_majors_info():
    """ì „ê³µ ì •ë³´ ë¡œë“œ (ì—°ë½ì²˜, í™ˆí˜ì´ì§€ í¬í•¨)"""
    try:
        df = pd.read_excel('data/majors_info.xlsx')
        return df
    except FileNotFoundError:
        st.warning("âš ï¸ data/majors_info.xlsx íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return pd.DataFrame()
    except Exception as e:
        st.error(f"âŒ ì „ê³µ ì •ë³´ ë¡œë“œ ì˜¤ë¥˜: {e}")
        return pd.DataFrame()


def get_default_keywords():
    """ê¸°ë³¸ í‚¤ì›Œë“œ ë°ì´í„°"""
    return [
        {"í‚¤ì›Œë“œ": "ë³µìˆ˜ì „ê³µ", "íƒ€ì…": "ì œë„", "ì—°ê²°ì •ë³´": "ë³µìˆ˜ì „ê³µ"},
        {"í‚¤ì›Œë“œ": "ë³µì „", "íƒ€ì…": "ì œë„", "ì—°ê²°ì •ë³´": "ë³µìˆ˜ì „ê³µ"},
        {"í‚¤ì›Œë“œ": "ë¶€ì „ê³µ", "íƒ€ì…": "ì œë„", "ì—°ê²°ì •ë³´": "ë¶€ì „ê³µ"},
        {"í‚¤ì›Œë“œ": "ë¶€ì „", "íƒ€ì…": "ì œë„", "ì—°ê²°ì •ë³´": "ë¶€ì „ê³µ"},
        {"í‚¤ì›Œë“œ": "ì—°ê³„ì „ê³µ", "íƒ€ì…": "ì œë„", "ì—°ê²°ì •ë³´": "ì—°ê³„ì „ê³µ"},
        {"í‚¤ì›Œë“œ": "ìœµí•©ì „ê³µ", "íƒ€ì…": "ì œë„", "ì—°ê²°ì •ë³´": "ìœµí•©ì „ê³µ"},
        {"í‚¤ì›Œë“œ": "ìœµí•©ë¶€ì „ê³µ", "íƒ€ì…": "ì œë„", "ì—°ê²°ì •ë³´": "ìœµí•©ë¶€ì „ê³µ"},
        {"í‚¤ì›Œë“œ": "ë§ˆì´í¬ë¡œë””ê·¸ë¦¬", "íƒ€ì…": "ì œë„", "ì—°ê²°ì •ë³´": "ë§ˆì´í¬ë¡œë””ê·¸ë¦¬"},
        {"í‚¤ì›Œë“œ": "ë§ˆë””", "íƒ€ì…": "ì œë„", "ì—°ê²°ì •ë³´": "ë§ˆì´í¬ë¡œë””ê·¸ë¦¬"},
        {"í‚¤ì›Œë“œ": "MD", "íƒ€ì…": "ì œë„", "ì—°ê²°ì •ë³´": "ë§ˆì´í¬ë¡œë””ê·¸ë¦¬"},
        {"í‚¤ì›Œë“œ": "í•™ì ", "íƒ€ì…": "ì£¼ì œ", "ì—°ê²°ì •ë³´": "í•™ì ì •ë³´"},
        {"í‚¤ì›Œë“œ": "ì´ìˆ˜í•™ì ", "íƒ€ì…": "ì£¼ì œ", "ì—°ê²°ì •ë³´": "í•™ì ì •ë³´"},
        {"í‚¤ì›Œë“œ": "ì‹ ì²­", "íƒ€ì…": "ì£¼ì œ", "ì—°ê²°ì •ë³´": "ì‹ ì²­ì •ë³´"},
        {"í‚¤ì›Œë“œ": "ì§€ì›", "íƒ€ì…": "ì£¼ì œ", "ì—°ê²°ì •ë³´": "ì‹ ì²­ì •ë³´"},
        {"í‚¤ì›Œë“œ": "ë¹„êµ", "íƒ€ì…": "ì£¼ì œ", "ì—°ê²°ì •ë³´": "ë¹„êµí‘œ"},
        {"í‚¤ì›Œë“œ": "ì°¨ì´", "íƒ€ì…": "ì£¼ì œ", "ì—°ê²°ì •ë³´": "ë¹„êµí‘œ"},
        {"í‚¤ì›Œë“œ": "ì¡¸ì—…", "íƒ€ì…": "ì£¼ì œ", "ì—°ê²°ì •ë³´": "ì¡¸ì—…ìš”ê±´"},
        {"í‚¤ì›Œë“œ": "ì¡¸ì—…ì¸ì¦", "íƒ€ì…": "ì£¼ì œ", "ì—°ê²°ì •ë³´": "ì¡¸ì—…ìš”ê±´"},
        {"í‚¤ì›Œë“œ": "ì¡¸ì—…ì‹œí—˜", "íƒ€ì…": "ì£¼ì œ", "ì—°ê²°ì •ë³´": "ì¡¸ì—…ìš”ê±´"},
    ]

def get_sample_programs():
    """ìƒ˜í”Œ ì œë„ ë°ì´í„°"""
    return {
        "ë³µìˆ˜ì „ê³µ": {
            "description": "ì£¼ì „ê³µ ì™¸ì— ë‹¤ë¥¸ ì „ê³µì„ ì¶”ê°€ë¡œ ì´ìˆ˜í•˜ì—¬ 2ê°œì˜ í•™ìœ„ë¥¼ ì·¨ë“í•˜ëŠ” ì œë„",
            "credits_general": "-",
            "credits_major": "36í•™ì  ì´ìƒ",
            "graduation_certification": "ë¶ˆí•„ìš”",
            "graduation_exam": "ë¶ˆí•„ìš”",
            "qualification": "2í•™ë…„ ì´ìƒ, í‰ì  2.0 ì´ìƒ",
            "degree": "2ê°œ í•™ìœ„ ìˆ˜ì—¬",
            "difficulty": "â˜…â˜…â˜…â˜…â˜†",
            "features": ["ì¡¸ì—… ì‹œ 2ê°œ í•™ìœ„ ì·¨ë“", "ì·¨ì—… ì‹œ ê²½ìŸë ¥ ê°•í™”", "í•™ì  ë¶€ë‹´ ë†’ìŒ"],
            "notes": ""
        },
        "ë¶€ì „ê³µ": {
            "description": "ì£¼ì „ê³µ ì™¸ì— ë‹¤ë¥¸ ì „ê³µì˜ ê¸°ì´ˆê³¼ëª©ì„ ì´ìˆ˜í•˜ëŠ” ì œë„",
            "credits_general": "-",
            "credits_major": "21í•™ì  ì´ìƒ",
            "graduation_certification": "ë¶ˆí•„ìš”",
            "graduation_exam": "ë¶ˆí•„ìš”",
            "qualification": "2í•™ë…„ ì´ìƒ",
            "degree": "ì£¼ì „ê³µ í•™ìœ„ (ë¶€ì „ê³µ í‘œê¸°)",
            "difficulty": "â˜…â˜…â˜†â˜†â˜†",
            "features": ["í•™ì  ë¶€ë‹´ ì ìŒ", "í•™ìœ„ì¦ì— ë¶€ì „ê³µ í‘œê¸°"],
            "notes": ""
        }
    }

def get_sample_faq():
    """ìƒ˜í”Œ FAQ ë°ì´í„°"""
    return [
        {
            "ì¹´í…Œê³ ë¦¬": "ì¼ë°˜",
            "ì§ˆë¬¸": "ë³µìˆ˜ì „ê³µê³¼ ë¶€ì „ê³µì˜ ì°¨ì´ëŠ”?",
            "ë‹µë³€": "ë³µìˆ˜ì „ê³µì€ 36í•™ì  ì´ìƒì„ ì´ìˆ˜í•˜ì—¬ 2ê°œì˜ í•™ìœ„ë¥¼ ë°›ì§€ë§Œ, ë¶€ì „ê³µì€ 21í•™ì  ì´ìˆ˜ë¡œ ì£¼ì „ê³µ í•™ìœ„ë§Œ ë°›ìŠµë‹ˆë‹¤."
        }
    ]

# ë°ì´í„° ë¡œë“œ
PROGRAM_INFO = load_programs()
FAQ_DATA = load_faq()
CURRICULUM_MAPPING = load_curriculum_mapping()
COURSES_DATA = load_courses()
KEYWORDS_DATA = load_keywords()
GRAD_REQUIREMENTS = load_graduation_requirements()
PRIMARY_REQUIREMENTS = load_primary_requirements()
MAJORS_INFO = load_majors_info()  # ğŸ†• ì „ê³µ ì •ë³´ ë¡œë“œ

def token_partial_match(root_input, target_clean):
    """
    root_input: ì •ì œëœ ì‚¬ìš©ì ì…ë ¥ (ê³µë°± ì œê±°ëœ ìƒíƒœ)
    target_clean: ì „ê³µëª… ì •ì œ ë¬¸ìì—´
    """
    # í•œê¸€/ì˜ë¬¸ í† í° ì¶”ì¶œ
    tokens = re.findall(r'[ê°€-í£a-zA-Z]+', root_input)

    for t in tokens:
        if len(t) >= 2 and t in target_clean:
            return True
    return False

def normalize_major_type(val):
    v = str(val)
    if 'í•„ìˆ˜' in v or 'ì „í•„' in v:
        return 'ì „ê³µí•„ìˆ˜'
    if 'ì„ íƒ' in v or 'ì „ì„ ' in v:
        return 'ì „ê³µì„ íƒ'
    return 'ê¸°íƒ€'

# === [í•µì‹¬] AI ì§€ì‹ ê²€ìƒ‰ í•¨ìˆ˜ (RAG) - ìˆ˜ì • ë²„ì „ ===
def get_ai_context(user_input, data_dict):
    context = ""
    user_input_clean = user_input.replace(" ", "").lower()

    # âœ… ë°˜ë“œì‹œ ë¨¼ì € ì´ˆê¸°í™”
    is_course_query = False
    is_contact_query = False

    is_course_query = any(
        w in user_input_clean
        for w in ["ê³¼ëª©", "êµê³¼ëª©", "ì¶”ì²œ", "ë¦¬ìŠ¤íŠ¸", "ìˆ˜ê°•", "í•™ë…„"]
    )

    is_contact_query = any(
        w in user_input_clean
        for w in ["ì—°ë½ì²˜", "ì‚¬ë¬´ì‹¤", "ìœ„ì¹˜", "ë²ˆí˜¸"]
    )

    # ë°ì´í„° ê°€ì ¸ì˜¤ê¸° (ì „ì—­ ë³€ìˆ˜ í™œìš© ë° ì•ˆì „ì¥ì¹˜)
    majors_info = data_dict.get('majors', MAJORS_INFO)
    primary_req = data_dict.get('primary_req', PRIMARY_REQUIREMENTS)
    courses_data = data_dict.get('courses', COURSES_DATA)
    faq_data = data_dict.get('faq', FAQ_DATA)
    prog_info = data_dict.get('programs', PROGRAM_INFO)

    # MD ì¿¼ë¦¬ ì—¬ë¶€ íŒë‹¨
    is_md_query = any(k in user_input_clean for k in ['md', 'ë§ˆì´í¬ë¡œ', 'ì†Œë‹¨ìœ„', 'ë§ˆë””'])

    # 1ï¸âƒ£ ì§ˆë¬¸ ì˜ë„ íŒë³„
    is_contact_query = any(
        w in user_input_clean
        for w in ["ì—°ë½ì²˜", "ì‚¬ë¬´ì‹¤", "ìœ„ì¹˜", "ë²ˆí˜¸"]
    )
    
    # 1ï¸âƒ£ ì „ê³µ/MD ì—¬ë¶€ íŒë³„
    is_md_query = any(
        w in user_input_clean
        for w in ["ë§ˆì´í¬ë¡œë””ê·¸ë¦¬", "ì†Œë‹¨ìœ„", "MD"]
    )

    # 2ï¸âƒ£ ì „ê³µëª… í•µì‹¬ì–´ ì¶”ì¶œ
    raw_keyword = re.sub(r'[^\w]', '', user_input_clean)
    is_contact_query = any(w in user_input_clean for w in ["ì—°ë½ì²˜", "ì‚¬ë¬´ì‹¤", "ìœ„ì¹˜", "ë²ˆí˜¸"])
  
    if is_md_query:
        root_input = re.sub(r'(ë³´ì—¬ì¤˜|ì•Œë ¤ì¤˜|êµê³¼ëª©|ë¦¬ìŠ¤íŠ¸|ê³¼ëª©|ë­ì•¼|ë­ìˆì–´|ì¶”ì²œ|í•´ì¤˜)', '', raw_keyword)

    elif is_contact_query:
        # â— ì—°ë½ì²˜ ì§ˆë¬¸ì¼ ë•ŒëŠ” "ì „ê³µ"ë§Œ ì œê±°, í•µì‹¬ ëª…ì¹­ì€ ì‚´ë¦°ë‹¤
        root_input = re.sub(r'(í•™ê³¼|í•™ë¶€)', '', raw_keyword)

    else:
        root_input = re.sub(
            r'(ì „ê³µ|í•™ê³¼|í•™ë¶€|ê³¼ëª©|í•™ë…„|ì‹ ì²­|í•™ì |ë³´ì—¬ì¤˜|ì•Œë ¤ì¤˜|êµê³¼ëª©|ë¦¬ìŠ¤íŠ¸)',
            '',
            raw_keyword
        )

    if is_course_query:
        # â— ì „ê³µëª… ë³´ì¡´
        root_input = re.sub(
            r'(í•™ë…„|ê³¼ëª©|ì¶”ì²œ|í•´ì¤˜|ì•Œë ¤ì¤˜)',
            '',
            raw_keyword
        )
    else:
        root_input = re.sub(
            r'(ì „ê³µ|í•™ê³¼|í•™ë¶€|ì‹ ì²­|í•™ì )',
            '',
            raw_keyword
        )

    # ì „ê³µ ëª©ë¡ í™•ë³´
    all_majors_set = set()
    if not majors_info.empty:
        names = majors_info['ì „ê³µëª…'].dropna().astype(str).unique()
        all_majors_set.update(names)
    if not courses_data.empty:
        names = courses_data['ì „ê³µëª…'].dropna().astype(str).unique()
        all_majors_set.update(names)
    all_majors_list = list(all_majors_set)

    target_year = None
    for i in range(1, 5):
        if f"{i}í•™ë…„" in user_input_clean:
            target_year = i
            break

    # 3ï¸âƒ£ ğŸ”¥ ì „ê³µ ë§¤ì¹­ (matched_majors ìƒì„±)
    matched_majors = set()
    
    major_list = set()

    if not majors_info.empty and 'ì „ê³µëª…' in majors_info.columns:
        major_list.update(
            majors_info['ì „ê³µëª…'].dropna().astype(str).unique()
        )

    if not courses_data.empty and 'ì „ê³µëª…' in courses_data.columns:
        major_list.update(
            courses_data['ì „ê³µëª…'].dropna().astype(str).unique()
        )

    major_list = list(major_list)

    # 5ï¸âƒ£ ê³¼ëª©/ì¶”ì²œ ì§ˆë¬¸ì¸ì§€ íŒë³„
    is_course_query = any(w in user_input_clean for w in [
        "ê³¼ëª©", "ì¶”ì²œ", "ìˆ˜ê°•", "ê°•ì˜"
    ])

   # 4ï¸âƒ£ ğŸ”¥ í•™ë…„ ì¶”ì¶œ
    year_match = re.search(r'([1-4])\s*í•™ë…„', user_input_clean)
    target_year = int(year_match.group(1)) if year_match else None

    # 4ï¸âƒ£ ê³¼ëª© ì¡°íšŒ ë¶„ê¸° (ğŸ”¥ ì´ê²Œ í•µì‹¬)
    if is_course_query and matched_majors:
        for m_str in matched_majors:
            major_courses = COURSES_DATA[COURSES_DATA['ì „ê³µëª…'] == m_str]

            # í•™ë…„ í•„í„°
            if target_year:
                major_courses = major_courses[
                    major_courses['í•™ë…„'] == target_year
                ]

            # ğŸ”¹ ë§ˆì´í¬ë¡œë””ê·¸ë¦¬ ì œì™¸
            if 'ì œë„ìœ í˜•' in major_courses.columns:
                major_courses = major_courses[
                    ~major_courses['ì œë„ìœ í˜•']
                    .astype(str)
                    .str.contains('ì†Œë‹¨ìœ„|ë§ˆì´í¬ë¡œ|MD', case=False, na=False)
                ]

            if major_courses.empty:
                context += f"[ì•ˆë‚´] {m_str} {target_year}í•™ë…„ ê³¼ëª© ì •ë³´ê°€ ë°ì´í„°ì— ì—†ìŠµë‹ˆë‹¤.\n"
                continue
                
            # âœ… ğŸ”¥ ì—¬ê¸°!!!! (ë‹¹ì‹ ì´ ë¬¼ì–´ë³¸ ì½”ë“œ)
            major_courses['ì „ê³µêµ¬ë¶„ì •ë¦¬'] = (
                major_courses['ì´ìˆ˜êµ¬ë¶„'].apply(normalize_major_type)
            )

            required_courses = major_courses[
                major_courses['ì „ê³µêµ¬ë¶„ì •ë¦¬'] == 'ì „ê³µí•„ìˆ˜'
            ]

            elective_courses = major_courses[
                major_courses['ì „ê³µêµ¬ë¶„ì •ë¦¬'] == 'ì „ê³µì„ íƒ'
            ]

            # ğŸ”¹ ì´ì œë¶€í„° "ì¶”ì²œ" ì¶œë ¥
            context += f"### [{major} {target_year}í•™ë…„ ì¶”ì²œ ê³¼ëª©]\n"

            if not required_courses.empty:
                context += "ğŸ”¹ ì „ê³µí•„ìˆ˜ ê³¼ëª©\n"
                for _, row in required_courses.head(10).iterrows():
                    context += f"- {row['ê³¼ëª©ëª…']} ({row.get('í•™ê¸°','-')}í•™ê¸°)\n"

            if not elective_courses.empty:
                context += "\nğŸ”¹ ì „ê³µì„ íƒ ê³¼ëª©\n"
                for _, row in elective_courses.head(10).iterrows():
                    context += f"- {row['ê³¼ëª©ëª…']} ({row.get('í•™ê¸°','-')}í•™ê¸°)\n"

            context += "\n"

    for m_str in major_list:
        m_clean = re.sub(r'\s+', '', m_str)
        m_root = m_clean.replace("ì „ê³µ", "")

        # 1ï¸âƒ£ 1ìˆœìœ„
        if root_input in m_clean or root_input in m_root:
              matched_majors.add(m_str)
        # 2ï¸âƒ£ 2ìˆœìœ„
        elif len(root_input) >= 4 and root_input[:4] in m_clean:
            matched_majors.add(m_str)

    # =============================== 
    # ğŸ”’ ì—°ë½ì²˜ ì§ˆë¬¸ ì „ìš© ë³´ê°• ë¡œì§ (ì¶”ê°€)
    # ===============================
    if is_contact_query and not matched_majors:
        for m_str in major_list:
            if m_str.replace(" ", "") in raw_keyword:
                matched_majors.add(m_str)

    # ë§¤ì¹­ëœ ì „ê³µ ìƒì„¸ ì •ë³´ ì¶”ê°€
    if matched_majors:
        context += f"[ê²€ìƒ‰ëœ íŠ¹ì • ì „ê³µ: {', '.join(matched_majors)}]\n\n"

        for m_name in list(matched_majors)[:3]:  # ìµœëŒ€ 3ê°œê¹Œì§€
            # A. ê¸°ë³¸ ì •ë³´ (ì—°ë½ì²˜ ë“±)
            if not majors_info.empty:
                m_rows = majors_info[majors_info['ì „ê³µëª…'] == m_name]
                if not m_rows.empty:
                    m_row = m_rows.iloc[0]
                    p_type = str(m_row.get('ì œë„ìœ í˜•', ''))
                    
                    context += f"### [{m_name} ìƒì„¸ì •ë³´]\n"
                    
                    # MDê°€ ì•„ë‹ ë•Œë§Œ ì—°ë½ì²˜ ì œê³µ
                    if 'ë§ˆì´í¬ë¡œ' not in p_type and 'ì†Œë‹¨ìœ„' not in p_type:
                        context += f"- ì—°ë½ì²˜: {m_row.get('ì—°ë½ì²˜','-')}\n"
                        context += f"- ìœ„ì¹˜: {m_row.get('ìœ„ì¹˜','-')}\n"
                    
                    context += f"- ì œë„ìœ í˜•: {p_type}\n"
                    context += f"- ì†Œê°œ: {m_row.get('ì „ê³µì„¤ëª…','-')}\n\n"
            
            # B. ê³¼ëª© ì •ë³´
            if not courses_data.empty and is_course_query:
                for major in matched_majors:
                    major_courses = courses_data[courses_data['ì „ê³µëª…'] == major]

                    # âœ… [í•µì‹¬] MD ì§ˆë¬¸ì´ ì•„ë‹ˆë©´ ë§ˆì´í¬ë¡œë””ê·¸ë¦¬ ê³¼ëª© ì œì™¸
                    if not is_md_query and 'ì œë„ìœ í˜•' in major_courses.columns:
                        major_courses = major_courses[
                            ~major_courses['ì œë„ìœ í˜•']
                            .astype(str)
                            .str.contains('ì†Œë‹¨ìœ„|ë§ˆì´í¬ë¡œ|MD', case=False, na=False)
                        ]

                    # âœ… í•™ë…„ í•„í„°
                    if target_year:
                        major_courses = major_courses[
                            major_courses['í•™ë…„']
                                .astype(str)
                                .str.startswith(str(target_year))
                        ]

                    if major_courses.empty:
                        context += f"[ì•ˆë‚´] {major} {target_year}í•™ë…„ ê³¼ëª© ì •ë³´ê°€ ë°ì´í„°ì— ì—†ìŠµë‹ˆë‹¤.\n"
                    else:
                        context += f"### [{major} {target_year}í•™ë…„ ì¶”ì²œ ê³¼ëª©]\n"
                        for _, row in major_courses.head(15).iterrows():
                            context += (
                                f"- {row.get('í•™ë…„','-')}í•™ë…„ "
                                f"{row.get('í•™ê¸°','-')}í•™ê¸°: "
                                f"{row.get('ê³¼ëª©ëª…')} ({row.get('í•™ì ','-')}í•™ì )\n"
                            )
                        context += "\n"

    # ==========================================================
    # [2] ë§ˆì´í¬ë¡œë””ê·¸ë¦¬ ì „ìš© ì¶”ê°€ ê²€ìƒ‰ (is_md_queryì¼ ë•Œë§Œ)
    # ==========================================================
    if is_md_query and not courses_data.empty:
        if 'ì œë„ìœ í˜•' in courses_data.columns and 'ì „ê³µëª…' in courses_data.columns:
            
            # MD ê³¼ëª©ë§Œ í•„í„°ë§
            md_courses_df = courses_data[
                courses_data['ì œë„ìœ í˜•'].astype(str).str.contains('ì†Œë‹¨ìœ„|ë§ˆì´í¬ë¡œ|MD', case=False, na=False)
            ]
            
            if not md_courses_df.empty:
                md_major_list = md_courses_df['ì „ê³µëª…'].unique()
                matched_md_majors = []

                for m_name in md_major_list:
                    m_str = str(m_name)
                    m_clean = re.sub(r'^\d+\.?\s*', '', m_str)
                    m_clean = re.sub(r'[^\w]', '', m_clean.lower())
                    
                    paren_match = re.search(r'\(([^)]+)\)', m_str)
                    parent_major = ""
                    if paren_match:
                        parent_major = re.sub(r'[^\w]', '', paren_match.group(1).lower())
                    
                    match_found = False
                    
                    if root_input in m_clean or m_clean in root_input:
                        match_found = True
                    elif token_partial_match(root_input, m_clean):
                        match_found = True
                    elif parent_major and token_partial_match(root_input, parent_major):
                        match_found = True
                    elif len(root_input) >= 4 and root_input[:4] in m_clean:
                        match_found = True
                    
                    if match_found and m_name not in matched_majors:
                        matched_md_majors.append(m_name)

                # MD ë§¤ì¹­ ê²°ê³¼ ì¶”ê°€
                if matched_md_majors:
                    for m_name in matched_md_majors:
                        context += f"### [ğŸ¯ {m_name} ê³¼ëª© ë¦¬ìŠ¤íŠ¸]\n"
                        context += "â€» ì´ ê³¼ëª©ë“¤ì€ 'ì†Œë‹¨ìœ„ì „ê³µê³¼ì •(ë§ˆì´í¬ë¡œë””ê·¸ë¦¬)' ì´ìˆ˜ìš© ê³¼ëª©ì…ë‹ˆë‹¤.\n"
                        
                        m_courses = md_courses_df[md_courses_df['ì „ê³µëª…'] == m_name]
                        for _, row in m_courses.head(25).iterrows():
                            grade = row.get('í•™ë…„', '-')
                            term = row.get('í•™ê¸°', '-')
                            try:
                                grade = int(float(grade))
                            except:
                                pass
                            try:
                                term = int(float(term))
                            except:
                                pass
                            
                            context += f"- {grade}í•™ë…„ {term}í•™ê¸°: {row['ê³¼ëª©ëª…']} ({row['í•™ì ']}í•™ì )\n"
                        context += "\n"

    # ==========================================================
    # [3] ì œë„ ì¹´í…Œê³ ë¦¬ ë¦¬ìŠ¤íŠ¸ (íŠ¹ì • ì „ê³µì´ ì—†ì„ ë•Œë§Œ)
    # ==========================================================
    if not matched_majors:
        categories = {
            "ìœµí•©ì „ê³µ": ["ìœµí•©ì „ê³µ", "ìœµí•©"],
            "ë¶€ì „ê³µ": ["ë¶€ì „ê³µ"],
            "ë³µìˆ˜ì „ê³µ": ["ë³µìˆ˜ì „ê³µ", "ë³µì „"],
            "ë§ˆì´í¬ë¡œë””ê·¸ë¦¬": ["ë§ˆì´í¬ë¡œë””ê·¸ë¦¬", "ë§ˆë””", "ì†Œë‹¨ìœ„", "md"],
            "ì—°ê³„ì „ê³µ": ["ì—°ê³„ì „ê³µ", "ì—°ê³„"]
        }

        for cat_name, keywords in categories.items():
            if any(kw in user_input_clean for kw in keywords):
                if not majors_info.empty and 'ì œë„ìœ í˜•' in majors_info.columns:
                    matched_rows = majors_info[majors_info['ì œë„ìœ í˜•'].str.contains(cat_name, na=False)]
                    if not matched_rows.empty:
                        major_list = matched_rows['ì „ê³µëª…'].tolist()
                        context += f"[{cat_name} ì „ì²´ ëª©ë¡]\n- {', '.join(major_list)}\n\n"

    # ==========================================================
    # [4] ë³¸ì „ê³µ ì´ìˆ˜ìš”ê±´ ê²€ìƒ‰
    # ==========================================================
    if not primary_req.empty:
        pm_input = re.sub(r'(ì „ê³µ|í•™ê³¼|í•™ë¶€|ì˜|ì‹ ì²­|í•™ì |ì•Œë ¤ì¤˜|md)', '', user_input_clean)
        matched_primary = [m for m in primary_req['ì „ê³µëª…'].unique() if pm_input in str(m).lower()]
        
        for m in matched_primary[:1]:
            df_major = primary_req[primary_req['ì „ê³µëª…'] == m]
            context += f"### [{m}] ë³¸ì „ê³µ ì´ìˆ˜í•™ì  ìƒì„¸ ê¸°ì¤€\n"
            for _, row in df_major.iterrows():
                context += f"- êµ¬ë¶„: {row['êµ¬ë¶„']}, ë³¸ì „ê³µí•„ìˆ˜: {row.get('ë³¸ì „ê³µ_ì „í•„',0)}, ì „ê³µì„ íƒ: {row.get('ë³¸ì „ê³µ_ì „ì„ ',0)}, ê³„: {row.get('ë³¸ì „ê³µ_ê³„',0)}\n"

    # ==========================================================
    # [5] FAQ ê²€ìƒ‰
    # ==========================================================
    if faq_data:
        for faq in faq_data:
            if user_input_clean in str(faq['ì§ˆë¬¸']).replace(" ","").lower():
                context += f"[FAQ] Q: {faq['ì§ˆë¬¸']}\nA: {faq['ë‹µë³€']}\n\n"

    # ==========================================================
    # [6] ì œë„ ìì²´ ì„¤ëª…
    # ==========================================================
    for p_name, p_info in prog_info.items():
        if p_name in user_input_clean:
            context += f"### [{p_name}] ì œë„ ì„¤ëª…\n- {p_info['description']}\n- ì´ìˆ˜í•™ì : {p_info['credits_multi']}\n\n"

    return context

# === [í•µì‹¬] Gemini API ë‹µë³€ ìƒì„± ===
def generate_ai_response(user_input, chat_history, data_dict):
    """Gemini APIë¥¼ ì‚¬ìš©í•˜ì—¬ ë‹µë³€ ìƒì„±"""
    
    # 1. ì—‘ì…€ì—ì„œ ê´€ë ¨ ì§€ì‹ ì¶”ì¶œ
    context = get_ai_context(user_input, data_dict)
    
    # 2. ëŒ€í™” ê¸°ë¡ ìš”ì•½ (ìµœê·¼ 3ê°œë§Œ)
    history_text = ""
    for chat in chat_history[-3:]:
        history_text += f"{chat['role']}: {chat['content']}\n"

    # 3. ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ (AIì˜ ì„±ê²©ê³¼ ê·œì¹™ ì„¤ì •)
    prompt = f"""
    ë‹¹ì‹ ì€ 'í•œê²½êµ­ë¦½ëŒ€í•™êµ'ì˜ ìœ ì—°í•™ì‚¬ì œë„(ë‹¤ì „ê³µ) ì•ˆë‚´ ì „ë¬¸ AI ìƒë‹´ì›ì…ë‹ˆë‹¤.
    ì§ˆë¬¸ì— ëŒ€í•´ ì•„ë˜ ì œê³µëœ [í•™ì‚¬ ë°ì´í„°]ë§Œì„ ê·¼ê±°ë¡œ ë‹µë³€í•˜ì„¸ìš”.
    í•™ìƒì´ ë‹¤ì „ê³µ ì‹ ì²­ì— ëŒ€í•´ ë¬¼ìœ¼ë©´, ë‹¤ì „ê³µ í•™ì ë¿ë§Œ ì•„ë‹ˆë¼ [ë³¸ì „ê³µ í•™ì  ë³€ë™] ì •ë³´ë„ ë°˜ë“œì‹œ í™•ì¸í•´ì„œ ì•Œë ¤ì£¼ì„¸ìš”.
    
    [í•™ì‚¬ ë°ì´í„°]
    {context if context else "ê²€ìƒ‰ ê²°ê³¼ ì—†ìŒ. ì •í™•í•œ ì •ë³´ëŠ” ì „ê³µ ì‚¬ë¬´ì‹¤ ë¬¸ì˜ë¥¼ ê¶Œê³ í•˜ì„¸ìš”"}

    [ëŒ€í™” ê¸°ë¡]
    {history_text}

    ì§ˆë¬¸: {user_input}

    [ê·œì¹™]
    1. ë°˜ë“œì‹œ ì œê³µëœ [í•™ì‚¬ ë°ì´í„°]ë¥¼ ìµœìš°ì„ ìœ¼ë¡œ ì°¸ê³ í•˜ì—¬ ë‹µë³€í•˜ì„¸ìš”.
    2. í•™ìƒì´ íŠ¹ì • ì „ê³µì˜ ê³¼ëª©ì„ ë¬¼ì–´ë³´ê±°ë‚˜ ì¶”ì²œì„ ìš”ì²­í•˜ë©´, ë°ì´í„°ì— ìˆëŠ” ê³¼ëª©ëª…ì„ ì–¸ê¸‰í•˜ë©° ì¶”ì²œ ì´ìœ ë¥¼ ì§§ê²Œ ì„¤ëª…í•˜ì„¸ìš”.
    3. 'ìë£Œê°€ ë¶€ì¡±í•˜ì—¬ ì œê³µí•´ ë“œë¦¬ê¸° ì–´ë µìŠµë‹ˆë‹¤', 'í•™ì‚¬ ì‹œìŠ¤í…œ ë‚´ ë³„ë„ì˜ í˜ì´ì§€ì—ì„œ í™•ì¸í•˜ë¼', 'í™ˆí˜ì´ì§€ë¥¼ ì°¸ê³ í•˜ë¼', 'í¬í„¸ì—ì„œ ì¡°íšŒí•˜ë¼'ëŠ” ì‹ì˜ ë¬´ì±…ì„í•˜ê±°ë‚˜ ëª¨í˜¸í•œ ì•ˆë‚´ëŠ” ì ˆëŒ€ í•˜ì§€ ë§ˆì„¸ìš”.
    4. ë°ì´í„°ì— ì—†ëŠ” ë‚´ìš©ì„ ë‹µë³€í•  ë•ŒëŠ” 'ì œê°€ ê°€ì§„ ìë£Œì—ëŠ” ì—†ì§€ë§Œ ì¼ë°˜ì ì¸ ë‚´ìš©ì€ ì´ë ‡ìŠµë‹ˆë‹¤'ë¼ê³  ë°íˆê³ , ì •í™•í•œ í™•ì¸ì€ í•´ë‹¹ ì „ê³µ ë˜ëŠ” í•™ì‚¬ì§€ì›íŒ€ì— ë¬¸ì˜í•˜ë¼ê³  ì•ˆë‚´í•˜ì„¸ìš”.
    5. ê³¼ëª© ë¦¬ìŠ¤íŠ¸, ìˆ˜ê°•í•´ì•¼í•  ê³¼ëª© ë“± í™•ì¸ì€ ì™¼ìª½ ë©”ë‰´ì˜ 'ë‹¤ì „ê³µ ì œë„ ì•ˆë‚´'ì—ì„œ í™•ì¸í•˜ë¼ê³  ì•ˆë‚´í•˜ì„¸ìš”.
    6. ë§íˆ¬ëŠ” ì¹œì ˆí•˜ê³  ëª…í™•í•˜ê²Œ 'ìŠµë‹ˆë‹¤'ì²´ë¥¼ ì‚¬ìš©í•˜ì„¸ìš”.
    7. ì¤‘ìš”í•œ ìˆ˜ì¹˜(í•™ì  ë“±)ëŠ” ê°•ì¡°(**) í‘œì‹œë¥¼ í•˜ì„¸ìš”.
    8. ë‹µë³€ ëì—ëŠ” ì—°ê´€ëœ í‚¤ì›Œë“œ(ì˜ˆ: #ë³µìˆ˜ì „ê³µ #ì‹ ì²­ê¸°ê°„)ë¥¼ 2~3ê°œ ë‹¬ì•„ì£¼ì„¸ìš”.
    9. ì „ê³µëª…ì´ ëª¨í˜¸í•œ ê²½ìš°(ì˜ˆ: 'í–‰ì •'ë§Œ ì…ë ¥): 
       - "í˜¹ì‹œ 'í–‰ì •í•™ì „ê³µ'ì„ ì°¾ìœ¼ì‹œëŠ” ê±¸ê¹Œìš”?"ì™€ ê°™ì´ í›„ë³´êµ° ì¤‘ì—ì„œ ê°€ì¥ ê°€ëŠ¥ì„± ë†’ì€ ì „ê³µì„ ë˜ë¬¼ì–´ë³´ì„¸ìš”.
       - ë°ì´í„°ì— ê²€ìƒ‰ëœ í›„ë³´êµ°({context.split(']')[0] if ']' in context else ''})ì´ ìˆë‹¤ë©´ ì´ë¥¼ ë¦¬ìŠ¤íŠ¸ë¡œ ë³´ì—¬ì£¼ì„¸ìš”.
    10. ì§ˆë¬¸ ê°€ì´ë“œ ì œê³µ:
       - ë‹µë³€ ë§ˆì§€ë§‰ì— í•­ìƒ "ğŸ’¡ ë” ì •í™•í•œ ì •ë³´ë¥¼ ì›í•˜ì‹œë©´ 'ê²½ì˜í•™ì „ê³µ 2í•™ë…„ ê³¼ëª© ì•Œë ¤ì¤˜'ì™€ ê°™ì´ ì„¸ë¶€ì ìœ¼ë¡œ ì§ˆë¬¸í•´ ì£¼ì„¸ìš”!"ë¼ëŠ” ê°€ì´ë“œë¥¼ ë„£ìœ¼ì„¸ìš”.
    11. ê³¼ëª© ì¶”ì²œ:
       - ë°ì´í„°ì— ê³¼ëª© ì •ë³´ê°€ ìˆë‹¤ë©´ ë˜ë¬»ëŠ” ë™ì‹œì— "ìš°ì„  ì°¾ìœ¼ì‹œëŠ” ì „ê³µì¼ ê²ƒìœ¼ë¡œ ì˜ˆìƒë˜ëŠ” {context.split('[')[1].split(' ')[0] if '[' in context else 'í•´ë‹¹ ì „ê³µ'}ì˜ ê³¼ëª©ì„ ì•ˆë‚´í•´ ë“œë¦½ë‹ˆë‹¤"ë¼ë©° ë§›ë³´ê¸° ì •ë³´ë¥¼ ì œê³µí•˜ì„¸ìš”.
    12. ì¹œì ˆë„: í•™ìƒì„ ëŒ€í•˜ë“¯ ì¹œì ˆí•˜ê³  ë”°ëœ»í•˜ê²Œ ë‹µë³€í•˜ì„¸ìš”.
    13. í•™ìƒì´ ì§ˆë¬¸í•œ ë‚´ìš©ì— ëŒ€í•´ ë°ì´í„°ê°€ ë¶€ì¡±í•˜ë‹¤ë©´, ì§ˆë¬¸ ì˜ˆì‹œ(ì˜ˆ: ì „ê³µëª…ê³¼ í•™ë…„ì„ í•¨ê»˜ ë§ì”€í•´ ì£¼ì„¸ìš”)ë¥¼ ì°¸ê³ í•˜ì—¬ ë‹¤ì‹œ ì§ˆë¬¸í•˜ë„ë¡ ì¹œì ˆí•˜ê²Œ ìœ ë„í•´ì¤˜.
    14. ì§ˆë¬¸ ì˜ˆì‹œ(ë²„íŠ¼)ë¥¼ ëˆ„ë¥¸ ê²½ìš°ì²˜ëŸ¼ ì§ˆë¬¸ì´ ì¡°ê¸ˆ í¬ê´„ì ì´ë”ë¼ë„, "êµ¬ì²´ì ìœ¼ë¡œ ë§í•´ë‹¬ë¼"ëŠ” ë‹µë³€ë¶€í„° í•˜ì§€ ë§ˆì„¸ìš”.
    15. ë°ì´í„°ì— ìˆëŠ” ì •ë³´(ì—°ë½ì²˜ ë§›ë³´ê¸°, ì „ê³µ ë¦¬ìŠ¤íŠ¸ ë“±)ë¥¼ í™œìš©í•˜ì—¬ ì¼ë‹¨ ì•„ëŠ” ë²”ìœ„ ë‚´ì—ì„œ ìµœëŒ€í•œ í’ë¶€í•˜ê²Œ ë‹µë³€í•˜ì„¸ìš”.
    16. ì—°ë½ì²˜ë¥¼ ë¬¼ìœ¼ë©´ í‘œ(Table) í˜•ì‹ì„ ì‚¬ìš©í•˜ì—¬ ê¹”ë”í•˜ê²Œ ì •ë¦¬í•´ ë³´ì—¬ì£¼ì„¸ìš”.
    17. ì •ë³´ê°€ ë§ì•„ ë¦¬ìŠ¤íŠ¸ë¥¼ ë³´ì—¬ì¤€ í›„ì—ëŠ”, "ë” ê¶ê¸ˆí•œ íŠ¹ì • ì „ê³µì´ ìˆë‹¤ë©´ ì´ë¦„ì„ ë§ì”€í•´ ì£¼ì„¸ìš”!"ë¼ê³  ìì—°ìŠ¤ëŸ½ê²Œ ìœ ë„í•˜ì„¸ìš”.
    18. ë§Œì•½ íŠ¹ì • ì „ê³µì˜ ì‹ ì²­ ì ˆì°¨ê°€ ë°ì´í„°ì— ì—†ë‹¤ë©´, ì œê³µëœ [ë°ì´í„°] ì¤‘ 'ë‹¤ì „ê³µ ì‹ ì²­'ì´ë‚˜ 'ì¼ë°˜ì ì¸ ì‹ ì²­ ê¸°ê°„' ì •ë³´ë¥¼ í™œìš©í•˜ì—¬ "ê³µí†µì ìœ¼ë¡œ ë‹¤ì „ê³µ ì‹ ì²­ì€ ë§¤ë…„ 4ì›”, 10ì›”ê²½ì— ì§„í–‰ë©ë‹ˆë‹¤"ì™€ ê°™ì´ ì•„ëŠ” ë²”ìœ„ ë‚´ì—ì„œ ìµœëŒ€í•œ ë‹µë³€í•˜ì„¸ìš”.
    19. ë°ì´í„°ì— ì‹ ì²­ ê¸°ê°„ ì •ë³´ê°€ ì¡°ê¸ˆì´ë¼ë„ ìˆë‹¤ë©´ ê·¸ê²ƒì„ ìµœìš°ì„ ìœ¼ë¡œ ì•ˆë‚´í•˜ì„¸ìš”.
    20. ì •ë³´ê°€ ì • ë¶€ì¡±í•˜ë‹¤ë©´ ë‹µë³€ ëì— "ë” ìƒì„¸í•œ ê°œì¸ë³„ ìƒí™©ì€ í•™ì‚¬ì§€ì›íŒ€(031-670-5035) ë˜ëŠ” ì „ê³µì— ë¬¸ì˜í•˜ë©´ ì •í™•íˆ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤"ë¼ê³  ë§ë¶™ì´ì„¸ìš”.
    21. ë°ì´í„°ì— [ë³¸ì „ê³µ í•™ì  ë³€ë™ ì •ë³´]ê°€ í¬í•¨ë˜ì–´ ìˆë‹¤ë©´, ì´ë¥¼ ê°•ì¡°í•´ì„œ ì•ˆë‚´í•˜ì„¸ìš”. 
    22. ì˜ˆ: "í–‰ì •í•™ì „ê³µ í•™ìƒì´ ë³µìˆ˜ì „ê³µì„ ì‹ ì²­í•˜ë©´, ë³¸ì „ê³µ ì´ìˆ˜ í•™ì ì´ ê¸°ì¡´ 70í•™ì ì—ì„œ 45í•™ì ìœ¼ë¡œ ì¤„ì–´ë“¤ì–´ ë¶€ë‹´ì´ ì ì–´ì§‘ë‹ˆë‹¤!"ì™€ ê°™ì€ ë°©ì‹ìœ¼ë¡œ ì„¤ëª…í•˜ì„¸ìš”.
    23. ë§Œì•½ ì‚¬ìš©ìì˜ ì „ê³µì´ ë¬´ì—‡ì¸ì§€ ëª¨ë¥¸ë‹¤ë©´, "ë³¸ì „ê³µì— ë”°ë¼ ë‹¤ì „ê³µ ì‹ ì²­ ì‹œ ë³¸ì „ê³µ ì´ìˆ˜ í•™ì ì´ ì¤„ì–´ë“¤ ìˆ˜ ìˆìœ¼ë‹ˆ, ë³¸ì „ê³µ ì´ë¦„ì„ ë§ì”€í•´ì£¼ì‹œë©´ ë” ì •í™•íˆ ì•ˆë‚´í•´ ë“œë¦´ê²Œìš”."ë¼ê³  ì¹œì ˆíˆ ë˜ë¬¼ìœ¼ì„¸ìš”.
    24. í•™ìƒì´ íŠ¹ì • ì „ê³µ(ì˜ˆ: ê²½ì˜í•™ì „ê³µ)ì—ì„œ ë‹¤ì „ê³µ(ì˜ˆ: ë³µìˆ˜ì „ê³µ)ì„ í•  ë•Œì˜ í•™ì  ë³€í™”ë¥¼ ë¬¼ìœ¼ë©´:
       - ë°ì´í„°ì— ìˆëŠ” 'êµ¬ë¶„: ë‹¨ì¼ì „ê³µ'ì¼ ë•Œì˜ í•™ì ê³¼ 'êµ¬ë¶„: ë³µìˆ˜ì „ê³µ'ì¼ ë•Œì˜ í•™ì ì„ ì°¾ì•„ ì„œë¡œ ë¹„êµí•´ì£¼ì„¸ìš”.
       - "ë‹¨ì¼ì „ê³µ ì‹œì—ëŠ” ë³¸ì „ê³µì„ 00í•™ì  ë“¤ì–´ì•¼ í•˜ì§€ë§Œ, ë³µìˆ˜ì „ê³µì„ ì‹ ì²­í•˜ë©´ 00í•™ì ìœ¼ë¡œ ì¤„ì–´ë“­ë‹ˆë‹¤"ë¼ê³  ëª…í™•íˆ ë§í•˜ì„¸ìš”.
    25. ì ˆëŒ€ë¡œ "êµ¬ì²´ì ì¸ ì •ë³´ê°€ í¬í•¨ë˜ì–´ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤"ë¼ëŠ” ë§ì„ ë¨¼ì € í•˜ì§€ ë§ˆì„¸ìš”. ë°ì´í„°ì— 'êµ¬ë¶„'ë³„ í•™ì ì´ ìˆë‹¤ë©´ ê·¸ê²ƒì´ ë°”ë¡œ ê·¸ ì •ë³´ì…ë‹ˆë‹¤.
    26. ì •ë³´ë¥¼ í‘œ(Table) í˜•íƒœë¡œ ì •ë¦¬í•´ì„œ ë³´ì—¬ì£¼ë©´ í•™ìƒì´ ì´í•´í•˜ê¸° ì‰½ìŠµë‹ˆë‹¤.
    27. ë°ì´í„°ì— ë³¸ì „ê³µ ì´ë¦„ì€ ìˆëŠ”ë° ì‹ ì²­í•˜ë ¤ëŠ” ì œë„(ì˜ˆ: ìœµí•©ì „ê³µ)ì— ëŒ€í•œ í–‰ì´ ì—†ë‹¤ë©´, "ë‹¨ì¼ì „ê³µ ê¸°ì¤€ì€ ì´ë ‡ìŠµë‹ˆë‹¤. ë‹¤ì „ê³µ ì‹ ì²­ ì‹œ ë³€ë™ ìˆ˜ì¹˜ëŠ” í•™ê³¼ ì‚¬ë¬´ì‹¤ì— í™•ì¸ì´ í•„ìš”í•©ë‹ˆë‹¤."ë¼ê³  ì•ˆë‚´í•˜ì„¸ìš”.
    28. ë§ˆì´í¬ë¡œë””ê·¸ë¦¬(MD)ë¥¼ ì´ìˆ˜í•˜ë”ë¼ë„ **ë³¸ì „ê³µ(1ì „ê³µ) ì¡¸ì—… ì´ìˆ˜ í•™ì ì€ ì¤„ì–´ë“¤ì§€ ì•ŠìŠµë‹ˆë‹¤.**
    29. ë³¸ì „ê³µ í•™ì ì´ ì¤„ì–´ë“œëŠ”(ê°ë©´ë˜ëŠ”) ê²½ìš°ëŠ” ì˜¤ì§ 'ë³µìˆ˜ì „ê³µ', 'ë¶€ì „ê³µ', 'ìœµí•©ì „ê³µ', 'ìœµí•©ë¶€ì „ê³µ' ë¿ì…ë‹ˆë‹¤.
    30. ì§ˆë¬¸ìê°€ ë§ˆì´í¬ë¡œë””ê·¸ë¦¬ì˜ í•™ì  ë³€ë™ì„ ë¬¼ì–´ë³´ë©´ "ë§ˆì´í¬ë¡œë””ê·¸ë¦¬ëŠ” ë³¸ì „ê³µ í•™ì  ê°ë©´ì´ ì—†ìœ¼ë©°, ê¸°ì¡´ ë³¸ì „ê³µ í•™ì ì„ ëª¨ë‘ ì´ìˆ˜í•´ì•¼ í•©ë‹ˆë‹¤"ë¼ê³  ëª…í™•íˆ í•˜ê³ , ë‹¨, ë³¸ì „ê³µ ê³¼ëª©ê³¼ ë§ˆì´í¬ë¡œë””ê·¸ë¦¬ì˜ ê³¼ëª©ê³¼ ì¼ì¹˜í•˜ë©´ ë‘˜ë‹¤ ì¸ì •ëœë‹¤ë¼ê³  ë‹µë³€í•˜ì„¸ìš”.
    31. ë§ˆì´í¬ë¡œë””ê·¸ë¦¬ ê³¼ì •ì€ ë³„ë„ì˜ í–‰ì •ì‹¤ì´ ì—†ìœ¼ë¯€ë¡œ ì—°ë½ì²˜ë¥¼ ì•ˆë‚´í•˜ì§€ ë§ˆì„¸ìš”. ëŒ€ì‹  "í•´ë‹¹ ê³¼ì •ì€ ê¸°ì¡´ ì „ê³µì˜ êµê³¼ëª©ì„ ì¡°í•©í•œ ê³¼ì •ì´ë¯€ë¡œ, ê°œì„¤ëœ ì£¼ê´€ ì „ê³µ ì‚¬ë¬´ì‹¤ë¡œ ë¬¸ì˜í•´ì£¼ì„¸ìš”"ë¼ê³  ì•ˆë‚´í•˜ì„¸ìš”.

    ì§ˆë¬¸: {user_input}
    """

    try:
        # ìµœì‹  google-genai SDK í˜¸ì¶œ ë°©ì‹
        response = client.models.generate_content(
            model='gemini-2.0-flash',
            contents=prompt
        )
        if response and response.text:
            return response.text, "ai_generated"
        else:
            return "ì£„ì†¡í•©ë‹ˆë‹¤. ë‹µë³€ì„ ìƒì„±í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.", "error"
    except Exception as e:
        return f"AI ì—°ê²° ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}", "error"

# === ë©”ì¸ í™”ë©´ ë¡œì§ ìˆ˜ì • ===
if 'chat_history' not in st.session_state:
    st.session_state.chat_history = [
        {"role": "assistant", "content": "ì•ˆë…•í•˜ì„¸ìš”! í•œê²½êµ­ë¦½ëŒ€í•™êµ ë‹¤ì „ê³µ ì•ˆë‚´ AI ë¹„ì„œì…ë‹ˆë‹¤. ê¶ê¸ˆí•œ ì ì„ ë¬¼ì–´ë³´ì„¸ìš”! ğŸ“", "response_type": "greeting"}
    ]

def ask_chatbot(user_input):
    # 1. í‚¤ì›Œë“œ ê¸°ë°˜ìœ¼ë¡œ ë°ì´í„°ì—ì„œ 'ì§€ì‹ ì†ŒìŠ¤' í™•ë³´ (ê¸°ì¡´ keyword_match ë¡œì§ í™œìš©)
    # ì§ì ‘ ë‹µë³€ì„ ì¶œë ¥í•˜ì§€ ì•Šê³ , AIì—ê²Œ ì „ë‹¬í•  context ë³€ìˆ˜ì— ë‹´ìŠµë‹ˆë‹¤.
    extracted_context = get_ai_context(user_input, all_data)
    
    # 2. ë§Œì•½ ì •ë§ íŠ¹ìˆ˜í•œ ì‹œìŠ¤í…œ ëª…ë ¹(ì˜ˆ: "ê³„ì‚°ê¸° ì¼œì¤˜")ì´ë¼ë©´ ì¦‰ì‹œ ì²˜ë¦¬
    if "ê³„ì‚°ê¸°" in user_input:
        return "ê³„ì‚°ê¸° ê¸°ëŠ¥ì„ ì‹¤í–‰í•©ë‹ˆë‹¤.", "command_calc"

    # 3. í™•ë³´ëœ ì§€ì‹ì„ AIì—ê²Œ ë˜ì ¸ì„œ "ì´ ë‚´ìš© ê¸°ë°˜ìœ¼ë¡œ ì¹œì ˆí•˜ê²Œ ë‹µí•´ì¤˜"ë¼ê³  ì‹œí‚´
    try:
        response_text, res_type = generate_ai_response(user_input, st.session_state.chat_history, all_data)
        return response_text, res_type
    except:
        # AIê°€ ì‹¤íŒ¨í•  ê²½ìš°ì—ë§Œ ë°±ì—…ìš©ìœ¼ë¡œ ê¸°ì¡´ í‚¤ì›Œë“œ ë‹µë³€ ì¶œë ¥ (Fallback)
        return generate_response(user_input)

# === í‚¤ì›Œë“œ ê²€ìƒ‰ í•¨ìˆ˜ ===
def search_by_keyword(user_input):
    """í‚¤ì›Œë“œ ê¸°ë°˜ ê²€ìƒ‰ (ìµœìš°ì„ )"""
    user_input_lower = user_input.lower()
    
    matched_keywords = []
    
    for keyword_data in KEYWORDS_DATA:
        keyword = keyword_data['í‚¤ì›Œë“œ'].lower()
        
        if keyword in user_input_lower:
            matched_keywords.append(keyword_data)
    
    if matched_keywords:
        matched_keywords.sort(key=lambda x: len(x['í‚¤ì›Œë“œ']), reverse=True)
        return matched_keywords[0]
    
    return None

def find_majors_with_details(user_input):
    """
    ë‹¨ì–´ë§Œ ì…ë ¥í•´ë„ ì „ê³µëª…/í‚¤ì›Œë“œì™€ ë§¤ì¹­í•˜ì—¬ ìƒì„¸ ì •ë³´ë¥¼ ë°˜í™˜
    """
    if MAJORS_INFO.empty:
        return []
    
    # 1. ì…ë ¥ê°’ ì •ì œ (ê³µë°± ì œê±°)
    user_input_clean = user_input.replace(" ", "").lower()
    
    # ì…ë ¥ê°’ì´ ë„ˆë¬´ ì§§ìœ¼ë©´(1ê¸€ì) ê²€ìƒ‰ í’ˆì§ˆì„ ìœ„í•´ ì œì™¸ (ì˜ˆ: 'í•™', 'ê³¼' ë“±)
    if len(user_input_clean) < 2:
        return []

    results = []
    
    for _, row in MAJORS_INFO.iterrows():
        # [ìˆ˜ì •] ë§ˆì´í¬ë¡œë””ê·¸ë¦¬/ì†Œë‹¨ìœ„ì „ê³µì€ ì—°ë½ì²˜ ì•ˆë‚´ì—ì„œ ì œì™¸
        p_type = str(row.get('ì œë„ìœ í˜•', ''))
        if 'ë§ˆì´í¬ë¡œ' in p_type or 'ì†Œë‹¨ìœ„' in p_type:
            continue

        # ë°ì´í„° ì •ì œ
        major_name = str(row['ì „ê³µëª…']).strip()
        major_clean = major_name.replace(" ", "").lower()
        
        # 'ì „ê³µ', 'í•™ê³¼', 'í•™ë¶€'ë¥¼ ë—€ í•µì‹¬ ë‹¨ì–´ ì¶”ì¶œ (ì˜ˆ: ê²½ì˜í•™ì „ê³µ -> ê²½ì˜í•™)
        core_name = major_clean.replace("ì „ê³µ", "").replace("í•™ê³¼", "").replace("í•™ë¶€", "")
        
        # í‚¤ì›Œë“œ ê°€ì ¸ì˜¤ê¸°
        keywords = str(row.get('ê´€ì‹¬ë¶„ì•¼í‚¤ì›Œë“œ', '')).lower()
        keyword_list = [k.strip().replace(" ", "") for k in keywords.split(',')]
        
        # === ë§¤ì¹­ ë¡œì§ ===
        match_found = False
        priority = 0
        
        # Case A: ì „ê³µëª…ì— ì…ë ¥ì–´ê°€ í¬í•¨ë¨ (ì˜ˆ: ì…ë ¥ 'ê²½ì˜' -> ë°ì´í„° 'ê²½ì˜ì „ê³µ')
        if user_input_clean in major_clean: 
            match_found = True
            priority = 3  # ê°€ì¥ ë†’ì€ ìš°ì„ ìˆœìœ„
            
        # Case B: í•µì‹¬ ë‹¨ì–´ê°€ ì…ë ¥ì–´ì™€ ê°™ìŒ (ì˜ˆ: ì…ë ¥ 'ê²½ì˜' -> ë°ì´í„° 'ê²½ì˜í•™'ì˜ í•µì‹¬ 'ê²½ì˜')
        elif core_name in user_input_clean:
            match_found = True
            priority = 2
            
        # Case C: í‚¤ì›Œë“œ ë§¤ì¹­ (ì˜ˆ: ì…ë ¥ 'íšŒê³„' -> í‚¤ì›Œë“œ 'íšŒê³„')
        elif any(user_input_clean in k for k in keyword_list if k):
            match_found = True
            priority = 1

        if match_found:
            results.append({
                'major': major_name,
                'description': row.get('ì „ê³µì„¤ëª…', 'ì„¤ëª… ì—†ìŒ'),
                'contact': row.get('ì—°ë½ì²˜', '-'),
                'homepage': row.get('í™ˆí˜ì´ì§€', '-'),
                'location': row.get('ìœ„ì¹˜', '-'),
                'program_types': row.get('ì œë„ìœ í˜•', '-'),
                'priority': priority
            })
    
    # ìš°ì„ ìˆœìœ„ ë†’ìŒ -> ì´ë¦„ ì§§ì€ ìˆœ(ì •í™•ë„ ë†’ì„ í™•ë¥ )ìœ¼ë¡œ ì •ë ¬
    results.sort(key=lambda x: (-x['priority'], len(x['major'])))
    
    return results


# === ìœ ì‚¬ë„ ê¸°ë°˜ ê²€ìƒ‰ í•¨ìˆ˜ ===
@st.cache_resource
def create_faq_vectorizer():
    """FAQ ì§ˆë¬¸ë“¤ì„ ë²¡í„°í™”"""
    questions = [faq['ì§ˆë¬¸'] for faq in FAQ_DATA]
    vectorizer = TfidfVectorizer()
    
    if questions:
        vectors = vectorizer.fit_transform(questions)
        return vectorizer, vectors, questions
    return None, None, []

def find_similar_faq(user_input, threshold=0.5):
    """ìœ ì‚¬í•œ FAQ ì°¾ê¸°"""
    vectorizer, faq_vectors, questions = create_faq_vectorizer()
    
    if vectorizer is None or not questions:
        return None
    
    user_vector = vectorizer.transform([user_input])
    similarities = cosine_similarity(user_vector, faq_vectors)[0]
    
    max_similarity_idx = np.argmax(similarities)
    max_similarity = similarities[max_similarity_idx]
    
    if max_similarity >= threshold:
        return FAQ_DATA[max_similarity_idx], max_similarity
    
    return None

def get_top_similar_faqs(user_input, top_n=3):
    """ê°€ì¥ ìœ ì‚¬í•œ FAQ ì—¬ëŸ¬ ê°œ ë°˜í™˜"""
    vectorizer, faq_vectors, questions = create_faq_vectorizer()
    
    if vectorizer is None or not questions:
        return []
    
    user_vector = vectorizer.transform([user_input])
    similarities = cosine_similarity(user_vector, faq_vectors)[0]
    
    top_indices = np.argsort(similarities)[-top_n:][::-1]
    
    results = []
    for idx in top_indices:
        if similarities[idx] > 0.1:
            results.append({
                'faq': FAQ_DATA[idx],
                'similarity': similarities[idx]
            })
    
    return results

def find_similar_program(user_input):
    """ì œë„ëª… ìœ ì‚¬ë„ ê²€ìƒ‰"""
    program_names = list(PROGRAM_INFO.keys())
    
    for program in program_names:
        if program in user_input:
            return program
    
    for program in program_names:
        if any(word in user_input for word in program.split()):
            return program
    
    return None

# === ğŸ†• ê´€ì‹¬ë¶„ì•¼ ê¸°ë°˜ ì „ê³µ ì¶”ì²œ í•¨ìˆ˜ ===
def recommend_majors_by_interest(user_input):
    """ê´€ì‹¬ë¶„ì•¼ í‚¤ì›Œë“œ ë§¤ì¹­ ë¡œì§ ê°œì„ """
    # 1. ë°ì´í„° ë¡œë“œ í™•ì¸
    if MAJORS_INFO.empty:
        return []
    
    # 2. í•„ìˆ˜ ì»¬ëŸ¼ í™•ì¸ (ì»¬ëŸ¼ëª…ì´ ë‹¤ë¥¼ ê²½ìš°ë¥¼ ëŒ€ë¹„í•´ ìœ ì—°í•˜ê²Œ ì²˜ë¦¬ ê°€ëŠ¥)
    if 'ê´€ì‹¬ë¶„ì•¼í‚¤ì›Œë“œ' not in MAJORS_INFO.columns:
        # ì»¬ëŸ¼ëª…ì´ ë‹¤ë¥¼ ê²½ìš° ìˆ˜ë™ìœ¼ë¡œ ë§¤í•‘í•˜ê±°ë‚˜ ë¹ˆ ë¦¬ìŠ¤íŠ¸ ë°˜í™˜
        return []

    user_input_lower = user_input.lower()
    recommendations = []
    
    for _, row in MAJORS_INFO.iterrows():
        # ë°ì´í„° ì „ì²˜ë¦¬ (NaN ì²˜ë¦¬ ë° ë¬¸ìì—´ ë³€í™˜)
        raw_keywords = str(row.get('ê´€ì‹¬ë¶„ì•¼í‚¤ì›Œë“œ', ''))
        if raw_keywords == 'nan' or not raw_keywords.strip():
            continue
            
        # ì½¤ë§ˆ(,) ê¸°ì¤€ìœ¼ë¡œ ë‚˜ëˆ„ê³  ê³µë°± ì œê±°
        keywords_list = [k.strip().lower() for k in raw_keywords.split(',')]
        
        # 3. ë§¤ì¹­ ê²€ì‚¬: ì…ë ¥ ë¬¸ì¥ì— í‚¤ì›Œë“œê°€ í¬í•¨ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸
        # (ì˜ˆ: ì…ë ¥ "ì¸ê³µì§€ëŠ¥ ë°°ìš°ê³  ì‹¶ì–´" -> í‚¤ì›Œë“œ "ì¸ê³µì§€ëŠ¥" ë§¤ì¹­)
        matched = [k for k in keywords_list if k in user_input_lower]
        
        if matched:
            recommendations.append({
                'major': row['ì „ê³µëª…'],
                'description': row.get('ì „ê³µì„¤ëª…', 'ì„¤ëª… ì—†ìŒ'),
                'program_types': row.get('ì œë„ìœ í˜•', '-'),
                'match_score': len(matched), # ë§¤ì¹­ëœ í‚¤ì›Œë“œ ê°œìˆ˜ë¡œ ì ìˆ˜ ì‚°ì •
                'matched_keywords': matched,
                'contact': row.get('ì—°ë½ì²˜', '-'),
                'homepage': row.get('í™ˆí˜ì´ì§€', '-')
            })
    
    # ë§¤ì¹­ ì ìˆ˜ê°€ ë†’ì€ ìˆœìœ¼ë¡œ ì •ë ¬ í›„ ìƒìœ„ 5ê°œ ë°˜í™˜
    recommendations.sort(key=lambda x: x['match_score'], reverse=True)
    return recommendations[:5]

def display_major_info(major_name):
    """íŠ¹ì • ì „ê³µì˜ ì—°ë½ì²˜/í™ˆí˜ì´ì§€ ì •ë³´ í‘œì‹œ"""
    if MAJORS_INFO.empty:
        return "ì „ê³µ ì •ë³´ë¥¼ ë¶ˆëŸ¬ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
    
    major_data = MAJORS_INFO[MAJORS_INFO['ì „ê³µëª…'] == major_name]
    
    if major_data.empty:
        return f"'{major_name}' ì „ê³µ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
    
    row = major_data.iloc[0]
    
    response = f"**{major_name} ğŸ“**\n\n"
    response += f"**ğŸ“ ì†Œê°œ:** {row['ì „ê³µì„¤ëª…']}\n\n"
    response += f"**ğŸ“š ì´ìˆ˜ ê°€ëŠ¥ ë‹¤ì „ê³µ ì œë„:** {row['ì œë„ìœ í˜•']}\n\n"
    response += f"**ğŸ“ ì—°ë½ì²˜:** {row['ì—°ë½ì²˜']}\n\n"
    
    if pd.notna(row.get('í™ˆí˜ì´ì§€')) and row['í™ˆí˜ì´ì§€'] != '-':
        response += f"**ğŸŒ í™ˆí˜ì´ì§€:** {row['í™ˆí˜ì´ì§€']}\n\n"
    
    if pd.notna(row.get('ìœ„ì¹˜')) and row['ìœ„ì¹˜'] != '-':
        response += f"**ğŸ“ ìœ„ì¹˜:** {row['ìœ„ì¹˜']}\n\n"
    
    return response


# === ì´ë¯¸ì§€ í‘œì‹œ í•¨ìˆ˜ ===
def display_curriculum_image(major, program_type):
    """ì´ìˆ˜ì²´ê³„ë„ ë˜ëŠ” ì•ˆë‚´ ì´ë¯¸ì§€ í‘œì‹œ"""
    result = CURRICULUM_MAPPING[
        (CURRICULUM_MAPPING['ì „ê³µëª…'] == major) & 
        (CURRICULUM_MAPPING['ì œë„ìœ í˜•'] == program_type)
    ]
    
    if not result.empty:
        raw_filenames = str(result.iloc[0]['íŒŒì¼ëª…'])
        filenames = [f.strip() for f in raw_filenames.split(',')]
        
        if len(filenames) > 1:
            cols = st.columns(len(filenames)) 
            for idx, filename in enumerate(filenames):
                image_path = f"images/curriculum/{filename}"
                with cols[idx]:
                    if os.path.exists(image_path):
                        st.image(image_path, caption=f"{major} ì•ˆë‚´-{idx+1}", use_container_width=True)
                    else:
                        st.warning(f"âš ï¸ ì´ë¯¸ì§€ íŒŒì¼ ì—†ìŒ: {filename}")
            return True
            
        else:
            filename = filenames[0]
            image_path = f"images/curriculum/{filename}"
            
            if os.path.exists(image_path):
                is_micro = "ì†Œë‹¨ìœ„ì „ê³µê³¼ì •(ë§ˆì´í¬ë¡œë””ê·¸ë¦¬)" in program_type or "ë§ˆì´í¬ë¡œë””ê·¸" in program_type
                caption_text = f"{major} ì•ˆë‚´ ì´ë¯¸ì§€" if is_micro else f"{major} ì´ìˆ˜ì²´ê³„ë„"
                
                if is_micro:
                    col1, col2, col3 = st.columns([1, 2, 1]) 
                    with col2:
                        st.image(image_path, caption=caption_text, use_container_width=True)
                else:
                    st.image(image_path, caption=caption_text, use_container_width=True)
                
                return True
            else:
                st.warning(f"âš ï¸ ì´ë¯¸ì§€ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {image_path}")
                return False
    else:
        if "ì†Œë‹¨ìœ„ì „ê³µê³¼ì •(ë§ˆì´í¬ë¡œë””ê·¸ë¦¬)" not in program_type:
            st.info(f"ğŸ’¡ {major} {program_type}ì˜ ì´ìˆ˜ì²´ê³„ë„ê°€ ì¤€ë¹„ ì¤‘ì…ë‹ˆë‹¤.")
        return False
    
# === ê³¼ëª© í‘œì‹œ í•¨ìˆ˜ ===
def display_courses(major, program_type):
    """ê³¼ëª© ì •ë³´ í‘œì‹œ"""
    courses = COURSES_DATA[
        (COURSES_DATA['ì „ê³µëª…'] == major) & 
        (COURSES_DATA['ì œë„ìœ í˜•'] == program_type)
    ]
    
    if not courses.empty:
        st.subheader(f"ğŸ“š {major} í¸ì„± êµê³¼ëª©(2025í•™ë…„ë„ êµìœ¡ê³¼ì •)")       
        
        if "ì†Œë‹¨ìœ„ì „ê³µê³¼ì •(ë§ˆì´í¬ë¡œë””ê·¸ë¦¬)" in program_type:
            semesters = sorted(courses['í•™ê¸°'].unique())
            
            for semester in semesters:
                st.markdown(f"#### {int(semester)}í•™ê¸°")
                
                semester_courses = courses[courses['í•™ê¸°'] == semester]
                
                for _, course in semester_courses.iterrows():
                    division = course['ì´ìˆ˜êµ¬ë¶„']
                    course_name = course['ê³¼ëª©ëª…']
                    credits = int(course['í•™ì '])
                    
                    if division in ['ì „í•„', 'í•„ìˆ˜']:
                        badge_color = "ğŸ”´"
                    elif division in ['ì „ì„ ', 'ì„ íƒ']:
                        badge_color = "ğŸŸ¢"
                    else:
                        badge_color = "ğŸ”µ"
                    
                    st.write(f"{badge_color} **[{division}]** {course_name} ({credits}í•™ì )")
                
                st.write("")
                
        else:
            years = sorted([int(y) for y in courses['í•™ë…„'].unique() if pd.notna(y)])
            
            if len(years) > 0:
                tabs = st.tabs([f"{year}í•™ë…„" for year in years])
                
                for idx, year in enumerate(years):
                    with tabs[idx]:
                        year_courses = courses[courses['í•™ë…„'] == year]
                        semesters = sorted(year_courses['í•™ê¸°'].unique())
                        
                        for semester in semesters:
                            st.write(f"**{int(semester)}í•™ê¸°**")
                            semester_courses = year_courses[year_courses['í•™ê¸°'] == semester]
                            
                            for _, course in semester_courses.iterrows():
                                division = course['ì´ìˆ˜êµ¬ë¶„']
                                course_name = course['ê³¼ëª©ëª…']
                                credits = int(course['í•™ì '])
                                
                                if division in ['ì „í•„', 'í•„ìˆ˜']:
                                    badge_color = "ğŸ”´"
                                elif division in ['ì „ì„ ', 'ì„ íƒ']:
                                    badge_color = "ğŸŸ¢"
                                else:
                                    badge_color = "ğŸ”µ"
                                
                                st.write(f"{badge_color} **[{division}]** {course_name} ({credits}í•™ì )")
                            
                            st.write("")
               
        return True
    else:
        return False

# === ë¹„êµí‘œ ìƒì„± ===
def create_comparison_table():
    data = {
        "ì œë„": list(PROGRAM_INFO.keys()),
        "ì´ìˆ˜í•™ì (êµì–‘)": [info["credits_general"] for info in PROGRAM_INFO.values()],
        "ì›ì „ê³µ ì´ìˆ˜í•™ì ": [info["credits_primary"] for info in PROGRAM_INFO.values()],
        "ë‹¤ì „ê³µ ì´ìˆ˜í•™ì ": [info["credits_multi"] for info in PROGRAM_INFO.values()],
        "ì¡¸ì—…ì¸ì¦": [info["graduation_certification"] for info in PROGRAM_INFO.values()],
        "ì¡¸ì—…ì‹œí—˜": [info["graduation_exam"] for info in PROGRAM_INFO.values()],
        "í•™ìœ„ê¸° í‘œê¸°": [info["degree"] for info in PROGRAM_INFO.values()],
        "ë‚œì´ë„": [info["difficulty"] for info in PROGRAM_INFO.values()],
        "ì‹ ì²­ìê²©": [info["qualification"] for info in PROGRAM_INFO.values()]
    }
    return pd.DataFrame(data)

# === ì±—ë´‡ ì‘ë‹µ ìƒì„± ===
def generate_response(user_input):
    user_input_lower = user_input.lower()
    
    # 1. ì¸ì‚¬
    if any(x in user_input_lower for x in ["ì•ˆë…•", "í•˜ì´", "hello", "ë°˜ê°€"]):
        return "ì•ˆë…•í•˜ì„¸ìš”! ğŸ‘‹ ìœ ì—°í•™ì‚¬ì œë„(ë‹¤ì „ê³µ) ì•ˆë‚´ AIì±—ë´‡ì…ë‹ˆë‹¤. ê¶ê¸ˆí•œ ì „ê³µì´ë‚˜ ì œë„ë¥¼ ë¬¼ì–´ë³´ì„¸ìš”!", "greeting"

    # ====================================================
    # 2. [í†µí•© ê²€ìƒ‰] ì „ê³µ/ê´€ì‹¬ë¶„ì•¼ ê²€ìƒ‰ (ìµœìš°ì„  ì²˜ë¦¬)
    # "ê²½ì˜", "ì»´í“¨í„° ì—°ë½ì²˜", "AI ì¶”ì²œ" ë“± ëª¨ë“  ì¼€ì´ìŠ¤ë¥¼ ì—¬ê¸°ì„œ ì²˜ë¦¬
    # ====================================================
    search_results = find_majors_with_details(user_input)
    
    if search_results:
        response = f"**ğŸ” '{user_input}' ê´€ë ¨ ì „ê³µ ì •ë³´ì…ë‹ˆë‹¤.**\n\n"
        
        # ìƒìœ„ 3ê°œë§Œ í‘œì‹œ
        for idx, info in enumerate(search_results[:3], 1):
            response += f"### {idx}. {info['major']}\n"
            
            # ì†Œê°œ (ì„¤ëª…ì´ ì—†ìœ¼ë©´ ìƒëµ)
            if info['description'] and info['description'] != 'ì„¤ëª… ì—†ìŒ':
                response += f"**ğŸ“ ì†Œê°œ:** {info['description']}\n\n"
            
            # ì—°ë½ì²˜ (í•„ìˆ˜ ì •ë³´)
            response += f"**ğŸ“ ì—°ë½ì²˜:** {info['contact']}\n"
            
            # í™ˆí˜ì´ì§€ (ì •ë³´ê°€ ìˆëŠ” ê²½ìš°ë§Œ í‘œì‹œ)
            if info['homepage'] not in ['-', 'nan', None, '']:
                 response += f"**ğŸŒ í™ˆí˜ì´ì§€:** [{info['homepage']}]({info['homepage']})\n"
            
            # ìœ„ì¹˜ (ì •ë³´ê°€ ìˆëŠ” ê²½ìš°ë§Œ í‘œì‹œ)
            if info['location'] not in ['-', 'nan', None, '']:
                response += f"**ğŸ“ ì „ê³µ ì‚¬ë¬´ì‹¤ ìœ„ì¹˜:** {info['location']}\n"
            
            # ì œë„ ìœ í˜•
            response += f"\n**ğŸ“ ì´ìˆ˜ ê°€ëŠ¥ ë‹¤ì „ê³µ:** {info['program_types']}\n"
            response += "\n"
            
        return response, "major_info"

    # ====================================================
    # 3. [ì˜ˆì™¸ ì²˜ë¦¬] ì „ê³µëª… ì—†ì´ 'ì—°ë½ì²˜'ë§Œ ë¬¼ì–´ë³¸ ê²½ìš°
    # ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ì„ ë•Œë§Œ ì‹¤í–‰ë¨ -> ì „ì²´ ëª©ë¡ ì œê³µ
    # ====================================================
    if any(word in user_input_lower for word in ["ì—°ë½ì²˜", "ì „í™”ë²ˆí˜¸", "ê³¼ì‚¬", "ì‚¬ë¬´ì‹¤"]):
        response = "**ğŸ“ ì „ê³µë³„ ì—°ë½ì²˜ ì•ˆë‚´**\n\n"
        response += "ì°¾ìœ¼ì‹œëŠ” **ì „ê³µëª…ì„ ì •í™•íˆ ë§ì”€í•´ì£¼ì‹œë©´** í•´ë‹¹ ì‚¬ë¬´ì‹¤ ì •ë³´ë¥¼ ì•ˆë‚´í•´ë“œë¦½ë‹ˆë‹¤.\n"
        response += "ì•„ë˜ ëª©ë¡ì— ìˆëŠ” ì „ê³µëª…ì„ ì…ë ¥í•´ ë³´ì„¸ìš”.\n\n"
        
        if not MAJORS_INFO.empty:
            # 1. ë°ì´í„° ì •ë¦¬
            df_clean = MAJORS_INFO.dropna(subset=['ì „ê³µëª…']).copy()
            df_clean['ì „ê³µëª…'] = df_clean['ì „ê³µëª…'].astype(str)
            
            # 2. ê·¸ë£¹ ë¶„ë¦¬ ë¡œì§ (ë§ˆì´í¬ë¡œë””ê·¸ë¦¬ vs ì¼ë°˜)
            try:
                is_md = df_clean['ì œë„ìœ í˜•'].str.contains('ë§ˆì´í¬ë¡œ|ì†Œë‹¨ìœ„', na=False) | \
                        df_clean['ì „ê³µëª…'].str.contains('ë§ˆì´í¬ë¡œ|ì†Œë‹¨ìœ„', na=False)
            except KeyError:
                is_md = df_clean['ì „ê³µëª…'].str.contains('ë§ˆì´í¬ë¡œ|ì†Œë‹¨ìœ„', na=False)

            general_majors = sorted(df_clean[~is_md]['ì „ê³µëª…'].unique())
            md_majors = sorted(df_clean[is_md]['ì „ê³µëª…'].unique())
            
            # 3. ì¼ë°˜ ì „ê³µ ì¶œë ¥
            response += "### ğŸ« í•™ë¶€/ì „ê³µ\n"
            if general_majors:
                for i in range(0, len(general_majors), 3):
                    batch = general_majors[i:i+3]
                    response += " | ".join(batch) + "\n"
            
            # 4. ë§ˆì´í¬ë¡œë””ê·¸ë¦¬ ì¶œë ¥
            if md_majors:
                response += "\n### ğŸ“ ì†Œë‹¨ìœ„ì „ê³µ(ë§ˆì´í¬ë¡œë””ê·¸ë¦¬)\n"
                for i in range(0, len(md_majors), 2):
                    batch = md_majors[i:i+2]
                    response += " | ".join(batch) + "\n"
        
        return response, "contact_list"

    # ====================================================
    # 4. ì œë„ í‚¤ì›Œë“œ ê²€ìƒ‰
    # ====================================================
    keyword_match = search_by_keyword(user_input)
    if keyword_match:
        keyword_type = keyword_match['íƒ€ì…']
        linked_info = keyword_match['ì—°ê²°ì •ë³´']
        
        if keyword_type == "ì œë„" and linked_info in PROGRAM_INFO:
            info = PROGRAM_INFO[linked_info]
            response = f"**{linked_info}** ğŸ“š\n\n"
            response += f"**ì„¤ëª…:** {info['description']}\n\n"
            response += f"**ğŸ“– ì´ìˆ˜í•™ì **\n"
            response += f"- êµì–‘: {info['credits_general']}\n"
            response += f"- ì›ì „ê³µ: {info['credits_primary']}\n\n"
            response += f"- ë‹¤ì „ê³µ: {info['credits_multi']}\n\n"
            response += f"**ğŸ“ ì¡¸ì—… ìš”ê±´**\n"
            response += f"- ì¡¸ì—…ì¸ì¦: {info['graduation_certification']}\n"
            response += f"- ì¡¸ì—…ì‹œí—˜: {info['graduation_exam']}\n\n"
            response += f"**âœ… ì‹ ì²­ìê²©:** {info['qualification']}\n"
            response += f"**ğŸ“œ í•™ìœ„ê¸° í‘œê¸°:** {info['degree']}\n"
            response += f"**â™§ ë‚œì´ë„:** {info['difficulty']}\n\n"
            
            if info['features']:
                response += f"**âœ¨ íŠ¹ì§•:**\n"
                for feature in info['features']:
                    response += f"- {feature.strip()}\n"
            if info['notes']:
                response += f"\n**ğŸ’¡ ê¸°íƒ€:** {info['notes']}"
                
            response += f"\n\n_ğŸ” í‚¤ì›Œë“œ '{keyword_match['í‚¤ì›Œë“œ']}'ë¡œ ê²€ìƒ‰ë¨_"
            return response, "program" # [ìˆ˜ì •] ì˜¬ë°”ë¥¸ response ë¦¬í„´
        
        elif keyword_type == "ì£¼ì œ":
            if linked_info == "í•™ì ì •ë³´":
                response = "**ì œë„ë³„ ì´ìˆ˜ í•™ì ** ğŸ“–\n\n"
                for program, info in PROGRAM_INFO.items():
                    response += f"**{program}**\n"
                    response += f"  - êµì–‘: {info['credits_general']}\n"
                    response += f"  - ì›ì „ê³µ: {info['credits_primary']}\n\n"
                    response += f"  - ë‹¤ì „ê³µ: {info['credits_multi']}\n\n"
                response += f"_ğŸ” í‚¤ì›Œë“œ '{keyword_match['í‚¤ì›Œë“œ']}'ë¡œ ê²€ìƒ‰ë¨_"
                return response, "credits"
            
            elif linked_info == "ì‹ ì²­ì •ë³´":
                response = "**ì‹ ì²­ ê´€ë ¨ ì •ë³´** ğŸ“\n\n"
                response += "ë‹¤ì „ê³µ ì œë„ëŠ” ë§¤ í•™ê¸° ì´ˆ(4ì›”, 10ì›”), í•™ê¸°ë§(6ì›”, 12ì›”)ì— ì‹ ì²­ ê°€ëŠ¥í•©ë‹ˆë‹¤.\n\n"
                response += "ìì„¸í•œ ë‚´ìš©ì€ 'ğŸ“š ë‹¤ì „ê³µ ì œë„ ì•ˆë‚´' ë˜ëŠ” 'â“ FAQ' ë©”ë‰´'ë¥¼ í™•ì¸í•˜ì‹œê±°ë‚˜, - [ğŸ“¥ í™ˆí˜ì´ì§€ í•™ì‚¬ê³µì§€](https://www.hknu.ac.kr/kor/562/subview.do)\në¥¼ ì°¸ê³ í•´ ì£¼ì„¸ìš”!\n\n"
                response += f"_ğŸ” í‚¤ì›Œë“œ '{keyword_match['í‚¤ì›Œë“œ']}'ë¡œ ê²€ìƒ‰ë¨_"
                return response, "application"
            
            elif linked_info == "ë¹„êµí‘œ":
                response = "ê° ì œë„ì˜ ë¹„êµëŠ” ì™¼ìª½ ì‚¬ì´ë“œë°”ì˜ 'ğŸ“š ë‹¤ì „ê³µ ì œë„ ì•ˆë‚´'ì—ì„œ í™•ì¸í•˜ì‹¤ ìˆ˜ ìˆìŠµë‹ˆë‹¤!\n\n"
                response += f"_ğŸ” í‚¤ì›Œë“œ '{keyword_match['í‚¤ì›Œë“œ']}'ë¡œ ê²€ìƒ‰ë¨_"
                return response, "comparison"
            
            elif linked_info == "ì¡¸ì—…ìš”ê±´":
                response = "**ì œë„ë³„ ì¡¸ì—… ìš”ê±´** ğŸ“\n\n"
                for program, info in PROGRAM_INFO.items():
                    response += f"**{program}**\n"
                    response += f"  - ì¡¸ì—…ì¸ì¦: {info['graduation_certification']}\n"
                    response += f"  - ì¡¸ì—…ì‹œí—˜: {info['graduation_exam']}\n\n"
                response += f"_ğŸ” í‚¤ì›Œë“œ '{keyword_match['í‚¤ì›Œë“œ']}'ë¡œ ê²€ìƒ‰ë¨_"
                return response, "graduation"
    
    # ====================================================
    # 5. FAQ ë° ê¸°íƒ€ ë¡œì§
    # ====================================================
    
    # FAQ ìœ ì‚¬ë„ ê²€ìƒ‰
    similar_faq = find_similar_faq(user_input)
    if similar_faq:
        faq, similarity = similar_faq
        response = f"**Q. {faq['ì§ˆë¬¸']}**\n\nA. {faq['ë‹µë³€']}\n\n"
        response += f"_ğŸ’¡ ë‹µë³€ ì‹ ë¢°ë„: {similarity*100:.0f}%_"
        return response, "faq"
    
    # ì œë„ ì„¤ëª… ê²€ìƒ‰ (ìœ ì‚¬ë„)
    program = find_similar_program(user_input)
    if program:
        info = PROGRAM_INFO[program]
        response = f"**{program}** ğŸ“š\n\n"
        response += f"**ì„¤ëª…:** {info['description']}\n..." # (ê¸¸ì–´ì„œ ìƒëµ, í•„ìš”í•œ ê²½ìš° ìœ„ì™€ ë™ì¼í•˜ê²Œ ì‘ì„±)
        return response, "program"
    
    # ë¹„êµ ì§ˆë¬¸
    if any(word in user_input_lower for word in ["ë¹„êµ", "ì°¨ì´", "ë‹¤ë¥¸ì ", "vs"]):
        return "ê° ì œë„ì˜ ë¹„êµëŠ” ì™¼ìª½ ì‚¬ì´ë“œë°”ì˜ 'ğŸ“š ë‹¤ì „ê³µ ì œë„ ì•ˆë‚´'ì—ì„œ í™•ì¸í•˜ì‹¤ ìˆ˜ ìˆìŠµë‹ˆë‹¤!", "comparison"
    
    # í•™ì  ê´€ë ¨ (í‚¤ì›Œë“œ ë§¤ì¹­ ì‹¤íŒ¨ ì‹œ ë°±ì—…)
    if any(word in user_input_lower for word in ["í•™ì ", "ëª‡í•™ì "]):
        response = "**ì œë„ë³„ ì´ìˆ˜ í•™ì ** ğŸ“–\n\n"
        for program, info in PROGRAM_INFO.items():
            response += f"**{program}**\n - êµì–‘: {info['credits_general']}\n - ì›ì „ê³µ: {info['credits_primary']}\n - ë‹¤ì „ê³µ: {info['credits_multi']}\n\n"
        return response, "credits"
    
    # ì‹ ì²­ ê´€ë ¨ (ë°±ì—…)
    if any(word in user_input_lower for word in ["ì‹ ì²­", "ì§€ì›", "ì–¸ì œ", "ê¸°ê°„"]):
        return "ë§¤ í•™ê¸° ì´ˆ(4ì›”, 10ì›”) ë° í•™ê¸°ë§(6ì›”, 12ì›”)ì— ì‹ ì²­ ê°€ëŠ¥í•©ë‹ˆë‹¤.", "application"
    
    # ìœ ì‚¬ ì§ˆë¬¸ ì œì•ˆ
    similar_faqs = get_top_similar_faqs(user_input, top_n=3)
    if similar_faqs:
        response = "ì •í™•íˆ ì¼ì¹˜í•˜ëŠ” ë‹µë³€ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ğŸ˜…\n\n**í˜¹ì‹œ ë‹¤ìŒ ì§ˆë¬¸ ì¤‘ í•˜ë‚˜ë¥¼ ì°¾ìœ¼ì…¨ë‚˜ìš”?**\n\n"
        for i, item in enumerate(similar_faqs, 1):
            response += f"{i}. {item['faq']['ì§ˆë¬¸']} _({item['similarity']*100:.0f}%)_\n"
        return response, "suggestion"
    
    # ì™„ì „ ë§¤ì¹­ ì‹¤íŒ¨
    return "ì£„ì†¡í•©ë‹ˆë‹¤. ì§ˆë¬¸ì„ ì´í•´í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ğŸ˜…\n'ê²½ì˜'ì´ë‚˜ 'ë³µìˆ˜ì „ê³µ'ì²˜ëŸ¼ í•µì‹¬ ë‹¨ì–´ë¡œ ì§ˆë¬¸í•´ ë³´ì‹œê² ì–´ìš”?", "no_match"

# === ë©”ì¸ UI ===
def main():
    # 1. ë°ì´í„° ë¡œë“œ
    ALL_DATA = load_all_data()

    st.title("ğŸ“ í•œê²½êµ­ë¦½ëŒ€ ìœ ì—°í•™ì‚¬ì œë„(ë‹¤ì „ê³µ) ì•ˆë‚´")
    
    # === ì‚¬ì´ë“œë°” ì„¤ì • ===
    with st.sidebar:
        st.markdown(
            """
            <div style='text-align: center; padding: 10px 0;'>
                <h1 style='font-size: 3rem; margin-bottom: 0;'>ğŸ“</h1>
                <h3 style='margin-top: 0;'>HKNU ë‹¤ì „ê³µ ì œë„ ì•ˆë‚´</h3>
            </div>
            """, 
            unsafe_allow_html=True
        )
        
        menu = option_menu(
            menu_title=None,
            options=["AIì±—ë´‡ ìƒë‹´", "ë‹¤ì „ê³µ ì œë„ ì•ˆë‚´", "FAQ"], 
            icons=["chat-dots-fill", "journal-bookmark-fill", "question-circle-fill"],
            menu_icon="cast",
            default_index=0,
            styles={
                "container": {"padding": "0!important", "background-color": "#fafafa"},
                "icon": {"color": "orange", "font-size": "18px"}, 
                "nav-link": {"font-size": "16px", "text-align": "left", "margin":"0px", "--hover-color": "#eee"},
                "nav-link-selected": {"background-color": "#0091FF"},
            }
        )

        st.divider()

        with st.container(border=True):
            st.markdown("### ğŸ¤– ë‹¤ì „ê³µ ì•ˆë‚´ AIì±—ë´‡")
            st.caption("Powered by Gemini 2.0")
            st.info(
                """
                **AIì±—ë´‡ì´ ì—¬ëŸ¬ë¶„ì˜ ë‹¤ì „ê³µ ê³ ë¯¼ì„
                í•´ê²°í•´ ë“œë¦½ë‹ˆë‹¤.
                
                *"ê²½ì˜í•™ê³¼ ì¡¸ì—…ìš”ê±´ì€?"*
                *"ë³µìˆ˜ì „ê³µ ì‹ ì²­ ê¸°ê°„ì€?"*
                
                ë¬´ì—‡ì´ë“  ë¬¼ì–´ë³´ì„¸ìš”!
                """
            )

        with st.container(border=True):
            st.markdown("### ğŸ“š ë‹¤ì „ê³µ ì œë„ë€?")
            st.success("ì£¼ì „ê³µ ì™¸ì— ë³µìˆ˜, ë¶€, ìœµí•©ì „ê³µ ë“± ë‹¤ì–‘í•œ í•™ìœ„ë¥¼ ì·¨ë“í•˜ì—¬ ìœµí•©í˜• ì¸ì¬ë¡œ ì„±ì¥í•˜ëŠ” ì œë„ì…ë‹ˆë‹¤.")
            
        st.markdown("---")
        st.caption("â“’ í•™ì‚¬ì§€ì›íŒ€ 031-670-5035")


    # === ë©”ì¸ ì½˜í…ì¸  ì˜ì—­ ===
    
    if menu == "AIì±—ë´‡ ìƒë‹´":
        st.subheader("ğŸ’¬ AI ìƒë‹´ì›ê³¼ ëŒ€í™”í•˜ê¸°")

        # [ë³µì›ë¨] ğŸ‘‹ ìƒë‹¨ ì§ˆë¬¸ ì˜ˆì‹œ ê°€ì´ë“œ
        with st.expander("ğŸ’¡ ì–´ë–¤ ì§ˆë¬¸ì„ í•´ì•¼ í• ì§€ ëª¨ë¥´ê² ë‚˜ìš”? (í´ë¦­)", expanded=True):
            st.markdown("ê¶ê¸ˆí•œ ì§ˆë¬¸ ë²„íŠ¼ì„ ëˆ„ë¥´ë©´ AIê°€ ë°”ë¡œ ë‹µë³€í•´ ë“œë¦½ë‹ˆë‹¤!")
            
            example_questions = [
                "í–‰ì •í•™ì „ê³µ 2í•™ë…„ ê³¼ëª© ì¶”ì²œí•´ì¤˜",
                "ë³µìˆ˜ì „ê³µê³¼ ë¶€ì „ê³µì˜ ì°¨ì´ì ì€?",
                "ìœµí•©ì „ê³µì—ëŠ” ì–´ë–¤ ì „ê³µì´ ìˆì–´?", 
                "ë‹¤ì „ê³µ ì‹ ì²­ ê¸°ê°„ê³¼ ë°©ë²• ì•Œë ¤ì¤˜",
                "ê²½ì˜í•™ì „ê³µ ì‚¬ë¬´ì‹¤ ì—°ë½ì²˜ë‘ ìœ„ì¹˜ ì–´ë””ì•¼?", 
                "ë³µìˆ˜ì „ê³µ ì‹ ì²­ ì‹œ ì¡¸ì—… ì´ìˆ˜ í•™ì  ë³€í™”ëŠ”?"
            ]

            # 2ë‹¨ ê·¸ë¦¬ë“œë¡œ ë²„íŠ¼ ë°°ì¹˜
            cols = st.columns(2)
            for idx, question in enumerate(example_questions):
                if cols[idx % 2].button(f"ğŸ’¬ {question}", use_container_width=True):
                    # ë²„íŠ¼ í´ë¦­ ì‹œ ë™ì‘ ë¡œì§
                    st.session_state.chat_history.append({"role": "user", "content": question})
                    
                    with st.spinner("AIê°€ ë‹µë³€ì„ ìƒì„± ì¤‘ì…ë‹ˆë‹¤..."):
                        response_text, res_type = generate_ai_response(
                            question, 
                            st.session_state.chat_history[:-1], 
                            ALL_DATA
                        )
                    
                    st.session_state.chat_history.append({
                        "role": "assistant", 
                        "content": response_text, 
                        "response_type": res_type
                    })
                    st.rerun()  # í™”ë©´ ìƒˆë¡œê³ ì¹¨í•˜ì—¬ ë‹µë³€ ì¦‰ì‹œ í‘œì‹œ

        st.divider()
        
        # ì±„íŒ… ê¸°ë¡ í‘œì‹œ
        for chat in st.session_state.chat_history:
            role = "user" if chat["role"] == "user" else "assistant"
            avatar = "ğŸ§‘â€ğŸ“" if role == "user" else "ğŸ¤–"
            with st.chat_message(role, avatar=avatar):
                st.markdown(chat["content"])
        
        # ì…ë ¥ì°½
        if prompt := st.chat_input("ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”..."):
            st.session_state.chat_history.append({"role": "user", "content": prompt})
            with st.chat_message("user", avatar="ğŸ§‘â€ğŸ“"):
                st.markdown(prompt)

            with st.chat_message("assistant", avatar="ğŸ¤–"):
                with st.spinner("AIê°€ ë‹µë³€ì„ ìƒì„± ì¤‘ì…ë‹ˆë‹¤..."):
                    response_text, res_type = generate_ai_response(
                        prompt, 
                        st.session_state.chat_history[:-1], 
                        ALL_DATA
                    )
                    st.markdown(response_text)
                    
            st.session_state.chat_history.append({"role": "assistant", "content": response_text, "response_type": res_type})
            scroll_to_bottom()

    # === [í™”ë©´ 2] ë‹¤ì „ê³µ ì œë„ ì•ˆë‚´ ===
    elif menu == "ë‹¤ì „ê³µ ì œë„ ì•ˆë‚´":
        st.header("ğŸ“Š ì œë„ í•œëˆˆì— ë¹„êµ")

        # 1. ìƒë‹¨ ì¹´ë“œí˜• UI
        if 'programs' in ALL_DATA and ALL_DATA['programs']:
            cols = st.columns(3)
            for idx, (program, info) in enumerate(ALL_DATA['programs'].items()):
                with cols[idx % 3]:
                    desc = info.get('description', 'ì„¤ëª… ì—†ìŒ')
                    c_pri = info.get('credits_primary', '-')
                    c_mul = info.get('credits_multi', '-')
                    degree = info.get('degree', '-')
                    difficulty = info.get('difficulty', 'â­')
                    
                    long_text_style = "overflow: hidden; text-overflow: ellipsis; display: -webkit-box; -webkit-line-clamp: 2; -webkit-box-orient: vertical; line-height: 1.4;"

                    html_content = f"""
                    <div style="border: 1px solid #e5e7eb; border-radius: 14px; padding: 18px; background: white; box-shadow: 0 4px 6px rgba(0,0,0,0.05); min-height: 380px; margin-bottom: 20px; display: flex; flex-direction: column; justify-content: space-between;">
                        <div>
                            <h3 style="margin: 0 0 8px 0; color: #1f2937; font-size: 1.2rem;">ğŸ“ {program}</h3>
                            <p style="color: #6b7280; font-size: 14px; margin-bottom: 12px; {long_text_style}">{desc}</p>
                            <hr style="margin: 12px 0; border: 0; border-top: 1px solid #e5e7eb;">
                            <div style="font-size: 14px; margin-bottom: 8px;">
                                <strong style="color: #374151;">ğŸ“– ì´ìˆ˜ í•™ì </strong>
                                <ul style="padding-left: 18px; margin: 4px 0; color: #4b5563;">
                                    <li style="margin-bottom: 4px;"><span style="font-weight:600; color:#374151;">ë³¸ì „ê³µ:</span> {c_pri}</li>
                                    <li><span style="font-weight:600; color:#374151;">ë‹¤ì „ê³µ:</span> {c_mul}</li>
                                </ul>
                            </div>
                        </div>
                        <div style="display: flex; justify-content: space-between; align-items: end; margin-top: 10px;">
                            <div style="max-width: 65%;">
                                <strong style="color: #374151; font-size: 14px;">ğŸ“œ í•™ìœ„ê¸°</strong><br>
                                <div style="font-size: 13px; color: #2563eb; background: #eff6ff; padding: 2px 6px; border-radius: 4px; white-space: nowrap; overflow: hidden; text-overflow: ellipsis;">{degree}</div>
                            </div>
                            <div style="text-align: right; min-width: 30%;">
                                <strong style="color: #374151; font-size: 14px;">ë‚œì´ë„</strong><br>
                                <span style="color: #f59e0b; font-size: 16px;">{difficulty}</span>
                            </div>
                        </div>
                    </div>"""
                    st.markdown(html_content, unsafe_allow_html=True)
        else:
            st.error("âŒ ì œë„ ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì˜¤ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")

        st.divider()

        # 2. ìƒì„¸ ì¡°íšŒ ê¸°ëŠ¥
        st.subheader("ğŸ” ìƒì„¸ ì •ë³´ ì¡°íšŒ")
        
        prog_keys = list(ALL_DATA['programs'].keys()) if 'programs' in ALL_DATA else []
        selected_program = st.selectbox("ìì„¸íˆ ì•Œì•„ë³¼ ì œë„ë¥¼ ì„ íƒí•˜ì„¸ìš”", prog_keys)
        
        if selected_program and 'programs' in ALL_DATA:
            info = ALL_DATA['programs'][selected_program]
            
            # ê¸°ë³¸ ì •ë³´ íƒ­
            tab1, tab2 = st.tabs(["ğŸ“ ê¸°ë³¸ ì •ë³´", "âœ… íŠ¹ì§• ë° ìœ ì˜ì‚¬í•­"])
            with tab1:
                col1, col2 = st.columns([2, 1])
                with col1:
                    st.info(f"**ê°œìš”**\n\n{info.get('description', '-')}")
                    st.subheader("ğŸ“– ì´ìˆ˜ í•™ì  ìƒì„¸")
                    st.markdown(f"""
                    - **êµì–‘:** {info.get('credits_general', '-')}
                    - **ì›ì „ê³µ:** {info.get('credits_primary', '-')}
                    - **ë‹¤ì „ê³µ:** {info.get('credits_multi', '-')}
                    """)
                    st.subheader("ğŸ“ ì¡¸ì—… ìš”ê±´")
                    st.markdown(f"- **ì¡¸ì—…ì¸ì¦:** {info.get('graduation_certification', '-')}")
                    st.markdown(f"- **ì¡¸ì—…ì‹œí—˜:** {info.get('graduation_exam', '-')}")

                with col2:
                    st.success(f"**ì‹ ì²­ ìê²©**\n\n{info.get('qualification', '-')}")
                    st.write(f"**í•™ìœ„ê¸° í‘œê¸°**\n\n{info.get('degree', '-')}")
            with tab2:
                for f in info.get('features', []): st.write(f"âœ”ï¸ {f}")
                if info.get('notes'): st.warning(f"**ğŸ’¡ ìœ ì˜ì‚¬í•­**: {info['notes']}")
            
            st.divider()

            # [âœ¨ ë³µì›ëœ ê¸°ëŠ¥] ì˜¤ë¦¬ì§€ë„ ì´ìˆ˜ í•™ì  í™•ì¸ ë¡œì§
            
            # 1) ì „ê³µ ëª©ë¡ í™•ë³´
            available_majors = set()
            if 'courses' in ALL_DATA and not ALL_DATA['courses'].empty:
                # ì œë„ ìœ í˜•ì´ í¬í•¨ëœ ì „ê³µ í•„í„°ë§
                c_df = ALL_DATA['courses']
                if 'ì œë„ìœ í˜•' in c_df.columns:
                    mask = c_df['ì œë„ìœ í˜•'].astype(str).str.contains(selected_program, na=False)
                    available_majors.update(c_df[mask]['ì „ê³µëª…'].unique())

            if 'curriculum' in ALL_DATA:
                 curr_df = ALL_DATA['curriculum']
                 if not curr_df.empty and 'ì œë„ìœ í˜•' in curr_df.columns:
                     mask = curr_df['ì œë„ìœ í˜•'].astype(str).str.contains(selected_program, na=False)
                     available_majors.update(curr_df[mask]['ì „ê³µëª…'].unique())

            # 2) ì „ê³µ ì„ íƒ UI (ì˜¤ë¦¬ì§€ë„ ìŠ¤íƒ€ì¼)
            if available_majors:
                target_programs = ["ë³µìˆ˜ì „ê³µ", "ë¶€ì „ê³µ", "ìœµí•©ì „ê³µ", "ìœµí•©ë¶€ì „ê³µ"]
                
                if selected_program in target_programs:
                    col_m1, col_m2 = st.columns(2)
                    with col_m1:
                        selected_major = st.selectbox(f"ì´ìˆ˜í•˜ë ¤ëŠ” {selected_program}", sorted(list(available_majors)))
                    with col_m2:
                        # ë³¸ì „ê³µ ëª©ë¡ ë¶ˆëŸ¬ì˜¤ê¸°
                        all_majors_list = []
                        if 'primary_req' in ALL_DATA and not ALL_DATA['primary_req'].empty:
                            all_majors_list = sorted(ALL_DATA['primary_req']['ì „ê³µëª…'].unique().tolist())
                        my_primary_major = st.selectbox("ë‚˜ì˜ ë³¸ì „ê³µ (ì œ1ì „ê³µ)", ["ì„ íƒ ì•ˆ í•¨"] + all_majors_list)
                else:
                    selected_major = st.selectbox(f"ì´ìˆ˜í•˜ë ¤ëŠ” {selected_program}", sorted(list(available_majors)))
                    my_primary_major = "ì„ íƒ ì•ˆ í•¨"

                # 3) í•™ì  ìš”ê±´ í‘œì‹œ (ì˜¤ë¦¬ì§€ë„ ë¡œì§)
                if selected_program in target_programs:
                    current_year = datetime.now().year
                    admission_year = st.number_input(
                        "ë³¸ì¸ í•™ë²ˆ (ì…í•™ì—°ë„)", 
                        min_value=2018, 
                        max_value=current_year, 
                        value=current_year
                    )
                    
                    st.write("")
                    
                    col_left, col_right = st.columns(2)
                    
                    # ì™¼ìª½: íƒ€ê²Ÿ ì „ê³µ ìš”ê±´
                    with col_left:
                        st.subheader(f"ğŸ¯ {selected_program}({selected_major}) ì´ìˆ˜ í•™ì  ê¸°ì¤€")
                        
                        if 'grad_req' in ALL_DATA and not ALL_DATA['grad_req'].empty:
                            req_data = ALL_DATA['grad_req'][
                                (ALL_DATA['grad_req']['ì „ê³µëª…'] == selected_major) & 
                                (ALL_DATA['grad_req']['ì œë„ìœ í˜•'].str.contains(selected_program, na=False))
                            ].copy()
                            
                            req_data['ê¸°ì¤€í•™ë²ˆ'] = pd.to_numeric(req_data['ê¸°ì¤€í•™ë²ˆ'], errors='coerce')
                            req_data = req_data.dropna(subset=['ê¸°ì¤€í•™ë²ˆ'])
                            applicable = req_data[req_data['ê¸°ì¤€í•™ë²ˆ'] <= admission_year]
                            
                            if not applicable.empty:
                                applicable = applicable.sort_values('ê¸°ì¤€í•™ë²ˆ', ascending=False)
                                row = applicable.iloc[0]
                                
                                st.write(f"- ì „ê³µí•„ìˆ˜: **{int(row['ì „ê³µí•„ìˆ˜'])}**í•™ì ")
                                st.write(f"- ì „ê³µì„ íƒ: **{int(row['ì „ê³µì„ íƒ'])}**í•™ì ")
                                st.markdown(f"#### ğŸ‘‰ {selected_program} {int(row['ì´í•™ì '])}í•™ì ")
                            else:
                                st.warning(f"{admission_year}í•™ë²ˆ ê¸°ì¤€ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
                        else:
                            st.warning("ì¡¸ì—…ìš”ê±´ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")

                    # ì˜¤ë¥¸ìª½: ë³¸ì „ê³µ ë³€ë™ ìš”ê±´
                    with col_right:
                        st.subheader(f"ğŸ  ë³¸ì „ê³µ({my_primary_major}) ì´ìˆ˜ í•™ì  ê¸°ì¤€")
                        
                        if my_primary_major != "ì„ íƒ ì•ˆ í•¨" and 'primary_req' in ALL_DATA:
                            pri_data = ALL_DATA['primary_req'][ALL_DATA['primary_req']['ì „ê³µëª…'] == my_primary_major].copy()
                            
                            if not pri_data.empty:
                                pri_data['ê¸°ì¤€í•™ë²ˆ'] = pd.to_numeric(pri_data['ê¸°ì¤€í•™ë²ˆ'], errors='coerce')
                                pri_valid = pri_data[pri_data['ê¸°ì¤€í•™ë²ˆ'] <= admission_year]
                                
                                if not pri_valid.empty:
                                    matched_row = None
                                    pri_valid = pri_valid.sort_values('ê¸°ì¤€í•™ë²ˆ', ascending=False)
                                    
                                    for _, p_row in pri_valid.iterrows():
                                        if selected_program in str(p_row['êµ¬ë¶„']):
                                            matched_row = p_row
                                            break
                                    
                                    if matched_row is not None:
                                        st.write(f"- ë³¸ì „ê³µ ì „í•„: **{int(matched_row['ë³¸ì „ê³µ_ì „í•„'])}**í•™ì ")
                                        st.write(f"- ë³¸ì „ê³µ ì „ì„ : **{int(matched_row['ë³¸ì „ê³µ_ì „ì„ '])}**í•™ì ")
                                        st.markdown(f"#### ğŸ‘‰ ë³¸ì „ê³µ {int(matched_row['ë³¸ì „ê³µ_ê³„'])}í•™ì ìœ¼ë¡œ ë³€ê²½")
                                        
                                        if pd.notna(matched_row.get('ë¹„ê³ ')):
                                            st.caption(f"ì°¸ê³ : {matched_row['ë¹„ê³ ']}")
                                    else:
                                        st.info(f"ë³€ë™ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. (ë‹¨ì¼ì „ê³µ ê¸°ì¤€ ìœ ì§€ ê°€ëŠ¥ì„±)")
                                else:
                                    st.warning(f"{admission_year}í•™ë²ˆ ê¸°ì¤€ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
                            else:
                                st.warning("ë³¸ì „ê³µ ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                        elif my_primary_major == "ì„ íƒ ì•ˆ í•¨":
                            st.info("ë³¸ì „ê³µì„ ì„ íƒí•˜ë©´ ë³€ë™ëœ ì´ìˆ˜ í•™ì ì„ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")

                st.divider()

                # ì´ë¯¸ì§€ í‘œì‹œ
                if selected_program == "ìœµí•©ì „ê³µ" or "ì†Œë‹¨ìœ„ì „ê³µ" in selected_program:
                    title = "ğŸ“‹ ì´ìˆ˜ì²´ê³„ë„" if selected_program == "ìœµí•©ì „ê³µ" else "ğŸ–¼ï¸ ê³¼ì • ì•ˆë‚´ ì´ë¯¸ì§€"
                    st.subheader(title)
                    display_curriculum_image(selected_major, selected_program)
        
                # ì´ìˆ˜ ê³¼ëª© í‘œì‹œ
                if not COURSES_DATA.empty:
                    display_courses(selected_major, selected_program)

    # === [í™”ë©´ 3] FAQ ===
    elif menu == "FAQ":
        st.header("â“ ìì£¼ ë¬»ëŠ” ì§ˆë¬¸")
        if 'faq' in ALL_DATA and ALL_DATA['faq']:
            for faq in ALL_DATA['faq']:
                with st.expander(f"Q. {faq['ì§ˆë¬¸']}"):
                    st.write(f"A. {faq['ë‹µë³€']}")
        else:
            st.info("ë“±ë¡ëœ FAQê°€ ì—†ìŠµë‹ˆë‹¤.")

if __name__ == "__main__":
    main()