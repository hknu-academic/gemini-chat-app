"""
============================================================
ğŸ“ ë‹¤ì „ê³µ ì•ˆë‚´ AIê¸°ë°˜ ì±—ë´‡
============================================================
ë²„ì „: 4.0 (ë¦¬íŒ©í† ë§ ë²„ì „)
ì£¼ìš” ë³€ê²½ì‚¬í•­:
1. FAQ ë©”ë‰´ ì‚­ì œ (AIì±—ë´‡ ìƒë‹´, ë‹¤ì „ê³µ ì œë„ ì•ˆë‚´ë§Œ ìœ ì§€)
2. faq_mapping.xlsx ê¸°ë°˜ FAQ ê²€ìƒ‰ ìš°ì„  ì ìš©
3. FAQ â†’ Semantic Router â†’ AI Fallback ìˆœì„œë¡œ ì²˜ë¦¬
4. YAML ì„¤ì • íŒŒì¼ê³¼ ì¤‘ë³µ ì œê±° ë° ì •ë¦¬
5. ë‹¤ì „ê³µ ì œë„ ì•ˆë‚´ í™”ë©´ ì™„ì „ ìœ ì§€
============================================================
"""

import streamlit as st
from google import genai
import pandas as pd
from streamlit_option_menu import option_menu
from datetime import datetime
import os
import yaml
import numpy as np
import re
import logging
import time
import hashlib

# Google Sheets ë¡œê¹…
try:
    import gspread
    from google.oauth2.service_account import Credentials
    GSPREAD_AVAILABLE = True
except ImportError:
    GSPREAD_AVAILABLE = False
    print("âš ï¸ gspread íŒ¨í‚¤ì§€ê°€ ì—†ìŠµë‹ˆë‹¤. ë¡œê¹…ì´ ë¹„í™œì„±í™”ë©ë‹ˆë‹¤.")

# ============================================================
# ğŸ“Œ ì„¤ì • íŒŒì¼ ë¡œë“œ
# ============================================================

def load_yaml_config(filename):
    """YAML ì„¤ì • íŒŒì¼ ë¡œë“œ"""
    config_path = os.path.join('config', filename)
    if os.path.exists(config_path):
        with open(config_path, 'r', encoding='utf-8') as f:
            return yaml.safe_load(f)
    return {}

MESSAGES = load_yaml_config('messages.yaml')
MAPPINGS = load_yaml_config('mappings.yaml')
SETTINGS = load_yaml_config('settings.yaml')

# ============================================================
# ğŸ“Œ ìƒìˆ˜ ì •ì˜
# ============================================================

DEFAULT_CONTACT_MESSAGE = "ğŸ“ ë¬¸ì˜: ì „ê³µ ì‚¬ë¬´ì‹¤ ë˜ëŠ” í•™ì‚¬ì§€ì›íŒ€ 031-670-5035ë¡œ ì—°ë½ì£¼ì‹œë©´ ë³´ë‹¤ ìƒì„¸í•œ ì •ë³´ë¥¼ ì•ˆë‚´ ë°›ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤."
CONTACT_MESSAGE = MESSAGES.get('contact', {}).get('default', DEFAULT_CONTACT_MESSAGE)

LINKS = MESSAGES.get('links', {})
ACADEMIC_NOTICE_URL = LINKS.get('academic_notice', "https://www.hknu.ac.kr/kor/562/subview.do")

PATHS = SETTINGS.get('paths', {})
CURRICULUM_IMAGES_PATH = PATHS.get('curriculum_images', "images/curriculum")

DIFFICULTY_STARS = MAPPINGS.get('difficulty_stars', {})


def convert_difficulty_to_stars(value):
    if pd.isna(value) or value == '':
        return DIFFICULTY_STARS.get('default', 'â­â­â­')
    if isinstance(value, str) and 'â­' in value:
        return value
    try:
        num = int(float(value))
        return DIFFICULTY_STARS.get(num, DIFFICULTY_STARS.get('default', 'â­â­â­'))
    except:
        return DIFFICULTY_STARS.get('default', 'â­â­â­')


# Semantic Router ì„¤ì •
logging.getLogger("semantic_router").setLevel(logging.ERROR)
SEMANTIC_ROUTER_ENABLED = True

SEMANTIC_ROUTER_AVAILABLE = False
Route = None
SemanticRouter = None
GoogleEncoder = None
LocalIndex = None

try:
    from semantic_router import Route
    from semantic_router.routers import SemanticRouter
    from semantic_router.encoders import GoogleEncoder
    from semantic_router.index import LocalIndex
    SEMANTIC_ROUTER_AVAILABLE = True
    SEMANTIC_ROUTER_VERSION = "0.1.x"
except ImportError:
    try:
        from semantic_router import Route
        from semantic_router.layer import RouteLayer as SemanticRouter
        from semantic_router.encoders import GoogleEncoder
        SEMANTIC_ROUTER_AVAILABLE = True
        SEMANTIC_ROUTER_VERSION = "0.0.x"
    except ImportError:
        SEMANTIC_ROUTER_AVAILABLE = False
        SEMANTIC_ROUTER_VERSION = None

# Gemini API ì„¤ì •
GEMINI_API_KEY = st.secrets["GEMINI_API_KEY"]
if not GEMINI_API_KEY:
    st.error("âš ï¸ GEMINI_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤!")
    st.stop()

client = genai.Client(api_key=GEMINI_API_KEY)


# ============================================================
# ğŸ“Š Google Sheets ë¡œê¹… ì‹œìŠ¤í…œ
# ============================================================

@st.cache_resource
def init_google_sheets():
    """Google Sheets ì´ˆê¸°í™”"""
    if not GSPREAD_AVAILABLE:
        return None
    
    try:
        if "gcp_service_account" not in st.secrets:
            print("âš ï¸ Google Sheets ì¸ì¦ ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤")
            return None
        
        credentials = Credentials.from_service_account_info(
            st.secrets["gcp_service_account"],
            scopes=[
                "https://www.googleapis.com/auth/spreadsheets",
                "https://www.googleapis.com/auth/drive"
            ]
        )
        gc = gspread.authorize(credentials)
        
        sheet_name = st.secrets.get("google_sheets", {}).get("sheet_name", "chatbot_ë¡œê·¸")
        
        try:
            sheet = gc.open(sheet_name)
        except gspread.SpreadsheetNotFound:
            sheet = gc.create(sheet_name)
            _init_worksheets(sheet)
        
        print("âœ… Google Sheets ì—°ë™ ì„±ê³µ")
        return sheet
    except Exception as e:
        print(f"âš ï¸ Google Sheets ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
        return None


def _init_worksheets(sheet):
    """ì›Œí¬ì‹œíŠ¸ ì´ˆê¸°í™”"""
    try:
        # ëŒ€í™” ë¡œê·¸ ì‹œíŠ¸
        try:
            chat_sheet = sheet.worksheet("chat_logs")
        except:
            chat_sheet = sheet.add_worksheet("chat_logs", 1000, 10)
            chat_sheet.append_row([
                "timestamp", "session_id", "user_question", "bot_response", 
                "response_type", "response_time", "page_context"
            ])
        
        # ë‹µë³€ ì‹¤íŒ¨ ë¡œê·¸ ì‹œíŠ¸
        try:
            failed_sheet = sheet.worksheet("failed_responses")
        except:
            failed_sheet = sheet.add_worksheet("failed_responses", 1000, 5)
            failed_sheet.append_row([
                "timestamp", "session_id", "user_question", 
                "attempted_response", "failure_reason"
            ])
        
        # ì¼ì¼ í†µê³„ ì‹œíŠ¸
        try:
            stats_sheet = sheet.worksheet("daily_stats")
        except:
            stats_sheet = sheet.add_worksheet("daily_stats", 1000, 6)
            stats_sheet.append_row([
                "date", "session_id", "first_visit", "last_visit", "total_questions"
            ])
    except Exception as e:
        print(f"âš ï¸ ì›Œí¬ì‹œíŠ¸ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")


def log_to_sheets(session_id, user_question, bot_response, response_type, response_time=0.0, page_context=""):
    """Google Sheetsì— ë¡œê·¸ ì €ì¥"""
    sheet = st.session_state.get('google_sheet')
    if not sheet:
        return
    
    try:
        chat_sheet = sheet.worksheet("chat_logs")
        stats_sheet = sheet.worksheet("daily_stats")
        
        # ëŒ€í™” ë¡œê·¸ ì¶”ê°€
        chat_sheet.append_row([
            datetime.now().isoformat(),
            session_id,
            user_question[:500],
            bot_response[:500],
            response_type,
            response_time,
            page_context
        ])
        
        # ì¼ì¼ í†µê³„ ì—…ë°ì´íŠ¸
        today = datetime.now().date().isoformat()
        stats = stats_sheet.get_all_records()
        
        session_row = None
        for idx, row in enumerate(stats, start=2):
            if row.get('date') == today and row.get('session_id') == session_id:
                session_row = idx
                break
        
        if session_row:
            current_count = stats_sheet.cell(session_row, 5).value
            stats_sheet.update_cell(session_row, 4, datetime.now().isoformat())
            stats_sheet.update_cell(session_row, 5, int(current_count or 0) + 1)
        else:
            stats_sheet.append_row([
                today,
                session_id,
                datetime.now().isoformat(),
                datetime.now().isoformat(),
                1
            ])
    except Exception as e:
        print(f"âš ï¸ ë¡œê¹… ì‹¤íŒ¨: {e}")


def log_failed_to_sheets(session_id, user_question, attempted_response, failure_reason):
    """ë‹µë³€ ì‹¤íŒ¨ ë¡œê·¸ ì €ì¥"""
    sheet = st.session_state.get('google_sheet')
    if not sheet:
        return
    
    try:
        failed_sheet = sheet.worksheet("failed_responses")
        failed_sheet.append_row([
            datetime.now().isoformat(),
            session_id,
            user_question[:500],
            attempted_response[:500],
            failure_reason
        ])
    except Exception as e:
        print(f"âš ï¸ ì‹¤íŒ¨ ë¡œê·¸ ì €ì¥ ì‹¤íŒ¨: {e}")


# í˜ì´ì§€ ì„¤ì •
st.set_page_config(
    page_title="ë‹¤ì „ê³µ ì•ˆë‚´ ì±—ë´‡",
    page_icon="ğŸ“",
    layout="wide",
    initial_sidebar_state="expanded",
    menu_items={
        'Get help': 'https://www.hknu.ac.kr',
        'Report a bug': 'https://www.hknu.ac.kr',
        'About': "# í•œê²½êµ­ë¦½ëŒ€ ë‹¤ì „ê³µ ì•ˆë‚´ AIê¸°ë°˜ ì±—ë´‡"
    }
)

# CSS ìŠ¤íƒ€ì¼
hide_streamlit_style = """
<style>
    [data-testid="stDecoration"] { display: none !important; }
    footer { display: none !important; }
    .main .block-container { padding-top: 2rem !important; }
</style>
"""
st.markdown(hide_streamlit_style, unsafe_allow_html=True)


def scroll_to_bottom():
    js = """
    <script>
        setTimeout(function() {
            var messages = window.parent.document.querySelectorAll('[data-testid="stChatMessage"]');
            if (messages.length > 0) {
                messages[messages.length - 1].scrollIntoView({behavior: "smooth", block: "end"});
            }
        }, 300);
    </script>
    """
    st.components.v1.html(js, height=0)


def initialize_session_state():
    if 'chat_history' not in st.session_state:
        st.session_state.chat_history = []
    if 'page' not in st.session_state:
        st.session_state.page = "AIì±—ë´‡ ìƒë‹´"
    
    # ì„¸ì…˜ ID ìƒì„±
    if 'session_id' not in st.session_state:
        timestamp = datetime.now().isoformat()
        st.session_state.session_id = hashlib.md5(timestamp.encode()).hexdigest()[:16]
    
    # Google Sheets ì´ˆê¸°í™”
    if 'google_sheet' not in st.session_state:
        st.session_state.google_sheet = init_google_sheets()


# ============================================================
# ğŸ“‚ ë°ì´í„° ë¡œë“œ
# ============================================================

@st.cache_data
def load_excel_data(file_path, sheet_name=0):
    try:
        if os.path.exists(file_path):
            result = pd.read_excel(file_path, sheet_name=sheet_name)
            if isinstance(result, dict):
                return list(result.values())[0] if result else pd.DataFrame()
            return result
        return pd.DataFrame()
    except Exception as e:
        return pd.DataFrame()


@st.cache_data
def load_program_info():
    df = load_excel_data('data/programs.xlsx')
    if not isinstance(df, pd.DataFrame) or df.empty:
        return {}
    programs = {}
    for _, row in df.iterrows():
        name = row.get('ì œë„ëª…', '')
        if name and pd.notna(name):
            def safe_get(key, default=''):
                val = row.get(key, default)
                return default if pd.isna(val) else val
            
            programs[name] = {
                'description': safe_get('ì„¤ëª…', ''),
                'qualification': safe_get('ì‹ ì²­ìê²©', ''),
                'credits_general': safe_get('ì´ìˆ˜í•™ì (êµì–‘)', ''),
                'credits_primary': safe_get('ì›ì „ê³µ ì´ìˆ˜í•™ì ', ''),
                'credits_multi': safe_get('ë‹¤ì „ê³µ ì´ìˆ˜í•™ì ', ''),
                'degree': safe_get('í•™ìœ„ê¸° í‘œê¸°', '-'),
                'features': str(safe_get('íŠ¹ì§•', '')).split('\n') if safe_get('íŠ¹ì§•', '') else [],
                'notes': safe_get('ê¸°íƒ€', ''),
                'difficulty': convert_difficulty_to_stars(safe_get('ë‚œì´ë„', '3')),
                'graduation_certification': safe_get('ì¡¸ì—…ì¸ì¦', '-'),
                'graduation_exam': safe_get('ì¡¸ì—…ì‹œí—˜', '-'),
            }
    return programs


@st.cache_data
def load_curriculum_mapping():
    try:
        if os.path.exists('data/curriculum_mapping.xlsx'):
            return pd.read_excel('data/curriculum_mapping.xlsx')
        return pd.DataFrame(columns=['ì „ê³µëª…', 'ì œë„ìœ í˜•', 'íŒŒì¼ëª…'])
    except:
        return pd.DataFrame(columns=['ì „ê³µëª…', 'ì œë„ìœ í˜•', 'íŒŒì¼ëª…'])


@st.cache_data
def load_courses_data():
    try:
        if os.path.exists('data/courses.xlsx'):
            return pd.read_excel('data/courses.xlsx')
        return pd.DataFrame(columns=['ì „ê³µëª…', 'ì œë„ìœ í˜•', 'í•™ë…„', 'í•™ê¸°', 'ì´ìˆ˜êµ¬ë¶„', 'ê³¼ëª©ëª…', 'í•™ì '])
    except:
        return pd.DataFrame(columns=['ì „ê³µëª…', 'ì œë„ìœ í˜•', 'í•™ë…„', 'í•™ê¸°', 'ì´ìˆ˜êµ¬ë¶„', 'ê³¼ëª©ëª…', 'í•™ì '])


@st.cache_data
def load_faq_mapping():
    """faq_mapping.xlsx ë¡œë“œ"""
    df = load_excel_data('data/faq_mapping.xlsx')
    if df.empty:
        return pd.DataFrame()
    # í•„ìš”í•œ ì»¬ëŸ¼ë§Œ ì„ íƒí•˜ê³  NaN ì œê±°
    required_cols = ['faq_id', 'intent', 'program', 'keyword', 'answer']
    if all(col in df.columns for col in required_cols):
        return df[required_cols].dropna(subset=['answer'])
    return pd.DataFrame()


@st.cache_data
def load_majors_info():
    """ì „ê³µ ì •ë³´ ë¡œë“œ (ë³µìˆ˜ì „ê³µ, ë¶€ì „ê³µ ë“± ì¼ë°˜ ì „ê³µ)"""
    return load_excel_data('data/majors_info.xlsx')


@st.cache_data
def load_microdegree_info():
    """ë§ˆì´í¬ë¡œë””ê·¸ë¦¬(ì†Œë‹¨ìœ„ì „ê³µê³¼ì •) ì •ë³´ ë¡œë“œ - ê³¼ì • ì¤‘ì‹¬"""
    return load_excel_data('data/microdegree_info.xlsx')


@st.cache_data
def load_graduation_requirements():
    return load_excel_data('data/graduation_requirements.xlsx')


@st.cache_data
def load_primary_requirements():
    return load_excel_data('data/primary_requirements.xlsx')


# ë°ì´í„° ë¡œë“œ
PROGRAM_INFO = load_program_info()
CURRICULUM_MAPPING = load_curriculum_mapping()
COURSES_DATA = load_courses_data()
FAQ_MAPPING = load_faq_mapping()
MAJORS_INFO = load_majors_info()
MICRODEGREE_INFO = load_microdegree_info()
GRADUATION_REQ = load_graduation_requirements()
PRIMARY_REQ = load_primary_requirements()

ALL_DATA = {
    'programs': PROGRAM_INFO,
    'curriculum': CURRICULUM_MAPPING,
    'courses': COURSES_DATA,
    'faq_mapping': FAQ_MAPPING,
    'majors': MAJORS_INFO,
    'microdegree': MICRODEGREE_INFO,
    'grad_req': GRADUATION_REQ,
    'primary_req': PRIMARY_REQ,
}


# ============================================================
# ğŸ“Œ í”„ë¡œê·¸ë¨ í‚¤ì›Œë“œ ë° ì¸í…íŠ¸ ì •ì˜
# ============================================================

PROGRAM_KEYWORDS = {
    'ë³µìˆ˜ì „ê³µ': ['ë³µìˆ˜ì „ê³µ', 'ë³µì „', 'ë³µìˆ˜'],
    'ë¶€ì „ê³µ': ['ë¶€ì „ê³µ', 'ë¶€ì „'],
    'ìœµí•©ì „ê³µ': ['ìœµí•©ì „ê³µ', 'ìœµí•©'],
    'ìœµí•©ë¶€ì „ê³µ': ['ìœµí•©ë¶€ì „ê³µ'],
    'ì—°ê³„ì „ê³µ': ['ì—°ê³„ì „ê³µ', 'ì—°ê³„'],
    'ì†Œë‹¨ìœ„ì „ê³µê³¼ì •': ['ì†Œë‹¨ìœ„ì „ê³µê³¼ì •', 'ì†Œë‹¨ìœ„ì „ê³µ', 'ì†Œë‹¨ìœ„'],
    'ë§ˆì´í¬ë¡œë””ê·¸ë¦¬': ['ë§ˆì´í¬ë¡œë””ê·¸ë¦¬', 'ë§ˆì´í¬ë¡œ', 'md', 'ë§ˆë””'],
}

def find_matching_majors(query_text, majors_df, microdegree_df):
    print("\n" + "="*60)
    print("ğŸ” ë°˜ë„ì²´ ê´€ë ¨ ì „ê³µ í™•ì¸")
    print("="*60)
    if not MAJORS_INFO.empty and 'ì „ê³µëª…' in MAJORS_INFO.columns:
        semiconductor = MAJORS_INFO[MAJORS_INFO['ì „ê³µëª…'].str.contains('ë°˜ë„ì²´', na=False)]
        print(f"ë°˜ë„ì²´ í¬í•¨ ì „ê³µ: {len(semiconductor)}ê°œ")
        for idx, row in semiconductor.iterrows():
            print(f"  - {row['ì „ê³µëª…']}")
    else:
        print("MAJORS_INFOê°€ ë¹„ì–´ìˆê±°ë‚˜ 'ì „ê³µëª…' ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤!")
    print("="*60 + "\n")

    print(f"\n[DEBUG find_matching_majors] ì…ë ¥: {query_text}")
    
    query_clean = query_text.replace(' ', '').lower()
    print(f"[DEBUG] query_clean: {query_clean}")
    
    exact_matches = []
    partial_matches = []
    
    # 1. ì¼ë°˜ì „ê³µì—ì„œ ê²€ìƒ‰
    if not majors_df.empty and 'ì „ê³µëª…' in majors_df.columns:
        print(f"[DEBUG] ì¼ë°˜ì „ê³µ ê²€ìƒ‰ ì‹œì‘ ({len(majors_df)}ê°œ)")
        for idx, row in majors_df.iterrows():
            major_name = str(row.get('ì „ê³µëª…', ''))
            major_clean = major_name.replace(' ', '').lower()
            
            # ğŸ”¥ ê´„í˜¸ ì œê±°: ì •ê·œì‹ ì‚¬ìš©
            import re
            major_no_paren = re.sub(r'[(\(].*?[)\)]', '', major_clean)
            query_no_paren = re.sub(r'[(\(].*?[)\)]', '', query_clean)
            
            # ë””ë²„ê¹… ì¶œë ¥
            if 'aië°˜ë„ì²´' in major_clean or 'ë°˜ë„ì²´ìœµí•©' in major_clean:
                print(f"[DEBUG]   ê²€ì‚¬: {major_name}")
                print(f"[DEBUG]     major_clean: {major_clean}")
                print(f"[DEBUG]     major_no_paren: {major_no_paren}")
                print(f"[DEBUG]     query_clean: {query_clean}")
                print(f"[DEBUG]     query_no_paren: {query_no_paren}")

            # ì •í™• ë§¤ì¹­ (ì›ë³¸)
            if major_clean == query_clean:
                print(f"[DEBUG]   âœ… ì •í™• ë§¤ì¹­: {major_name}")
                candidate = {
                    'name': major_name,
                    'type': 'major',
                    'program_type': row.get('ì œë„ìœ í˜•', ''),
                    'category': row.get('ê³„ì—´', ''),
                    'department': row.get('ì†Œì†í•™ë¶€', ''),
                    'match_score': len(major_clean),
                    'exact_match': True
                }
                exact_matches.append(candidate)
            
            # ğŸ”¥ ì •í™• ë§¤ì¹­ (ê´„í˜¸ë¬´ì‹œ)
            elif major_no_paren and major_no_paren == query_no_paren:
                print(f"[DEBUG]   âœ… ì •í™• ë§¤ì¹­(ê´„í˜¸ë¬´ì‹œ): {major_name}")
                candidate = {
                    'name': major_name,
                    'type': 'major',
                    'program_type': row.get('ì œë„ìœ í˜•', ''),
                    'category': row.get('ê³„ì—´', ''),
                    'department': row.get('ì†Œì†í•™ë¶€', ''),
                    'match_score': len(major_no_paren),
                    'exact_match': True
                }
                exact_matches.append(candidate)

            # ë¶€ë¶„ ë§¤ì¹­ (ì›ë³¸)
            elif major_clean and len(major_clean) > 2 and major_clean in query_clean:
                print(f"[DEBUG]   ë¶€ë¶„ ë§¤ì¹­: {major_name}")
                candidate = {
                    'name': major_name,
                    'type': 'major',
                    'program_type': row.get('ì œë„ìœ í˜•', ''),
                    'category': row.get('ê³„ì—´', ''),
                    'department': row.get('ì†Œì†í•™ë¶€', ''),
                    'match_score': len(major_clean),
                    'exact_match': False
                }
                partial_matches.append(candidate)

            # ğŸ”¥ ë¶€ë¶„ ë§¤ì¹­ (ê´„í˜¸ë¬´ì‹œ)
            elif major_no_paren and len(major_no_paren) > 2 and major_no_paren in query_no_paren:
                print(f"[DEBUG]   ë¶€ë¶„ ë§¤ì¹­(ê´„í˜¸ë¬´ì‹œ): {major_name}")
                candidate = {
                    'name': major_name,
                    'type': 'major',
                    'program_type': row.get('ì œë„ìœ í˜•', ''),
                    'category': row.get('ê³„ì—´', ''),
                    'department': row.get('ì†Œì†í•™ë¶€', ''),
                    'match_score': len(major_no_paren),
                    'exact_match': False
                }
                partial_matches.append(candidate)

            # ğŸ”¥ ë¶€ë¶„ ë§¤ì¹­ (ê´„í˜¸ë¬´ì‹œ) - candidate ìƒˆë¡œ ì •ì˜!
            elif major_no_paren and len(major_no_paren) > 2 and major_no_paren in query_no_paren:
                print(f"[DEBUG]   ë¶€ë¶„ ë§¤ì¹­(ê´„í˜¸ë¬´ì‹œ): {major_name}")
                candidate = {
                    'name': major_name,
                    'type': 'major',
                    'program_type': row.get('ì œë„ìœ í˜•', ''),
                    'category': row.get('ê³„ì—´', ''),
                    'department': row.get('ì†Œì†í•™ë¶€', ''),
                    'match_score': len(major_no_paren),
                    'exact_match': False
                }
                partial_matches.append(candidate)
    
    # 2. ë§ˆì´í¬ë¡œë””ê·¸ë¦¬ì—ì„œ ê²€ìƒ‰
    if not microdegree_df.empty and 'ê³¼ì •ëª…' in microdegree_df.columns:
        print(f"[DEBUG] ë§ˆì´í¬ë¡œë””ê·¸ë¦¬ ê²€ìƒ‰ ì‹œì‘ ({len(microdegree_df)}ê°œ)")
        for idx, row in microdegree_df.iterrows():
            course_name = str(row.get('ê³¼ì •ëª…', ''))
            course_clean = course_name.replace(' ', '').lower()
            
            print(f"[DEBUG]   ê³¼ì •ëª…: {course_name} â†’ clean: {course_clean}")
            
            # ì •í™•í•œ ë§¤ì¹­
            if course_clean == query_clean:
                print(f"[DEBUG]   âœ… ë§ˆì´í¬ë¡œ ì •í™• ë§¤ì¹­: {course_name}")
                candidate = {
                    'name': course_name,
                    'type': 'microdegree',
                    'program_type': 'ì†Œë‹¨ìœ„ì „ê³µê³¼ì •',
                    'category': row.get('ê³„ì—´', ''),
                    'department': row.get('êµìœ¡ìš´ì˜ì „ê³µ', ''),
                    'match_score': len(course_clean),
                    'exact_match': True
                }
                exact_matches.append(candidate)
            # ì „ì²´ ê³¼ì •ëª… í¬í•¨
            elif course_clean and course_clean in query_clean:
                print(f"[DEBUG]   ë§ˆì´í¬ë¡œ ë¶€ë¶„ ë§¤ì¹­: {course_name}")
                candidate = {
                    'name': course_name,
                    'type': 'microdegree',
                    'program_type': 'ì†Œë‹¨ìœ„ì „ê³µê³¼ì •',
                    'category': row.get('ê³„ì—´', ''),
                    'department': row.get('êµìœ¡ìš´ì˜ì „ê³µ', ''),
                    'match_score': len(course_clean),
                    'exact_match': False
                }
                partial_matches.append(candidate)
            # MD ì œê±° í›„ í‚¤ì›Œë“œ ë§¤ì¹­
            else:
                keyword = course_clean.replace('md', '').strip()
                if keyword and len(keyword) >= 2 and keyword in query_clean:
                    print(f"[DEBUG]   ë§ˆì´í¬ë¡œ í‚¤ì›Œë“œ ë§¤ì¹­: {course_name} (í‚¤ì›Œë“œ: {keyword})")
                    candidate = {
                        'name': course_name,
                        'type': 'microdegree',
                        'program_type': 'ì†Œë‹¨ìœ„ì „ê³µê³¼ì •',
                        'category': row.get('ê³„ì—´', ''),
                        'department': row.get('êµìœ¡ìš´ì˜ì „ê³µ', ''),
                        'match_score': len(keyword),
                        'exact_match': False
                    }
                    partial_matches.append(candidate)
    else:
        print(f"[DEBUG] âŒ ë§ˆì´í¬ë¡œë””ê·¸ë¦¬ ë°ì´í„° ì—†ìŒ ë˜ëŠ” 'ê³¼ì •ëª…' ì»¬ëŸ¼ ì—†ìŒ")
    
    # 3. ì •í™•í•œ ë§¤ì¹­ ìš°ì„ 
    if exact_matches:
        candidates = exact_matches
        print(f"[DEBUG] ì •í™• ë§¤ì¹­ ì‚¬ìš©: {len(exact_matches)}ê°œ")
    else:
        candidates = partial_matches
        print(f"[DEBUG] ë¶€ë¶„ ë§¤ì¹­ ì‚¬ìš©: {len(partial_matches)}ê°œ")
    
    # 4. ë¶€ë¶„ ë¬¸ìì—´ ì¤‘ë³µ ì œê±°
    if len(candidates) > 1:
        print(f"[DEBUG] ë¶€ë¶„ ë¬¸ìì—´ ì¤‘ë³µ ì²´í¬ ì‹œì‘")
        filtered_candidates = []
        
        # ê¸¸ì´ ìˆœìœ¼ë¡œ ì •ë ¬ (ê¸´ ê²ƒë¶€í„°)
        candidates_sorted = sorted(candidates, key=lambda x: len(x['name']), reverse=True)
        
        for i, cand in enumerate(candidates_sorted):
            cand_clean = cand['name'].replace(' ', '').lower()
            
            # ì´ í›„ë³´ë³´ë‹¤ ê¸´ í›„ë³´ ì¤‘ì— ì´ í›„ë³´ë¥¼ í¬í•¨í•˜ëŠ” ê²Œ ìˆëŠ”ì§€ í™•ì¸
            is_substring = False
            for j in range(i):
                longer_cand_clean = candidates_sorted[j]['name'].replace(' ', '').lower()
                if cand_clean in longer_cand_clean and cand_clean != longer_cand_clean:
                    is_substring = True
                    print(f"[DEBUG]   '{cand['name']}'ì€(ëŠ”) '{candidates_sorted[j]['name']}'ì˜ ë¶€ë¶„ ë¬¸ìì—´ â†’ ì œì™¸")
                    break
            
            if not is_substring:
                filtered_candidates.append(cand)
        
        candidates = filtered_candidates
        print(f"[DEBUG] ë¶€ë¶„ ë¬¸ìì—´ ì œê±° í›„: {len(candidates)}ê°œ")
    
    # 5. ì ìˆ˜ ìˆœìœ¼ë¡œ ì •ë ¬
    candidates.sort(key=lambda x: (x['match_score'], len(x['name'])), reverse=True)
    
    # 6. ì¤‘ë³µ ì œê±° (ì´ë¦„ ê¸°ì¤€)
    unique_candidates = []
    seen_names = set()
    for cand in candidates:
        if cand['name'] not in seen_names:
            unique_candidates.append(cand)
            seen_names.add(cand['name'])
    
    needs_filtering = len(unique_candidates) > 1
    
    print(f"[DEBUG] ìµœì¢… í›„ë³´: {len(unique_candidates)}ê°œ, í•„í„°ë§ í•„ìš”: {needs_filtering}")
    
    return unique_candidates, needs_filtering

def check_microdegree_data():
    """ë§ˆì´í¬ë¡œë””ê·¸ë¦¬ ë°ì´í„° í™•ì¸"""
    global MICRODEGREE_INFO
    
    print("\n" + "="*60)
    print("ğŸ” ë§ˆì´í¬ë¡œë””ê·¸ë¦¬ ë°ì´í„° ì²´í¬")
    print("="*60)
    
    if 'MICRODEGREE_INFO' not in globals():
        print("âŒ MICRODEGREE_INFO ì „ì—­ ë³€ìˆ˜ê°€ ì—†ìŠµë‹ˆë‹¤!")
        return
    
    if MICRODEGREE_INFO.empty:
        print("âŒ MICRODEGREE_INFOê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤!")
        print("ì›ì¸: load_microdegree_info() í•¨ìˆ˜ í™•ì¸ í•„ìš”")
        return
    
    print(f"âœ… MICRODEGREE_INFO: {len(MICRODEGREE_INFO)}ê°œ ê³¼ì •")
    print(f"\nì»¬ëŸ¼: {list(MICRODEGREE_INFO.columns)}")
    
    if 'ê³¼ì •ëª…' in MICRODEGREE_INFO.columns:
        print(f"\nê³¼ì •ëª… ëª©ë¡:")
        for idx, name in enumerate(MICRODEGREE_INFO['ê³¼ì •ëª…'].head(10), 1):
            print(f"  {idx}. {name}")
    else:
        print("âŒ 'ê³¼ì •ëª…' ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤!")
    
    print("="*60)

def apply_major_filters(candidates, query_text, detected_program=None):
    """ì œë„ìœ í˜• ë° ì†Œì†í•™ë¶€ í•„í„° ì ìš©"""
    if len(candidates) <= 1:
        return candidates
    
    query_clean = query_text.replace(' ', '').lower()
    filtered = candidates.copy()
    
    # 1. ì œë„ìœ í˜• í•„í„°
    if detected_program:
        program_filtered = [c for c in filtered if detected_program in c.get('program_type', '')]
        if program_filtered:
            filtered = program_filtered
    
    # 2. ìœµí•©ì „ê³µ vs ì¼ë°˜ì „ê³µ êµ¬ë¶„
    if len(filtered) > 1:
        has_convergence = any('ìœµí•©' in c.get('program_type', '') for c in filtered)
        has_regular = any('ë³µìˆ˜ì „ê³µ' in c.get('program_type', '') or 'ë¶€ì „ê³µ' in c.get('program_type', '') for c in filtered)
        
        if has_convergence and has_regular:
            if 'ìœµí•©' in query_clean:
                filtered = [c for c in filtered if 'ìœµí•©' in c.get('program_type', '')]
            else:
                filtered = [c for c in filtered if c.get('type') == 'major' and 'ìœµí•©' not in c.get('program_type', '')]
    
    # 3. ì†Œì†í•™ë¶€ í•„í„°
    if len(filtered) > 1:
        for candidate in filtered:
            dept = candidate.get('department', '')
            if dept and dept.replace(' ', '').lower() in query_clean:
                return [candidate]
            
    # 4. í•„í„°ë§ í›„ ë‹¤ì‹œ ì •ë ¬! (ì´ 2ì¤„ ì¶”ê°€)
    filtered.sort(key=lambda x: (x.get('match_score', 0), len(x.get('name', ''))), reverse=True)

    return filtered


def resolve_major_candidate(candidates, query_text):
    """ìµœì¢… í›„ë³´ í™•ì •"""
    if not candidates:
        return None, None
    
    if len(candidates) == 1:
        return candidates[0]['name'], candidates[0]['type']
    
    # ì—¬ëŸ¬ í›„ë³´: ì²« ë²ˆì§¸ ë°˜í™˜
    return candidates[0]['name'], candidates[0]['type']

# ============================================================
# ğŸ” [ì‹ ê·œ] ì—”í‹°í‹° ì¶”ì¶œ ì‹œìŠ¤í…œ
# ============================================================

def extract_entity_from_text(text):
    """
    [ë””ë²„ê¹… ë²„ì „] í…ìŠ¤íŠ¸ì—ì„œ ì „ê³µ/ê³¼ì • ì—”í‹°í‹° ì¶”ì¶œ
    """
    print(f"\n[DEBUG extract_entity_from_text] ì…ë ¥: {text}")
    
    # MAJORS_INFO, MICRODEGREE_INFOê°€ ì „ì—­ ë³€ìˆ˜ë¡œ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸
    global MAJORS_INFO, MICRODEGREE_INFO
    
    if 'MAJORS_INFO' not in globals():
        print("[DEBUG] âŒ MAJORS_INFOê°€ ì •ì˜ë˜ì§€ ì•ŠìŒ!")
        return None, None
    
    if 'MICRODEGREE_INFO' not in globals():
        print("[DEBUG] âŒ MICRODEGREE_INFOê°€ ì •ì˜ë˜ì§€ ì•ŠìŒ!")
        return None, None
    
    print(f"[DEBUG] MAJORS_INFO: {len(MAJORS_INFO)}ê°œ")
    print(f"[DEBUG] MICRODEGREE_INFO: {len(MICRODEGREE_INFO)}ê°œ")
    
    # 1. ë§¤ì¹­ í›„ë³´ ì°¾ê¸°
    candidates, needs_filtering = find_matching_majors(text, MAJORS_INFO, MICRODEGREE_INFO)
    
    print(f"[DEBUG] í›„ë³´ ê°œìˆ˜: {len(candidates)}")
    for i, cand in enumerate(candidates):
        print(f"[DEBUG]   í›„ë³´ {i+1}: {cand['name']} (íƒ€ì…: {cand['type']}, ì ìˆ˜: {cand.get('match_score', 0)})")
    
    # 2. í•„í„°ë§ ë¶ˆí•„ìš”í•˜ë©´ ë°”ë¡œ ë°˜í™˜
    if not needs_filtering:
        if candidates:
            result = (candidates[0]['name'], candidates[0]['type'])
            print(f"[DEBUG] âœ… ê²°ê³¼ (í•„í„°ë§ ë¶ˆí•„ìš”): {result}")
            return result
        print(f"[DEBUG] âŒ í›„ë³´ ì—†ìŒ")
        return None, None
    
    # 3. í•„í„°ë§ ì ìš©
    detected_program = extract_program_from_text(text)
    print(f"[DEBUG] ê°ì§€ëœ ì œë„: {detected_program}")
    
    filtered_candidates = apply_major_filters(candidates, text, detected_program)
    
    print(f"[DEBUG] í•„í„°ë§ í›„ ê°œìˆ˜: {len(filtered_candidates)}")
    for i, cand in enumerate(filtered_candidates):
        print(f"[DEBUG]   í•„í„° í›„ {i+1}: {cand['name']} (íƒ€ì…: {cand['type']})")
    
    # 4. ìµœì¢… í›„ë³´ í™•ì •
    result = resolve_major_candidate(filtered_candidates, text)
    print(f"[DEBUG] âœ… ìµœì¢… ê²°ê³¼: {result}")
    return result

def detect_course_keywords(text):
    """[STEP 2] êµê³¼ëª© ê´€ë ¨ í‚¤ì›Œë“œ ê°ì§€"""
    text_clean = text.replace(' ', '').lower()
    course_keywords = ['êµê³¼ëª©', 'ê³¼ëª©', 'ì»¤ë¦¬í˜ëŸ¼', 'ìˆ˜ì—…', 'ê°•ì˜', 'ì´ìˆ˜ì²´ê³„ë„', 'êµìœ¡ê³¼ì •', 'ë­ë“¤ì–´', 'ë­ë°°ì›Œ']
    return any(kw in text_clean for kw in course_keywords)


def detect_list_keywords(text):
    """[STEP 3-1] ëª©ë¡ ìš”ì²­ í‚¤ì›Œë“œ ê°ì§€"""
    text_clean = text.replace(' ', '').lower()
    list_keywords = ['ëª©ë¡', 'ë¦¬ìŠ¤íŠ¸', 'ì¢…ë¥˜', 'ì–´ë–¤ì „ê³µ', 'ì–´ë–¤ê³¼ì •', 'ë¬´ìŠ¨ì „ê³µ', 'ë¬´ìŠ¨ê³¼ì •', 'ë­ê°€ìˆì–´', 'ë­ìˆì–´']
    return any(kw in text_clean for kw in list_keywords)

# Semantic Routerìš© ì¸í…íŠ¸ ë°œí™” ì˜ˆì‹œ
INTENT_UTTERANCES = {
    'APPLY_QUALIFICATION': [
        "ì‹ ì²­ ìê²©ì´ ì–´ë–»ê²Œ ë˜ë‚˜ìš”?", "ì§€ì› ìê²© ì•Œë ¤ì£¼ì„¸ìš”", "ëˆ„ê°€ ì‹ ì²­í•  ìˆ˜ ìˆì–´ìš”?",
        "ìê²© ìš”ê±´ì´ ë­ì˜ˆìš”?", "ë‚˜ë„ ì‹ ì²­ ê°€ëŠ¥í•´?", "ëª‡ í•™ë…„ë¶€í„° í•  ìˆ˜ ìˆì–´ìš”?",
        "ì¡°ê±´ì´ ì–´ë–»ê²Œ ë¼?", "ì‹ ì²­ ì¡°ê±´ ì•Œë ¤ì¤˜", "ìê²©ì´ ë­ì•¼?",
    ],
    'APPLY_PERIOD': [
        "ì‹ ì²­ ê¸°ê°„ì´ ì–¸ì œì˜ˆìš”?", "ì–¸ì œ ì‹ ì²­í•´ìš”?", "ë§ˆê°ì¼ì´ ì–¸ì œì•¼?",
        "ì§€ì› ê¸°ê°„ ì•Œë ¤ì£¼ì„¸ìš”", "ì–¸ì œê¹Œì§€ ì‹ ì²­í•  ìˆ˜ ìˆì–´ìš”?", "ì ‘ìˆ˜ ê¸°ê°„ì´ ì–´ë–»ê²Œ ë¼?",
        "ëª‡ ì›”ì— ì‹ ì²­í•´?", "ê¸°ê°„ì€ ì–¸ì œì•¼?", "ê¸°ê°„ ì•Œë ¤ì¤˜",
    ],
    'APPLY_METHOD': [
        "ì‹ ì²­ ë°©ë²•ì´ ì–´ë–»ê²Œ ë˜ë‚˜ìš”?", "ì–´ë–»ê²Œ ì‹ ì²­í•´ìš”?", "ì‹ ì²­ ì ˆì°¨ ì•Œë ¤ì£¼ì„¸ìš”",
        "ì§€ì›í•˜ë ¤ë©´ ì–´ë–»ê²Œ í•´ì•¼ í•´?", "ì‹ ì²­í•˜ëŠ” ë²• ì•Œë ¤ì¤˜", "ì–´ë””ì„œ ì‹ ì²­í•´?",
        "ì ˆì°¨ê°€ ì–´ë–»ê²Œ ë¼?", "ë°©ë²• ì•Œë ¤ì¤˜",
    ],
    'APPLY_CANCEL': [
        "í¬ê¸°í•˜ê³  ì‹¶ì–´ìš”", "ì·¨ì†Œ ë°©ë²• ì•Œë ¤ì£¼ì„¸ìš”", "ì² íšŒí•˜ë ¤ë©´ ì–´ë–»ê²Œ í•´?",
        "ê·¸ë§Œë‘ê³  ì‹¶ì–´", "í¬ê¸° ì‹ ì²­ ì–´ë–»ê²Œ í•´?", "ì·¨ì†Œí•  ìˆ˜ ìˆì–´?",
    ],
    'APPLY_CHANGE': [
        "ë³€ê²½í•˜ê³  ì‹¶ì–´ìš”", "ì „ê³µ ë°”ê¾¸ê³  ì‹¶ì–´", "ìˆ˜ì •í•  ìˆ˜ ìˆë‚˜ìš”?",
        "ì „í™˜í•˜ë ¤ë©´ ì–´ë–»ê²Œ í•´?", "ë³€ê²½ ê°€ëŠ¥í•œê°€ìš”?",
    ],
    'PROGRAM_COMPARISON': [
        "ë³µìˆ˜ì „ê³µì´ë‘ ë¶€ì „ê³µ ì°¨ì´ê°€ ë­ì•¼?", "ë­ê°€ ë‹¤ë¥¸ ê±°ì•¼?", "ì°¨ì´ì  ì•Œë ¤ì¤˜",
        "ë¹„êµí•´ì¤˜", "ë­ê°€ ë” ì¢‹ì•„?", "ì–´ë–¤ ê²Œ ë‚˜ì„ê¹Œ?",
    ],
    'PROGRAM_INFO': [
        "ë³µìˆ˜ì „ê³µì´ ë­ì•¼?", "ë¶€ì „ê³µì´ ë­”ê°€ìš”?", "ìœµí•©ì „ê³µ ì„¤ëª…í•´ì¤˜",
        "ë§ˆì´í¬ë¡œë””ê·¸ë¦¬ê°€ ë­ì˜ˆìš”?", "ë‹¤ì „ê³µì´ ë­ì•¼?", "ë‹¤ì „ê³µ ì œë„ê°€ ë­ì•¼?",
    ],
    'CREDIT_INFO': [
        "í•™ì ì´ ëª‡ í•™ì ì´ì•¼?", "ì´ìˆ˜í•™ì  ì•Œë ¤ì¤˜", "ì¡¸ì—…í•˜ë ¤ë©´ ëª‡ í•™ì  í•„ìš”í•´?",
        "ì „í•„ ëª‡ í•™ì ì´ì•¼?", "í•„ìš”í•œ í•™ì  ìˆ˜",
    ],
    'PROGRAM_TUITION': [
        "ë“±ë¡ê¸ˆì´ ì¶”ê°€ë˜ë‚˜ìš”?", "ìˆ˜ê°•ë£Œ ë” ë‚´ì•¼ í•´?", "í•™ë¹„ê°€ ì˜¬ë¼ê°€?",
        "ì¶”ê°€ ë“±ë¡ê¸ˆ ìˆì–´?", "ì¥í•™ê¸ˆ ë°›ì„ ìˆ˜ ìˆì–´?",
    ],
    'COURSE_SEARCH': [
        "ì–´ë–¤ ê³¼ëª© ë“¤ì–´ì•¼ í•´?", "ì»¤ë¦¬í˜ëŸ¼ ì•Œë ¤ì¤˜", "ìˆ˜ì—… ë­ ë“¤ì–´?",
        "ê³¼ëª© ë¦¬ìŠ¤íŠ¸ ë³´ì—¬ì¤˜", "êµê³¼ëª© ì•Œë ¤ì¤˜",
    ],
    'CONTACT_SEARCH': [
        "ì—°ë½ì²˜ ì•Œë ¤ì¤˜", "ì „í™”ë²ˆí˜¸ê°€ ë­ì•¼?", "ë¬¸ì˜ ì–´ë””ë¡œ í•´?",
        "ì‚¬ë¬´ì‹¤ ì–´ë””ì•¼?", "ë‹´ë‹¹ì ì—°ë½ì²˜",
    ],
    'MAJOR_SEARCH': [ 
        "ë§ˆì´í¬ë¡œë””ê·¸ë¦¬ ì „ê³µ ëª©ë¡", "ë§ˆì´í¬ë¡œë””ê·¸ë¦¬ ì „ê³µ ë¦¬ìŠ¤íŠ¸ ì•Œë ¤ì¤˜", "ì†Œë‹¨ìœ„ì „ê³µê³¼ì • ì „ê³µ ë¦¬ìŠ¤íŠ¸",
    ],
    'MAJOR_INFO': [
        "ê²½ì˜í•™ì „ê³µ ì•Œë ¤ì¤˜", "ê²½ì˜í•™ì „ê³µì´ ë­ì•¼?", "ê²½ì˜í•™ê³¼ ì„¤ëª…í•´ì¤˜",
        "ì†Œí”„íŠ¸ì›¨ì–´ìœµí•©ì „ê³µ ì†Œê°œ", "ì†Œí”„íŠ¸ì›¨ì–´ìœµí•©ì „ê³µ ì–´ë–¤ ì „ê³µì´ì•¼?", "ì†Œí”„íŠ¸ì›¨ì–´ìœµí•©ì „ê³µì€ ì–´ë–¤ ê³³ì´ì•¼?",
        "ê¸°ê³„ê³µí•™ì „ê³µ ì–´ë•Œ?", "ê¸°ê³„ê³µí•™ì „ê³µ ì •ë³´", "ê¸°ê³„ê³µí•™ì „ê³µ ì•Œë ¤ì¤˜",
        "ì „ìê³µí•™ì „ê³µ ì†Œê°œ", "ì „ìê³µí•™ì „ê³µì´ê°€ ë­ì•¼?", "ì „ìê³µí•™ì „ê³µ ì„¤ëª…",
        "ê±´ì¶•í•™ì „ê³µ ì•Œë ¤ì¤˜", "ê±´ì¶•í•™ì „ê³µì´ ë­ì•¼?", "ê±´ì¶•í•™ì „ê³µ ì†Œê°œ",
        "ê²½ì˜í•™ì „ê³µ ì•Œë ¤ì¤˜", "ê²½ì˜í•™ì „ê³µì´ ë­ì•¼?", "ê²½ì˜í•™ì „ê³µ ì†Œê°œ",
        "ì‘ìš©ìƒëª…ê³¼í•™ì „ê³µ ì–´ë•Œ?", "ì‘ìš©ìƒëª…ê³¼í•™ì „ê³µ ì •ë³´", "ì‘ìš©ìƒëª…ê³¼í•™ì „ê³µ ì„¤ëª…",
        "í™”í•™ê³µí•™ì „ê³µ ì•Œë ¤ì¤˜", "í™”í•™ê³µí•™ì „ê³µì´ ë­ì•¼?", "í™”í•™ê³µí•™ ì†Œê°œ",
        "ë²•í•™ì „ê³µ ì •ë³´", "ë²•í•™ì „ê³µ ì•Œë ¤ì¤˜", "ë²•í•™ì „ê³µì€ ì–´ë–¤ ê³³ì´ì•¼?",
    ],
    'RECOMMENDATION': [
        "ë­ê°€ ì¢‹ì„ê¹Œ?", "ì¶”ì²œí•´ì¤˜", "ì–´ë–¤ ê²Œ ì¢‹ì•„?", "ë‚˜í•œí…Œ ë§ëŠ” ê±° ë­ì•¼?",
        "ë­ í•´ì•¼ í• ê¹Œ?", "ì„ íƒ ë„ì™€ì¤˜",
    ],
    'GREETING': [
        "ì•ˆë…•", "ì•ˆë…•í•˜ì„¸ìš”", "í•˜ì´", "hello", "hi", "ë°˜ê°€ì›Œ",
    ],
}

BLOCKED_KEYWORDS = ['ì‹œë°œ', 'ì”¨ë°œ', 'ã……ã…‚', 'ë³‘ì‹ ', 'ã…‚ã……', 'ì§€ë„', 'ã…ˆã„¹', 'ê°œìƒˆë¼', 'êº¼ì ¸', 'ë‹¥ì³', 'ì£½ì–´', 'ë¯¸ì¹œ', 'ì¡´ë‚˜', 'fuck']


# ============================================================
# ğŸ§  Semantic Router ì´ˆê¸°í™”
# ============================================================

@st.cache_resource
def initialize_semantic_router():
    if not SEMANTIC_ROUTER_AVAILABLE or not SEMANTIC_ROUTER_ENABLED:
        return None
    if Route is None or SemanticRouter is None or GoogleEncoder is None:
        return None
    try:
        encoder = GoogleEncoder(
            name="models/text-embedding-004",
            api_key=st.secrets["GEMINI_API_KEY"]

        )
        routes = [Route(name=intent_name, utterances=utterances) 
                  for intent_name, utterances in INTENT_UTTERANCES.items()]
        if LocalIndex is not None:
            router = SemanticRouter(encoder=encoder, routes=routes, index=LocalIndex())
        else:
            router = SemanticRouter(encoder=encoder, routes=routes)
        return router
    except Exception as e:
        return None


SEMANTIC_ROUTER = initialize_semantic_router()

# ============================================================
# ğŸ” FAQ ë§¤ì¹­ ì‹œìŠ¤í…œ
# ============================================================

def extract_program_from_text(text):
    """í…ìŠ¤íŠ¸ì—ì„œ í”„ë¡œê·¸ë¨(ì œë„) ì¶”ì¶œ"""
    text_lower = text.lower().replace(' ', '')
    
    PROGRAM_KEYWORDS = {
        'ë³µìˆ˜ì „ê³µ': ['ë³µìˆ˜ì „ê³µ', 'ë³µì „', 'ë³µìˆ˜'],
        'ë¶€ì „ê³µ': ['ë¶€ì „ê³µ', 'ë¶€ì „'],
        'ìœµí•©ì „ê³µ': ['ìœµí•©ì „ê³µ', 'ìœµí•©'],
        'ìœµí•©ë¶€ì „ê³µ': ['ìœµí•©ë¶€ì „ê³µ'],
        'ì—°ê³„ì „ê³µ': ['ì—°ê³„ì „ê³µ', 'ì—°ê³„'],
        'ì†Œë‹¨ìœ„ì „ê³µê³¼ì •': ['ì†Œë‹¨ìœ„ì „ê³µê³¼ì •', 'ì†Œë‹¨ìœ„ì „ê³µ', 'ì†Œë‹¨ìœ„'],
        'ë§ˆì´í¬ë¡œë””ê·¸ë¦¬': ['ë§ˆì´í¬ë¡œë””ê·¸ë¦¬', 'ë§ˆì´í¬ë¡œ', 'md', 'ë§ˆë””'],
    }
    
    program_order = ['ì†Œë‹¨ìœ„ì „ê³µê³¼ì •', 'ë§ˆì´í¬ë¡œë””ê·¸ë¦¬', 'ìœµí•©ë¶€ì „ê³µ', 'ìœµí•©ì „ê³µ', 'ë³µìˆ˜ì „ê³µ', 'ë¶€ì „ê³µ', 'ì—°ê³„ì „ê³µ']
    
    for program in program_order:
        keywords = PROGRAM_KEYWORDS.get(program, [program])
        for kw in keywords:
            if kw.lower().replace(' ', '') in text_lower:
                return program
    
    if 'ë‹¤ì „ê³µ' in text_lower:
        return 'ë‹¤ì „ê³µ'
    
    return None

def needs_question_completion(user_input, intent, extracted_info, faq_result):
    """
    [ê°œì„ ] ì§ˆë¬¸ ë³´ì™„ì´ í•„ìš”í•œì§€ íŒë‹¨
    """
    user_clean = user_input.replace(' ', '').lower()
    
    # 1. ì œë„ í‚¤ì›Œë“œë§Œ ìˆê³  êµ¬ì²´ì  ì§ˆë¬¸ ì—†ìŒ (ì˜ˆ: "ë³µìˆ˜ì „ê³µ")
    program_only_keywords = ['ë³µìˆ˜ì „ê³µ', 'ë¶€ì „ê³µ', 'ìœµí•©ì „ê³µ', 'ë§ˆì´í¬ë¡œë””ê·¸ë¦¬', 'ì†Œë‹¨ìœ„ì „ê³µê³¼ì •']
    is_program_only = any(kw in user_clean for kw in program_only_keywords) and len(user_clean) < 15
    
    # 2. ë¦¬ìŠ¤íŠ¸/ëª©ë¡ ì§ˆë¬¸ì—ì„œ ëŒ€ìƒ ëˆ„ë½
    list_keywords = ['ëª©ë¡', 'ë¦¬ìŠ¤íŠ¸', 'ì¢…ë¥˜', 'ì–´ë–¤', 'ë¬´ìŠ¨', 'ë­ê°€ìˆì–´', 'ë­ìˆì–´']
    if any(kw in user_clean for kw in list_keywords):
        if not extracted_info.get('program'):
            return True, 'target_missing'
    
    # 3. ğŸ”¥ ì‹ ì²­ ê´€ë ¨ í‚¤ì›Œë“œë§Œ ìˆê³  ì œë„ íƒ€ì… ì—†ìŒ
    intent_only_keywords = {
        'ê¸°ê°„': ['ê¸°ê°„', 'ì–¸ì œ', 'ë§ˆê°', 'ì¼ì •'],
        'ìê²©': ['ìê²©', 'ì¡°ê±´', 'ëŒ€ìƒ'],
        'ë°©ë²•': ['ë°©ë²•', 'ì–´ë–»ê²Œ', 'ì ˆì°¨'],
        'í•™ì ': ['í•™ì ', 'ëª‡í•™ì ', 'ì´ìˆ˜'],
    }
    
    for category, keywords in intent_only_keywords.items():
        if any(kw in user_clean for kw in keywords):
            # ì‹ ì²­/ê¸°ê°„/ìê²©/ë°©ë²• ë“±ì˜ í‚¤ì›Œë“œëŠ” ìˆì§€ë§Œ ì œë„ë‚˜ ì „ê³µì´ ì—†ìŒ
            target = extracted_info.get('entity') or extracted_info.get('program')
            if not target:
                return True, 'target_missing'
    
    # 4. FAQ ë§¤í•‘ ê²°ê³¼ ë¶„ì„
    if faq_result:
        if isinstance(faq_result, list) and len(faq_result) > 1:
            return True, 'intent_missing'
    
    # 5. targetê³¼ intent ë¶„ì„
    target = extracted_info.get('entity') or extracted_info.get('major') or extracted_info.get('program')
    
    has_intent = False
    for category, keywords in intent_only_keywords.items():
        if any(kw in user_clean for kw in keywords):
            has_intent = True
            break
    
    # targetì€ ìˆëŠ”ë° intentê°€ ì—†ëŠ” ê²½ìš° (ì˜ˆ: "ê²½ì˜í•™ì „ê³µ ì•Œë ¤ì¤˜")
    if target and not has_intent and not is_program_only:
        # ì´ ê²½ìš°ëŠ” ì „ê³µ ì •ë³´ ìš”ì²­ì´ë¯€ë¡œ ë³´ì™„ ë¶ˆí•„ìš”
        return False, None
    
    # intentëŠ” ìˆëŠ”ë° targetì´ ì—†ëŠ” ê²½ìš° (ì˜ˆ: "ì‹ ì²­ ê¸°ê°„ì€?")
    if has_intent and not target:
        return True, 'target_missing'
    
    return False, None


def complete_question_with_ai(user_input, previous_question=None):
    """AIë¥¼ ì‚¬ìš©í•˜ì—¬ ì§ˆë¬¸ ë³´ì™„"""
    try:
        context = ""
        if previous_question:
            context = f"\n\n[ì´ì „ ì§ˆë¬¸]\n{previous_question}\n"
        
        prompt = f"""ë‹¹ì‹ ì€ ëŒ€í•™ ë‹¤ì „ê³µ ì•ˆë‚´ ì±—ë´‡ì…ë‹ˆë‹¤.
í•™ìƒì˜ ì§ˆë¬¸ì´ ë¶ˆì™„ì „í•  ë•Œ, ë¬¸ë§¥ì„ íŒŒì•…í•˜ì—¬ ì§ˆë¬¸ì„ ë³´ì™„í•´ì£¼ì„¸ìš”.

{context}
[í˜„ì¬ ì§ˆë¬¸]
{user_input}

[ì§€ì¹¨]
1. ì§ˆë¬¸ì—ì„œ ë¹ ì§„ ì •ë³´(ì „ê³µëª…, ì œë„ëª…, ì˜ë„)ë¥¼ íŒŒì•…í•˜ì„¸ìš”
2. ì´ì „ ì§ˆë¬¸ ë§¥ë½ì„ í™œìš©í•˜ì—¬ ë³´ì™„í•˜ì„¸ìš”
3. ë³´ì™„ëœ ì™„ì „í•œ ì§ˆë¬¸ì„ í•œ ë¬¸ì¥ìœ¼ë¡œ ì¶œë ¥í•˜ì„¸ìš”
4. ì¶”ê°€ ì„¤ëª… ì—†ì´ ì§ˆë¬¸ë§Œ ì¶œë ¥í•˜ì„¸ìš”

ë³´ì™„ëœ ì§ˆë¬¸:"""

        response = client.models.generate_content(
            model='gemini-2.0-flash-exp',
            contents=prompt,
            config={'temperature': 0.3, 'max_output_tokens': 100}
        )
        
        completed = response.text.strip()
        completed = completed.replace('"', '').replace("'", '').replace('ì¶œë ¥:', '').strip()
        
        return completed
    except Exception as e:
        print(f"[ERROR] ì§ˆë¬¸ ë³´ì™„ ì‹¤íŒ¨: {e}")
        return user_input


def complete_question_with_context(user_input, extracted_info, previous_question=None):
    """
    [ê°œì„ ] ì»¨í…ìŠ¤íŠ¸ ê¸°ë°˜ ì§ˆë¬¸ ë³´ì™„
    """
    user_clean = user_input.replace(' ', '').lower()
    
    # 1. ğŸ”¥ ì‹ ì²­ ê´€ë ¨ ì§ˆë¬¸ (ê¸°ê°„/ìê²©/ë°©ë²•) - ì œë„ íƒ€ì… ëˆ„ë½
    intent_keywords = {
        'ê¸°ê°„': ['ê¸°ê°„', 'ì–¸ì œ', 'ë§ˆê°'],
        'ìê²©': ['ìê²©', 'ì¡°ê±´'],
        'ë°©ë²•': ['ë°©ë²•', 'ì–´ë–»ê²Œ'],
        'í•™ì ': ['í•™ì ', 'ëª‡í•™ì '],
    }
    
    has_intent = False
    intent_type = None
    for category, keywords in intent_keywords.items():
        if any(kw in user_clean for kw in keywords):
            has_intent = True
            intent_type = category
            break
    
    has_target = bool(extracted_info.get('entity') or extracted_info.get('program'))
    
    if has_intent and not has_target:
        # ì´ì „ ì§ˆë¬¸ì—ì„œ ì œë„/ì „ê³µ ì¶”ì¶œ
        if previous_question:
            prev_entity, _ = extract_entity_from_text(previous_question)
            prev_program = extract_program_from_text(previous_question)
            
            if prev_entity:
                # ì´ì „ì— íŠ¹ì • ì „ê³µ ì–¸ê¸‰í–ˆìœ¼ë©´
                return f"{prev_entity} {user_input}"
            elif prev_program:
                # ì´ì „ì— ì œë„ ì–¸ê¸‰í–ˆìœ¼ë©´
                return f"{prev_program} {user_input}"
        
        # ì´ì „ ì§ˆë¬¸ì´ ì—†ê±°ë‚˜ ì¶”ì¶œ ì‹¤íŒ¨ ì‹œ AIë¡œ ë³´ì™„
        return complete_question_with_ai(user_input, previous_question)
    
    # 2. ëª©ë¡ ì§ˆë¬¸ì—ì„œ ì œë„ íƒ€ì… ëˆ„ë½
    list_keywords = ['ëª©ë¡', 'ë¦¬ìŠ¤íŠ¸', 'ì¢…ë¥˜']
    if any(kw in user_clean for kw in list_keywords):
        if not extracted_info.get('program'):
            if previous_question:
                prev_program = extract_program_from_text(previous_question)
                if prev_program:
                    return f"{prev_program} {user_input}"
            
            return complete_question_with_ai(user_input, previous_question)
    
    return user_input

def search_faq_mapping(user_input, faq_df):
    """
    [í•˜ì´ë¸Œë¦¬ë“œ] FAQ ë§¤í•‘ ê²€ìƒ‰
    - ì„¸ë¶€ ê³¼ì •ëª… ìš°ì„  ì²´í¬ (ì½”ë“œ)
    - êµ¬ì²´ì  í‚¤ì›Œë“œ ë§¤ì¹­ (FAQ íŒŒì¼)
    """
    if faq_df.empty:
        return None, 0
    
    user_clean = user_input.lower().replace(' ', '')
    
    # STEP 1: ë³µìˆ˜ í”„ë¡œê·¸ë¨ ê°ì§€
    program_keywords = ['ë³µìˆ˜ì „ê³µ', 'ë¶€ì „ê³µ', 'ìœµí•©ì „ê³µ', 'ë§ˆì´í¬ë¡œì „ê³µ', 'ë§ˆì´í¬ë¡œë””ê·¸ë¦¬']
    programs_mentioned = [p for p in program_keywords if p in user_clean]
    
    if len(programs_mentioned) >= 2:
        return None, 0
    
    # STEP 1.5: "ëª©ë¡" ì§ˆë¬¸ ê°ì§€
    list_keywords = ['ëª©ë¡', 'ë¦¬ìŠ¤íŠ¸', 'ì „ê³µì€', 'ì–´ë–¤ì „ê³µ']
    is_list_query = any(kw in user_clean for kw in list_keywords)
    
    if is_list_query:
        return None, 0
    
    # ğŸ”¥ STEP 1.7: ì„¸ë¶€ ì „ê³µ/ê³¼ì •ëª… ê°ì§€ (ê°œì„ : ê°€ì¥ ê¸´ ê²ƒ ìš°ì„ )
    has_specific_entity = False
    
    # ì¼ë°˜ ì „ê³µëª… ì²´í¬
    if not MAJORS_INFO.empty:
        matched_majors = []
        for _, row in MAJORS_INFO.iterrows():
            major_name = str(row.get('ì „ê³µëª…', ''))
            major_clean = major_name.replace(' ', '').lower()
            
            if major_clean and len(major_clean) > 3 and major_clean in user_clean:
                matched_majors.append((major_name, len(major_clean)))
        
        # ê°€ì¥ ê¸´ ì „ê³µëª… ì„ íƒ
        if matched_majors:
            matched_majors.sort(key=lambda x: x[1], reverse=True)
            best_major = matched_majors[0][0]
            print(f"[DEBUG] ì¼ë°˜ ì „ê³µëª… ê°ì§€: {best_major} â†’ FAQ ìŠ¤í‚µ")
            has_specific_entity = True
    
    # ğŸ”¥ ë§ˆì´í¬ë¡œë””ê·¸ë¦¬ ì„¸ë¶€ ê³¼ì •ëª… ì²´í¬ (ê°œì„ : ê°€ì¥ ê¸´ ê²ƒ ìš°ì„ )
    if not has_specific_entity and not MICRODEGREE_INFO.empty and 'ê³¼ì •ëª…' in MICRODEGREE_INFO.columns:
        matched_courses = []
        
        for _, row in MICRODEGREE_INFO.iterrows():
            course_name = str(row.get('ê³¼ì •ëª…', ''))
            course_clean = course_name.replace(' ', '').lower()
            keyword = course_clean.replace('md', '').strip()
            
            # ì¡°ê±´ 1: ê³¼ì •ëª… ì „ì²´ ë§¤ì¹­
            if course_clean and course_clean in user_clean:
                matched_courses.append((course_name, len(course_clean), 'full'))
            # ì¡°ê±´ 2: í•µì‹¬ í‚¤ì›Œë“œ(3ì ì´ìƒ) + MD ë™ì‹œ ì¡´ì¬
            elif keyword and len(keyword) >= 3 and keyword in user_clean and 'md' in user_clean:
                matched_courses.append((course_name, len(keyword), 'keyword'))
        
        # ê°€ì¥ ê¸´ ê³¼ì •ëª… ì„ íƒ (ì ìˆ˜ê°€ ë†’ì€ ê²ƒ)
        if matched_courses:
            matched_courses.sort(key=lambda x: x[1], reverse=True)
            best_course = matched_courses[0][0]
            match_type = matched_courses[0][2]
            print(f"[DEBUG] ë§ˆì´í¬ë¡œ ê³¼ì •ëª… ê°ì§€({match_type}): {best_course} â†’ FAQ ìŠ¤í‚µ")
            has_specific_entity = True
    
    # ì„¸ë¶€ ì—”í‹°í‹°ê°€ ìˆìœ¼ë©´ FAQ ìŠ¤í‚µ
    if has_specific_entity:
        return None, 0
    
    # STEP 3: í”„ë¡œê·¸ë¨ ì¶”ì¶œ
    detected_program = extract_program_from_text(user_input)
    
    # í•™ì‚¬ì œë„ í‚¤ì›Œë“œ ê°ì§€
    academic_keywords = ['ì¦ëª…ì„œ', 'í•™ì êµë¥˜', 'êµì§', 'êµì›ìê²©', 'íœ´í•™', 'ë³µí•™', 'ì „ê³¼', 'ì „ê³µë³€ê²½', 'ì¬ì…í•™', 'ìˆ˜ê°•ì‹ ì²­', 'í•™ì ì¸ì •', 'ì´ìˆ˜êµ¬ë¶„', 'ì„±ì ì²˜ë¦¬', 'ì¡¸ì—…ì‹', 'í•™ìœ„ìˆ˜ì—¬ì‹', 'ìœ ì˜ˆ', 'ì¡¸ì—…ìœ ì˜ˆ', 'ì¡°ê¸°ì¡¸ì—…', 'ë“±ë¡ê¸ˆ', 'í•™ë¹„', 'ì„±ì ', 'í•™ì ', 'ìˆ˜ê°•ë‚´ì—­', 'ê³„ì ˆí•™ê¸°', 'ìˆ˜ê°•ì² íšŒ', 'ì¡¸ì—…', 'ì¥í•™ê¸ˆ', 'ììœ í•™ê¸°ì œ', 'ì„±ì í™•ì¸', 'ì„±ì ì¡°íšŒ', 'í•™ì í™•ì¸', 'ìˆ˜ê°•í™•ì¸', 'ì´ìˆ˜í•™ì í™•ì¸', 'í•™ì‚¬ì‹œìŠ¤í…œ']
    is_academic_system = any(kw in user_clean for kw in academic_keywords)
    
    if is_academic_system and not detected_program:
        detected_program = "í•™ì‚¬ì œë„"
    
    if not detected_program:
        return None, 0
    
    # STEP 4: FAQ í•„í„°ë§
    if detected_program == "í•™ì‚¬ì œë„":
        program_faq = faq_df[faq_df['program'] == 'í•™ì‚¬ì œë„']
    elif detected_program in ['ì†Œë‹¨ìœ„ì „ê³µê³¼ì •', 'ë§ˆì´í¬ë¡œë””ê·¸ë¦¬']:
        program_faq = faq_df[faq_df['program'].isin(['ì†Œë‹¨ìœ„ì „ê³µê³¼ì •', 'ë§ˆì´í¬ë¡œë””ê·¸ë¦¬', 'ë‹¤ì „ê³µ'])]
    elif detected_program == 'ë‹¤ì „ê³µ':
        program_faq = faq_df[faq_df['program'] == 'ë‹¤ì „ê³µ']
    else:
        program_faq = faq_df[faq_df['program'].isin([detected_program, 'ë‹¤ì „ê³µ'])]
    
    if program_faq.empty:
        return None, 0
    
    # STEP 5: í‚¤ì›Œë“œ ë§¤ì¹­
    best_match = None
    best_score = 0
    
    for _, row in program_faq.iterrows():
        keywords = str(row.get('keyword', '')).split(',')
        keywords = [k.strip().lower().replace(' ', '') for k in keywords if k.strip()]
        
        exclude_kws = str(row.get('exclude_keywords', '')).split(',')
        exclude_kws = [e.strip().lower().replace(' ', '') for e in exclude_kws if e.strip()]
        
        if any(ex in user_clean for ex in exclude_kws):
            continue
        
        keyword_matches = 0
        total_keyword_length = 0
        
        for kw in keywords:
            if kw in user_clean:
                keyword_matches += 1
                total_keyword_length += len(kw)
        
        if keyword_matches == 0:
            continue
        
        score = keyword_matches * 10 + total_keyword_length
        
        row_program = str(row.get('program', '')).strip()
        if row_program == detected_program:
            score += 30
        elif row_program == 'ë‹¤ì „ê³µ':
            score += 10
        
        if score > best_score:
            best_score = score
            best_match = row
    
    if best_score >= 20:
        return best_match, best_score
    
    return None, 0

def generate_conversational_response(faq_answer, user_input, program=None):
    """FAQ ë‹µë³€ì„ AIë¥¼ í†µí•´ ëŒ€í™”ì²´ë¡œ ë³€í™˜"""
    try:
        prompt = f"""ë‹¹ì‹ ì€ ë‹¤ì „ê³µ ì•ˆë‚´ AIê¸°ë°˜ ì±—ë´‡ì…ë‹ˆë‹¤. 
ë‹¤ìŒ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ í•™ìƒì—ê²Œ ì¹œê·¼í•˜ê³  ë„ì›€ì´ ë˜ëŠ” ëŒ€í™”ì²´ë¡œ ë‹µë³€í•´ì£¼ì„¸ìš”.

[í•™ìƒ ì§ˆë¬¸]
{user_input}

[ì°¸ê³  ì •ë³´]
{faq_answer}

[ì§€ì¹¨]
1. ì¹œê·¼í•˜ê³  ê³µì†í•œ ë§íˆ¬ë¥¼ ì‚¬ìš©í•˜ì„¸ìš” (ì˜ˆ: "~ìš”", "~ìŠµë‹ˆë‹¤")
2. í•µì‹¬ ì •ë³´ë¥¼ ë¹ ëœ¨ë¦¬ì§€ ë§ˆì„¸ìš”
3. í•„ìš”ì‹œ ì´ëª¨ì§€ë¥¼ ì ì ˆíˆ ì‚¬ìš©í•˜ì„¸ìš”
4. ë„ˆë¬´ ê¸¸ì§€ ì•Šê²Œ ê°„ê²°í•˜ê²Œ ì‘ì„±í•˜ì„¸ìš”
5. URLì€ ì¤‘ë³µì—†ì´ ë‹µë³€í•˜ì„¸ìš”
6. ë¬¸ì¥ ëë§ˆë‹¤ ì¤„ë°”ê¿ˆ ì¶”ê°€
7. ë§ˆì§€ë§‰ì— ì¶”ê°€ ì§ˆë¬¸ì´ ìˆëŠ”ì§€ ë¬¼ì–´ë³´ì„¸ìš”
"""
        
        response = client.models.generate_content(
            model='gemini-2.0-flash-exp',
            contents=prompt,
            config={'temperature': 0.7, 'max_output_tokens': 800}
        )
        return response.text.strip()
    except Exception as e:
        # AI ì‹¤íŒ¨ ì‹œ ì›ë³¸ ë°˜í™˜
        return faq_answer


# ============================================================
# ğŸ¨ HTML ì¹´ë“œ ìŠ¤íƒ€ì¼ í•¨ìˆ˜
# ============================================================

def create_header_card(title, emoji="ğŸ“‹", color="#667eea"):
    return f"""<h3 style="margin: 20px 0 16px 0; font-size: 1.3rem; color: #333; font-weight: 600;">{emoji} {title}</h3>"""


def create_info_card(title, content_list, border_color="#007bff", emoji="ğŸ“Œ"):
    items_html = ""
    for item in content_list:
        items_html += f'<p style="margin: 6px 0 6px 20px; font-size: 0.95rem; color: #333;">â€¢ {item}</p>\n'
    return f"""<div style="margin: 12px 0;"><h4 style="color: #333; margin: 10px 0 8px 0; font-size: 1rem; font-weight: 600;">{emoji} {title}</h4>{items_html}</div>"""


def create_simple_card(content, bg_color="#f0f7ff", border_color="#007bff"):
    return f"""<div style="margin: 12px 0; padding: 0;">{content}</div>"""


def create_step_card(step_num, title, description, color="#007bff"):
    return f"""<div style="display: flex; align-items: flex-start; margin: 12px 0; padding: 12px; background: white; border-radius: 10px; box-shadow: 0 2px 8px rgba(0,0,0,0.06);"><div style="background: {color}; color: white; width: 32px; height: 32px; border-radius: 50%; display: flex; align-items: center; justify-content: center; font-weight: bold; margin-right: 14px; flex-shrink: 0;">{step_num}</div><div><strong style="color: #333; font-size: 0.95rem;">{title}</strong><p style="margin: 4px 0 0 0; color: #666; font-size: 0.9rem;">{description}</p></div></div>"""


def create_tip_box(text, emoji="ğŸ’¡"):
    return f"""<p style="margin: 12px 0; color: #666; font-size: 0.9rem; font-style: italic;">{emoji} <strong>TIP:</strong> {text}</p>"""


def create_warning_box(text, emoji="âš ï¸"):
    return f"""<p style="margin: 12px 0; color: #dc3545; font-size: 0.9rem; font-weight: 500;">{emoji} {text}</p>"""


def create_contact_box():
    return """<p style="margin: 16px 0 0 0; color: #666; font-size: 0.9rem;">ğŸ“ <strong>ë¬¸ì˜:</strong> ì „ê³µ ì‚¬ë¬´ì‹¤ ë˜ëŠ” í•™ì‚¬ì§€ì›íŒ€ <strong>031-670-5035</strong></p>"""


def create_table_html(headers, rows, colors=None):
    header_html = "".join([f'<th style="padding: 10px; text-align: left; border-bottom: 2px solid #ddd; font-weight: 600;">{h}</th>' for h in headers])
    rows_html = ""
    for idx, row in enumerate(rows):
        cells = ""
        for i, cell in enumerate(row):
            cells += f'<td style="padding: 10px; border-bottom: 1px solid #eee;">{cell}</td>'
        rows_html += f"<tr>{cells}</tr>"
    return f'<div style="overflow-x: auto; margin: 16px 0;"><table style="width: 100%; border-collapse: collapse;"><thead><tr>{header_html}</tr></thead><tbody>{rows_html}</tbody></table></div>'


def format_faq_response_html(answer, program=None):
    """FAQ ë‹µë³€ì„ ì˜ˆìœ HTMLë¡œ í¬ë§·íŒ…"""
    # URL ë§í¬ ë³€í™˜
    url_pattern = r'(https?://[^\s]+)'
    answer = re.sub(url_pattern, r'<a href="\1" target="_blank" style="color: #007bff; text-decoration: underline;">\1</a>', answer)
    
    # ë²ˆí˜¸ ë¦¬ìŠ¤íŠ¸ (1. 2. 3.) ì²˜ë¦¬
    lines = answer.split('\n')
    formatted_lines = []
    in_list = False
    
    for line in lines:
        line = line.strip()
        if not line:
            continue
        
        # ë²ˆí˜¸ ë¦¬ìŠ¤íŠ¸ íŒ¨í„´
        if re.match(r'^\d+\.', line):
            if not in_list:
                formatted_lines.append('<ol style="margin: 10px 0; padding-left: 20px;">')
                in_list = True
            # ë²ˆí˜¸ ì œê±°í•˜ê³  ë‚´ìš©ë§Œ
            content = re.sub(r'^\d+\.\s*', '', line)
            formatted_lines.append(f'<li style="margin: 5px 0; color: #333;">{content}</li>')
        else:
            if in_list:
                formatted_lines.append('</ol>')
                in_list = False
            formatted_lines.append(f'<p style="margin: 8px 0; color: #333; line-height: 1.6;">{line}</p>')
    
    if in_list:
        formatted_lines.append('</ol>')
    
    content = '\n'.join(formatted_lines)
    
    # í”„ë¡œê·¸ë¨ë³„ ìƒ‰ìƒ
    colors = {
        'ë³µìˆ˜ì „ê³µ': '#667eea',
        'ë¶€ì „ê³µ': '#11998e',
        'ìœµí•©ì „ê³µ': '#f093fb',
        'ìœµí•©ë¶€ì „ê³µ': '#4facfe',
        'ì—°ê³„ì „ê³µ': '#fa709a',
        'ì†Œë‹¨ìœ„ì „ê³µê³¼ì •': '#a8edea',
        'ë§ˆì´í¬ë¡œë””ê·¸ë¦¬': '#a8edea',
        'ë‹¤ì „ê³µ': '#667eea',
    }
    color = colors.get(program, '#667eea')
    
    return f"""
<div style="background: linear-gradient(135deg, {color}15 0%, {color}05 100%); border-left: 4px solid {color}; border-radius: 12px; padding: 16px; margin: 12px 0;">
    {content}
</div>
"""


# ============================================================
# ğŸ”¥ ì˜ë„ ë¶„ë¥˜ í•¨ìˆ˜
# ============================================================

def extract_programs(text):
    found = []
    text_lower = text.lower()
    for program, keywords in PROGRAM_KEYWORDS.items():
        for kw in keywords:
            if kw in text_lower:
                if program not in found:
                    found.append(program)
                break
    return found


def extract_additional_info(user_input, intent):
    info = {}
    user_clean = user_input.lower().replace(' ', '')
    
    found_programs = extract_programs(user_clean)
    if found_programs:
        info['programs'] = found_programs
        info['program'] = found_programs[0]
    
    year_match = re.search(r'(20\d{2})', user_input)
    if year_match:
        info['year'] = int(year_match.group(1))
    
    credit_match = re.search(r'(\d+)\s*í•™ì ', user_input)
    if credit_match:
        info['credits'] = int(credit_match.group(1))
    
    major_patterns = [r'([ê°€-í£A-Za-z]+(?:ìœµí•©)?ì „ê³µ)', r'([ê°€-í£A-Za-z]+í•™ê³¼)']
    for pattern in major_patterns:
        major_match = re.search(pattern, user_input)
        if major_match:
            major_name = major_match.group(1)
            if major_name not in ['ë³µìˆ˜ì „ê³µ', 'ë¶€ì „ê³µ', 'ìœµí•©ì „ê³µ', 'ìœµí•©ë¶€ì „ê³µ', 'ì—°ê³„ì „ê³µ', 'ë‹¤ì „ê³µ']:
                info['major'] = major_name
                break
    
    return info


def classify_with_semantic_router(user_input):
    if SEMANTIC_ROUTER is None:
        return None, 0.0
    try:
        result = SEMANTIC_ROUTER(user_input)
        if result and result.name:
            return result.name, 0.8
        return None, 0.0
    except:
        return None, 0.0


def classify_with_ai(user_input):
    prompt = """ë‹¹ì‹ ì€ ì§ˆë¬¸ ë¶„ë¥˜ AIì…ë‹ˆë‹¤. ë‹¤ìŒ ì˜ë„ ì¤‘ í•˜ë‚˜ë¡œ ë¶„ë¥˜í•˜ì„¸ìš”.
[ì˜ë„]: APPLY_QUALIFICATION, APPLY_PERIOD, APPLY_METHOD, APPLY_CANCEL, APPLY_CHANGE, 
PROGRAM_COMPARISON, PROGRAM_INFO, CREDIT_INFO, PROGRAM_TUITION, COURSE_SEARCH, CONTACT_SEARCH, 
RECOMMENDATION, GREETING, OUT_OF_SCOPE
ê·œì¹™: ì˜ë„ ì´ë¦„ë§Œ ì¶œë ¥. "ë‹¤ì „ê³µì´ ë­ì•¼?"ëŠ” PROGRAM_INFO"""
    try:
        response = client.models.generate_content(
            model='gemini-2.0-flash',
            contents=f"ì§ˆë¬¸: {user_input}\n\nì˜ë„ë¥¼ ë¶„ë¥˜í•˜ì„¸ìš”.",
            config={'system_instruction': prompt, 'temperature': 0, 'max_output_tokens': 50}
        )
        intent = response.text.strip().upper()
        valid_intents = ['APPLY_QUALIFICATION', 'APPLY_PERIOD', 'APPLY_METHOD',
                         'APPLY_CANCEL', 'APPLY_CHANGE', 'PROGRAM_COMPARISON', 'PROGRAM_INFO',
                         'CREDIT_INFO', 'PROGRAM_TUITION', 'COURSE_SEARCH', 'CONTACT_SEARCH',
                         'RECOMMENDATION', 'GREETING', 'OUT_OF_SCOPE']
        for valid in valid_intents:
            if valid in intent:
                return valid
        return 'OUT_OF_SCOPE'
    except:
        return 'OUT_OF_SCOPE'


def classify_intent(user_input, use_ai_fallback=True):
    """
    [ë””ë²„ê¹… ë²„ì „] í†µí•© ì˜ë„ ë¶„ë¥˜ í•¨ìˆ˜
    """
    print(f"\n[DEBUG classify_intent] ì…ë ¥: {user_input}")
    
    user_clean = user_input.lower().replace(' ', '')
    
    # 1. ìš•ì„¤ ì°¨ë‹¨
    BLOCKED_KEYWORDS = ['ì‹œë°œ', 'ì”¨ë°œ', 'ã……ã…‚', 'ë³‘ì‹ ', 'ã…‚ã……', 'ì§€ë„', 'ã…ˆã„¹', 'ê°œìƒˆë¼', 'êº¼ì ¸', 'ë‹¥ì³', 'ì£½ì–´', 'ë¯¸ì¹œ', 'ì¡´ë‚˜', 'fuck']
    if any(kw in user_clean for kw in BLOCKED_KEYWORDS):
        print("[DEBUG] âŒ ìš•ì„¤ ì°¨ë‹¨")
        return 'BLOCKED', 'blocked', {}
    
    # 2. ì¸ì‚¬ë§ ì²˜ë¦¬
    greeting_keywords = ['ì•ˆë…•', 'í•˜ì´', 'í—¬ë¡œ', 'hello', 'hi', 'ë°˜ê°€ì›Œ']
    if any(kw in user_clean for kw in greeting_keywords) and len(user_clean) < 15:
        print("[DEBUG] âœ… ì¸ì‚¬ë§")
        return 'GREETING', 'keyword', {}
    
    # 3. ì—°ë½ì²˜/ì „í™”ë²ˆí˜¸ ë¬¸ì˜ (ìµœìš°ì„ )
    contact_keywords = ['ì—°ë½ì²˜', 'ì „í™”ë²ˆí˜¸', 'ë²ˆí˜¸', 'ë¬¸ì˜ì²˜', 'ì‚¬ë¬´ì‹¤', 'íŒ©ìŠ¤', 'contact', 'call']
    if any(kw in user_clean for kw in contact_keywords):
        print("[DEBUG] âœ… ì—°ë½ì²˜ ë¬¸ì˜")
        entity_name, entity_type = extract_entity_from_text(user_input)
        return 'CONTACT_SEARCH', 'keyword', {'entity': entity_name, 'entity_type': entity_type}
    
    # [STEP 1] ì „ê³µ/ê³¼ì • ì—”í‹°í‹° ì¶”ì¶œ
    entity_name, entity_type = extract_entity_from_text(user_input)
    print(f"[DEBUG] ì—”í‹°í‹° ì¶”ì¶œ ê²°ê³¼: name={entity_name}, type={entity_type}")
    
    # [STEP 2] êµê³¼ëª© í‚¤ì›Œë“œ ê°ì§€
    course_keywords = ['êµê³¼ëª©', 'ê³¼ëª©', 'ì»¤ë¦¬í˜ëŸ¼', 'ìˆ˜ì—…', 'ê°•ì˜', 'ì´ìˆ˜ì²´ê³„ë„', 'êµìœ¡ê³¼ì •', 'ë­ë“¤ì–´', 'ë­ë°°ì›Œ']
    has_course_keyword = any(kw in user_clean for kw in course_keywords)
    print(f"[DEBUG] êµê³¼ëª© í‚¤ì›Œë“œ: {has_course_keyword}")
    
    # [STEP 3] ëª©ë¡ í‚¤ì›Œë“œ ê°ì§€
    list_keywords = ['ëª©ë¡', 'ë¦¬ìŠ¤íŠ¸', 'ì¢…ë¥˜', 'ì–´ë–¤ì „ê³µ', 'ì–´ë–¤ê³¼ì •', 'ë¬´ìŠ¨ì „ê³µ', 'ë¬´ìŠ¨ê³¼ì •', 'ë­ê°€ìˆì–´', 'ë­ìˆì–´']
    has_list_keyword = any(kw in user_clean for kw in list_keywords)
    print(f"[DEBUG] ëª©ë¡ í‚¤ì›Œë“œ: {has_list_keyword}")
    
    # ì œë„ ìœ í˜• ì¶”ì¶œ
    program_type = extract_program_from_text(user_input)
    print(f"[DEBUG] ì œë„ ìœ í˜•: {program_type}")
    
    # ì¶”ì¶œëœ ì •ë³´ ì €ì¥
    extracted_info = {
        'entity': entity_name,
        'entity_type': entity_type,
        'program': program_type,
        'major': entity_name
    }
    
    # [STEP 4] ì§ˆë¬¸ ë³´ì™„ í•„ìš” ì—¬ë¶€ íŒë‹¨
    import streamlit as st
    previous_question = st.session_state.get('previous_question') if 'st' in dir() else None
    
    needs_completion, completion_type = needs_question_completion(
        user_input, None, extracted_info, None
    )
    
    if needs_completion:
        print(f"[DEBUG] ì§ˆë¬¸ ë³´ì™„ í•„ìš”: {completion_type}")
        completed_question = complete_question_with_context(
            user_input, extracted_info, previous_question
        )
        
        print(f"[DEBUG] ì›ë˜ ì§ˆë¬¸: {user_input}")
        print(f"[DEBUG] ë³´ì™„ëœ ì§ˆë¬¸: {completed_question}")
        
        # ë³´ì™„ëœ ì§ˆë¬¸ìœ¼ë¡œ ì¬ì²˜ë¦¬
        if completed_question != user_input:
            entity_name, entity_type = extract_entity_from_text(completed_question)
            program_type = extract_program_from_text(completed_question)
            has_course_keyword = any(kw in completed_question.lower().replace(' ', '') 
                                    for kw in course_keywords)
            has_list_keyword = any(kw in completed_question.lower().replace(' ', '') 
                                  for kw in list_keywords)
            
            extracted_info = {
                'entity': entity_name,
                'entity_type': entity_type,
                'program': program_type,
                'major': entity_name
            }
            print(f"[DEBUG] ì¬ì²˜ë¦¬ í›„ ì—”í‹°í‹°: {entity_name}")
    
    # 3-1. íŠ¹ì • ì „ê³µ/ê³¼ì • + êµê³¼ëª© í‚¤ì›Œë“œ â†’ COURSE_SEARCH
    if entity_name and has_course_keyword:
        print(f"[DEBUG] âœ… ë¶„ë¥˜: COURSE_SEARCH (ì—”í‹°í‹°={entity_name}, êµê³¼ëª© í‚¤ì›Œë“œ=True)")
        return 'COURSE_SEARCH', 'entity', {
            'entity': entity_name, 
            'entity_type': entity_type,
            'program': program_type,
            'major': entity_name
        }
    
    # 3-2. ì œë„ ìœ í˜• + ëª©ë¡ í‚¤ì›Œë“œ â†’ MAJOR_SEARCH (ì „ê³µ ëª©ë¡)
    if program_type and has_list_keyword:
        print(f"[DEBUG] âœ… ë¶„ë¥˜: MAJOR_SEARCH (ì œë„={program_type}, ëª©ë¡ í‚¤ì›Œë“œ=True)")
        return 'MAJOR_SEARCH', 'keyword', {'program': program_type}
    
    # 3-3. íŠ¹ì • ì „ê³µ/ê³¼ì • ì—”í‹°í‹°ë§Œ ìˆìŒ â†’ MAJOR_INFO (ì „ê³µ ì •ë³´)
    if entity_name:
        print(f"[DEBUG] âœ… ë¶„ë¥˜: MAJOR_INFO (ì—”í‹°í‹°={entity_name})")
        return 'MAJOR_INFO', 'entity', {
            'entity': entity_name,
            'entity_type': entity_type,
            'program': program_type,
            'major': entity_name
        }
    
    print(f"[DEBUG] âš ï¸ ì—”í‹°í‹° ì—†ìŒ, ê³„ì† ì§„í–‰...")
    
    # 4. í”„ë¡œê·¸ë¨ ê´€ë ¨ ì§ˆë¬¸ ë¶„ë¥˜ (ê¸°ì¡´ ë¡œì§ ìœ ì§€)
    def extract_programs(text):
        found = []
        text_lower = text.lower()
        PROGRAM_KEYWORDS = {
            'ë³µìˆ˜ì „ê³µ': ['ë³µìˆ˜ì „ê³µ', 'ë³µì „', 'ë³µìˆ˜'],
            'ë¶€ì „ê³µ': ['ë¶€ì „ê³µ', 'ë¶€ì „'],
            'ìœµí•©ì „ê³µ': ['ìœµí•©ì „ê³µ', 'ìœµí•©'],
            'ìœµí•©ë¶€ì „ê³µ': ['ìœµí•©ë¶€ì „ê³µ'],
            'ì—°ê³„ì „ê³µ': ['ì—°ê³„ì „ê³µ', 'ì—°ê³„'],
            'ì†Œë‹¨ìœ„ì „ê³µê³¼ì •': ['ì†Œë‹¨ìœ„ì „ê³µê³¼ì •', 'ì†Œë‹¨ìœ„ì „ê³µ', 'ì†Œë‹¨ìœ„'],
            'ë§ˆì´í¬ë¡œë””ê·¸ë¦¬': ['ë§ˆì´í¬ë¡œë””ê·¸ë¦¬', 'ë§ˆì´í¬ë¡œ', 'md', 'ë§ˆë””'],
        }
        for program, keywords in PROGRAM_KEYWORDS.items():
            for kw in keywords:
                if kw in text_lower:
                    if program not in found:
                        found.append(program)
                    break
        return found
    
    found_programs = extract_programs(user_clean)
    
    if found_programs:
        program = found_programs[0]
        print(f"[DEBUG] í”„ë¡œê·¸ë¨ ë°œê²¬: {program}")
        if any(kw in user_clean for kw in ['ìê²©', 'ì‹ ì²­í• ìˆ˜ìˆ', 'ì¡°ê±´', 'ëŒ€ìƒ', 'ê¸°ì¤€']):
            print(f"[DEBUG] âœ… ë¶„ë¥˜: APPLY_QUALIFICATION")
            return 'APPLY_QUALIFICATION', 'complex', {'program': program}
        if any(kw in user_clean for kw in ['ì–¸ì œ', 'ê¸°ê°„', 'ë§ˆê°', 'ë‚ ì§œ', 'ì¼ì •', 'ì‹œê¸°']):
            print(f"[DEBUG] âœ… ë¶„ë¥˜: APPLY_PERIOD")
            return 'APPLY_PERIOD', 'complex', {'program': program}
        if any(kw in user_clean for kw in ['ì–´ë–»ê²Œ', 'ë°©ë²•', 'ì ˆì°¨', 'ìˆœì„œ', 'ê²½ë¡œ']):
            print(f"[DEBUG] âœ… ë¶„ë¥˜: APPLY_METHOD")
            return 'APPLY_METHOD', 'complex', {'program': program}
        if any(kw in user_clean for kw in ['í•™ì ', 'ëª‡í•™ì ', 'ì´ìˆ˜í•™ì ']):
            print(f"[DEBUG] âœ… ë¶„ë¥˜: CREDIT_INFO")
            return 'CREDIT_INFO', 'complex', {'program': program}
        if any(kw in user_clean for kw in ['ë“±ë¡ê¸ˆ', 'ìˆ˜ê°•ë£Œ', 'í•™ë¹„', 'ì¥í•™ê¸ˆ']):
            print(f"[DEBUG] âœ… ë¶„ë¥˜: PROGRAM_TUITION")
            return 'PROGRAM_TUITION', 'complex', {'program': program}
        if any(kw in user_clean for kw in ['ì·¨ì†Œ', 'í¬ê¸°', 'ì² íšŒ', 'ê·¸ë§Œ']):
            print(f"[DEBUG] âœ… ë¶„ë¥˜: APPLY_CANCEL")
            return 'APPLY_CANCEL', 'complex', {'program': program}
        if any(kw in user_clean for kw in ['ë³€ê²½', 'ë°”ê¾¸', 'ì „í™˜']):
            print(f"[DEBUG] âœ… ë¶„ë¥˜: APPLY_CHANGE")
            return 'APPLY_CHANGE', 'complex', {'program': program}
        if any(kw in user_clean for kw in ['ì°¨ì´', 'ë¹„êµ', 'vs']):
            print(f"[DEBUG] âœ… ë¶„ë¥˜: PROGRAM_COMPARISON")
            return 'PROGRAM_COMPARISON', 'complex', {'program': program}
        print(f"[DEBUG] âœ… ë¶„ë¥˜: PROGRAM_INFO")
        return 'PROGRAM_INFO', 'inferred', {'program': program}
    
    # 5. Semantic Router
    if SEMANTIC_ROUTER is not None:
        print("[DEBUG] Semantic Router ì‹œë„")
        semantic_intent, score = classify_with_semantic_router(user_input)
        if semantic_intent:
            print(f"[DEBUG] âœ… Semantic Router: {semantic_intent}")
            return semantic_intent, 'semantic', extract_additional_info(user_input, semantic_intent)
    
    # 6. AI Fallback
    if use_ai_fallback:
        print("[DEBUG] AI Fallback ì‹œë„")
        try:
            ai_intent = classify_with_ai(user_input)
            if ai_intent not in ['OUT_OF_SCOPE', 'BLOCKED']:
                print(f"[DEBUG] âœ… AI ë¶„ë¥˜: {ai_intent}")
                return ai_intent, 'ai', extract_additional_info(user_input, ai_intent)
        except:
            pass
    
    print("[DEBUG] âŒ ë¶„ë¥˜: OUT_OF_SCOPE")
    return 'OUT_OF_SCOPE', 'fallback', {}


# ============================================================
# ğŸ« ê³„ì—´ë³„ ì „ê³µ ê·¸ë£¹í™” í—¬í¼ í•¨ìˆ˜
# ============================================================

def get_majors_by_category(program_type=None, data_source="majors"):
    """ê³„ì—´ë³„ë¡œ ì „ê³µì„ ê·¸ë£¹í™”í•˜ì—¬ ë°˜í™˜"""
    special_programs = ["ìœµí•©ì „ê³µ", "ìœµí•©ë¶€ì „ê³µ", "ì†Œë‹¨ìœ„ì „ê³µê³¼ì •", "ë§ˆì´í¬ë¡œë””ê·¸ë¦¬"]
    
    # ğŸ”¥ ë§ˆì´í¬ë¡œë””ê·¸ë¦¬/ì†Œë‹¨ìœ„ì „ê³µê³¼ì •ì¸ ê²½ìš° microdegree_info.xlsx ì‚¬ìš©
    if program_type in ["ì†Œë‹¨ìœ„ì „ê³µê³¼ì •", "ë§ˆì´í¬ë¡œë””ê·¸ë¦¬"]:
        if not MICRODEGREE_INFO.empty and 'ê³¼ì •ëª…' in MICRODEGREE_INFO.columns:
            field_column = 'ê³„ì—´' if 'ê³„ì—´' in MICRODEGREE_INFO.columns else None
            
            if field_column:
                field_courses = {}
                for _, row in MICRODEGREE_INFO.iterrows():
                    field = row.get(field_column, 'ê¸°íƒ€')
                    if pd.isna(field) or str(field).strip() == '':
                        field = 'ê¸°íƒ€'
                    field = str(field).strip()
                    
                    course_name = row.get('ê³¼ì •ëª…', '')
                    if course_name:
                        if field not in field_courses:
                            field_courses[field] = []
                        if course_name not in field_courses[field]:
                            field_courses[field].append(course_name)
                
                for field in field_courses:
                    field_courses[field] = sorted(field_courses[field])
                
                return field_courses
            else:
                return {"ì „ì²´": sorted(MICRODEGREE_INFO['ê³¼ì •ëª…'].unique().tolist())}
        return {}
    
    # ìœµí•©ì „ê³µ, ìœµí•©ë¶€ì „ê³µ
    if program_type in ["ìœµí•©ì „ê³µ", "ìœµí•©ë¶€ì „ê³µ"]:
        majors_list = []
        
        if not MAJORS_INFO.empty and 'ì œë„ìœ í˜•' in MAJORS_INFO.columns:
            if program_type == "ìœµí•©ì „ê³µ":
                mask = MAJORS_INFO['ì œë„ìœ í˜•'].str.contains('ìœµí•©ì „ê³µ', na=False) & ~MAJORS_INFO['ì œë„ìœ í˜•'].str.contains('ìœµí•©ë¶€ì „ê³µ', na=False)
            else:
                mask = MAJORS_INFO['ì œë„ìœ í˜•'].str.contains(program_type, na=False)
            majors_list = MAJORS_INFO[mask]['ì „ê³µëª…'].unique().tolist()
        
        if data_source == "courses" and not COURSES_DATA.empty and 'ì œë„ìœ í˜•' in COURSES_DATA.columns:
            if program_type == "ìœµí•©ì „ê³µ":
                mask = COURSES_DATA['ì œë„ìœ í˜•'].str.contains('ìœµí•©ì „ê³µ', na=False) & ~COURSES_DATA['ì œë„ìœ í˜•'].str.contains('ìœµí•©ë¶€ì „ê³µ', na=False)
            else:
                mask = COURSES_DATA['ì œë„ìœ í˜•'].str.contains(program_type, na=False)
            for m in COURSES_DATA[mask]['ì „ê³µëª…'].unique():
                if m not in majors_list:
                    majors_list.append(m)
        
        return {"ì „ì²´": sorted(majors_list)} if majors_list else {}
    
    # ì¼ë°˜ ì „ê³µ (ë³µìˆ˜ì „ê³µ, ë¶€ì „ê³µ, ì—°ê³„ì „ê³µ)
    category_majors = {}
    
    if not MAJORS_INFO.empty:
        has_category = 'ê³„ì—´' in MAJORS_INFO.columns
        
        if program_type:
            if program_type == "ë¶€ì „ê³µ":
                mask = MAJORS_INFO['ì œë„ìœ í˜•'].str.contains('ë¶€ì „ê³µ', na=False) & ~MAJORS_INFO['ì œë„ìœ í˜•'].str.contains('ìœµí•©ë¶€ì „ê³µ', na=False)
            else:
                mask = MAJORS_INFO['ì œë„ìœ í˜•'].str.contains(program_type, na=False)
            filtered_df = MAJORS_INFO[mask]
        else:
            filtered_df = MAJORS_INFO
        
        if has_category:
            for _, row in filtered_df.iterrows():
                category = row.get('ê³„ì—´', 'ê¸°íƒ€')
                if pd.isna(category) or str(category).strip() == '':
                    category = 'ê¸°íƒ€'
                category = str(category).strip()
                major_name = row['ì „ê³µëª…']
                
                if category not in category_majors:
                    category_majors[category] = []
                if major_name not in category_majors[category]:
                    category_majors[category].append(major_name)
        else:
            category_majors["ì „ì²´"] = filtered_df['ì „ê³µëª…'].unique().tolist()
    
    for cat in category_majors:
        category_majors[cat] = sorted(category_majors[cat])
    
    return category_majors


def get_category_color(category):
    colors = {
        'ê³µí•™ê³„ì—´': '#e74c3c',
        'ìì—°ê³¼í•™ê³„ì—´': '#27ae60',
        'ì¸ë¬¸ì‚¬íšŒê³„ì—´': '#3498db',
        'ì˜ˆì²´ëŠ¥ê³„ì—´': '#9b59b6',
        'ì˜í•™ê³„ì—´': '#e67e22',
        'ì‚¬ë²”ê³„ì—´': '#1abc9c',
        'ê¸°íƒ€': '#95a5a6',
        'ì „ì²´': '#667eea',
    }
    return colors.get(category, '#6c757d')


def format_majors_by_category_html(category_majors):
    if not category_majors:
        return "<p>ì „ê³µ ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤.</p>"
    
    html = ""
    for category, majors in category_majors.items():
        if not majors:
            continue
        color = get_category_color(category)
        majors_tags = " ".join([f'<span style="background: {color}22; color: {color}; padding: 3px 8px; border-radius: 12px; font-size: 0.8rem; margin: 2px; display: inline-block;">{m}</span>' for m in majors])
        
        html += f"""
<div style="margin-bottom: 12px;">
    <div style="background: {color}; color: white; padding: 6px 12px; border-radius: 8px 8px 0 0; font-weight: bold; font-size: 0.9rem;">
        ğŸ“š {category} ({len(majors)}ê°œ)
    </div>
    <div style="background: #f8f9fa; padding: 10px; border-radius: 0 0 8px 8px; border: 1px solid #dee2e6; border-top: none;">
        {majors_tags}
    </div>
</div>
"""
    return html


# ============================================================
# ğŸ¯ í•¸ë“¤ëŸ¬ í•¨ìˆ˜ë“¤
# ============================================================

import pandas as pd
import numpy as np

import pandas as pd
import numpy as np

import pandas as pd
import numpy as np

def handle_course_search(user_input, extracted_info, data_dict):
    """
    êµê³¼ëª© ê²€ìƒ‰ ìµœì¢… ì™„ì„±ë³¸
    ê¸°ëŠ¥:
    1. 1ì°¨(ì •í™•) -> 2ì°¨(í‚¤ì›Œë“œ) ê²€ìƒ‰ ìœ ì§€
    2. í•™ë…„/ì´ìˆ˜êµ¬ë¶„ ë¹ˆì¹¸ ì²˜ë¦¬ ë° ì´ëª¨í‹°ì½˜ ìœ ì§€
    3. ê³¼ëª©ëª… ì˜†ì— (í•™ì , êµìœ¡ìš´ì˜ì „ê³µ) í‘œì‹œ ì¶”ê°€
    """
    courses_data = data_dict.get('courses', pd.DataFrame())
    
    # ë°ì´í„° ì—†ìŒ ë°©ì–´ ë¡œì§
    if courses_data.empty:
        response = create_header_card("êµê³¼ëª© ê²€ìƒ‰", "ğŸ“š", "#ff6b6b")
        response += create_warning_box("êµê³¼ëª© ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        response += create_contact_box()
        return response, "ERROR"

    # 1. ì—”í‹°í‹° ì¶”ì¶œ
    entity = extracted_info.get('entity') or extracted_info.get('major')
    entity_type = extracted_info.get('entity_type')
    
    if not entity:
        entity, entity_type = extract_entity_from_text(user_input)
    
    # 2. [1ì°¨ ê²€ìƒ‰] ì •í™•í•œ ì „ê³µëª… ë§¤ì¹­
    major_courses = pd.DataFrame()
    if entity:
        major_courses = courses_data[courses_data['ì „ê³µëª…'] == entity].copy()
        # ì •í™•í•œ ë§¤ì¹­ ì—†ìœ¼ë©´ í¬í•¨ ê²€ìƒ‰ ì‹œë„
        if major_courses.empty:
            keyword_clean = entity.replace('MD', '').replace('md', '').replace('ì „ê³µ', '').replace(' ', '').strip()
            major_courses = courses_data[courses_data['ì „ê³µëª…'].str.contains(keyword_clean, case=False, na=False, regex=False)].copy()

    # 3. [2ì°¨ ê²€ìƒ‰ - ê¸°ëŠ¥ ìœ ì§€ë¨] ì¼ë°˜ í‚¤ì›Œë“œ ê´‘ë²”ìœ„ ê²€ìƒ‰ (Fallback)
    if major_courses.empty:
        search_target = entity if entity else user_input
        # 'ì „ê³µ', 'ê³¼' ë“±ì„ ë–¼ê³  ìˆœìˆ˜ í‚¤ì›Œë“œë¡œ ê²€ìƒ‰
        keyword = search_target.replace('ì „ê³µ', '').replace('í•™ê³¼', '').replace('ê³¼', '').replace('MD', '').replace('md', '').replace(' ', '').strip()
        
        if keyword:
            major_courses = courses_data[courses_data['ì „ê³µëª…'].str.contains(keyword, case=False, na=False, regex=False)].copy()
            # ê²€ìƒ‰ ì„±ê³µ ì‹œ ì—”í‹°í‹° ì´ë¦„ ì—…ë°ì´íŠ¸
            if not major_courses.empty and not entity:
                entity = major_courses.iloc[0]['ì „ê³µëª…']

    # ê²€ìƒ‰ ì‹¤íŒ¨ ì‹œ ì²˜ë¦¬
    if major_courses.empty:
        response = create_header_card("êµê³¼ëª© ê²€ìƒ‰", "ğŸ“š", "#ff6b6b")
        if entity:
            response += create_warning_box(f"'{entity}' ê´€ë ¨ êµê³¼ëª©ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        else:
            response += create_simple_card("<p style='margin:0;'>ì°¾ìœ¼ì‹œëŠ” ì „ê³µì´ë‚˜ êµê³¼ëª©ëª…ì„ ì •í™•íˆ ì…ë ¥í•´ì£¼ì„¸ìš”.</p>", "#f0f4ff", "#667eea")
        return response, "COURSE_SEARCH"

    # 4. í—¤ë” ë° ìƒë‹¨ ì •ë³´ êµ¬ì„±
    actual_name = major_courses['ì „ê³µëª…'].iloc[0]
    is_md = (entity_type == 'microdegree') or ('MD' in actual_name) or ('md' in actual_name.lower())
    header_color = "#a8edea" if is_md else "#667eea"
    
    response = create_header_card(f"{actual_name} êµê³¼ëª©", "ğŸ“š", header_color)
    
    # ì œë„ìœ í˜• í‘œì‹œ (ìƒë‹¨ ë°•ìŠ¤)
    info_items = []
    program_types = major_courses['ì œë„ìœ í˜•'].dropna().unique().tolist()
    program_str = ', '.join([str(pt) for pt in program_types])
    if program_str:
        info_items.append(f"ğŸ“‹ <strong>ì œë„ìœ í˜•:</strong> {program_str}")

    if info_items:
        response += '<div style="background: #f8f9fa; border-radius: 8px; padding: 12px; margin: 8px 0; font-size: 0.95em;">'
        for item in info_items:
            response += f'<div style="color: #555;">{item}</div>'
        response += '</div>'

    # 5. í•™ë…„/í•™ê¸°ë³„ ë¦¬ìŠ¤íŠ¸ ì¶œë ¥ (ì´ëª¨í‹°ì½˜, ë¹ˆì¹¸ ì²˜ë¦¬ ë¡œì§ ìœ ì§€ë¨)
    emoji_map = {1: "ğŸŒ±", 2: "ğŸŒ¿", 3: "ğŸŒ³", 4: "ğŸ“", 999: "â™¾ï¸"}
    
    # í•™ë…„ ì •ë ¬ (NaN -> 999)
    major_courses['sort_year'] = pd.to_numeric(major_courses['í•™ë…„'], errors='coerce').fillna(999)
    years = sorted(major_courses['sort_year'].unique())

    for sort_year in years:
        # í•™ë…„ í‘œì‹œ í…ìŠ¤íŠ¸ ì„¤ì •
        if sort_year == 999:
            year_data = major_courses[major_courses['í•™ë…„'].isna()]
            emoji = emoji_map.get(999)
            year_display = f"{emoji} í•™ë…„ ë¬´ê´€"
        else:
            year_data = major_courses[major_courses['sort_year'] == sort_year]
            emoji = emoji_map.get(int(sort_year), "ğŸ“…")
            year_display = f"{emoji} {int(sort_year)}í•™ë…„"

        if year_data.empty: continue

        response += f"""
<div style="background: white; border-radius: 8px; padding: 16px; margin: 12px 0; box-shadow: 0 2px 4px rgba(0,0,0,0.1);">
    <h4 style="margin: 0 0 12px 0; color: #333; border-bottom: 2px solid {header_color}; padding-bottom: 8px;">{year_display}</h4>
"""

        # í•™ê¸° ì •ë ¬ (ì—†ìœ¼ë©´ 0ìœ¼ë¡œ ì²˜ë¦¬)
        semesters = sorted([int(s) for s in year_data['í•™ê¸°'].dropna().unique()])
        if not semesters and not year_data.empty: semesters = [0]

        for sem in semesters:
            if sem == 0:
                sem_data = year_data[year_data['í•™ê¸°'].isna()]
                sem_display = "í•™ê¸° ë¯¸ì§€ì •"
            else:
                sem_data = year_data[year_data['í•™ê¸°'] == sem]
                sem_display = f"ğŸ“† {sem}í•™ê¸°"
            
            if sem_data.empty: continue

            response += f"""
<div style="margin: 12px 0;">
    <h5 style="margin: 0 0 8px 0; color: #555;">{sem_display}</h5>
"""
            
            # ì´ìˆ˜êµ¬ë¶„ í•„í„°ë§ (ë¹ˆì¹¸ í¬í•¨ ì²˜ë¦¬ ìœ ì§€ë¨)
            mask_required = sem_data['ì´ìˆ˜êµ¬ë¶„'].str.contains('í•„ìˆ˜', na=False)
            mask_elective = sem_data['ì´ìˆ˜êµ¬ë¶„'].str.contains('ì„ íƒ', na=False)
            mask_others = ~(mask_required | mask_elective)
            
            required = sem_data[mask_required]
            elective = sem_data[mask_elective]
            others = sem_data[mask_others]

            # ğŸ”¥ [ìˆ˜ì •ë¨] ê³¼ëª© ë¦¬ìŠ¤íŠ¸ ìƒì„± í•¨ìˆ˜: (í•™ì , êµìœ¡ìš´ì˜ì „ê³µ) ê²°í•©
            def create_course_list(rows, bg_color):
                items = ""
                for _, row in rows.iterrows():
                    course_title = row.get('ê³¼ëª©ëª…', '-')
                    
                    # ê´„í˜¸ ì•ˆì— ë“¤ì–´ê°ˆ ë‚´ìš© ìˆ˜ì§‘
                    details = []
                    
                    # 1. í•™ì  ì •ë³´
                    try:
                        c_val = row.get('í•™ì ')
                        if pd.notna(c_val):
                            details.append(f"{int(c_val)}í•™ì ")
                    except:
                        pass
                    
                    # 2. êµìœ¡ìš´ì˜ì „ê³µ ì •ë³´ (ì»¬ëŸ¼ì´ ìˆê³  ê°’ì´ ìˆì„ ë•Œë§Œ)
                    if 'êµìœ¡ìš´ì˜ì „ê³µ' in row.index:
                        op_major = row.get('êµìœ¡ìš´ì˜ì „ê³µ')
                        if pd.notna(op_major):
                            op_str = str(op_major).strip()
                            # 'nan' ë¬¸ìì—´ì´ë‚˜ ë¹ˆ ë¬¸ìì—´ì´ ì•„ë‹ ë•Œë§Œ ì¶”ê°€
                            if op_str and op_str.lower() != 'nan':
                                details.append(op_str)
                    
                    # 3. ê´„í˜¸ í¬ë§·íŒ…: (3í•™ì , í–‰ì •í•™ì „ê³µ)
                    detail_str = f" ({', '.join(details)})" if details else ""
                    
                    # --- ê³¼ëª©ê°œìš” ---
                    outline = row.get('êµê³¼ëª©ê°œìš”') if 'êµê³¼ëª©ê°œìš”' in row.index else None
                    has_outline = pd.notna(outline) and str(outline).strip() != ""

                    if has_outline:
                        items += f"""
<li style="margin: 4px 0;">
    <details>
        <summary style="cursor: pointer; padding: 6px 10px; border-radius: 4px;">
            â€¢ {course_title}{detail_str}
        </summary>
        <div style="margin: 6px 0 0 18px; font-size: 13px; color: #555;">
            {outline}
        </div>
    </details>
</li>
"""
                    else:
                        items += f"""
<li style="margin: 4px 0; padding: 6px 10px;">
    â€¢ {course_title}{detail_str}
</li>
"""
                return items

            # ê° ì„¹ì…˜ ì¶œë ¥
            if not required.empty:
                response += f"""
<div style="margin: 8px 0;">
    <strong style="color: #dc3545;">ğŸ”´ ì „ê³µí•„ìˆ˜</strong>
    <ul style="list-style: none; padding-left: 0; margin: 8px 0;">
        {create_course_list(required, "")}
</ul>
</div>"""
            
            if not elective.empty:
                response += f"""
<div style="margin: 8px 0;">
    <strong style="color: #28a745;">ğŸŸ¢ ì „ê³µì„ íƒ</strong>
    <ul style="list-style: none; padding-left: 0; margin: 8px 0;">
         {create_course_list(elective, "")}
</ul>
</div>"""
                
            if not others.empty:
                response += f"""
<div style="margin: 8px 0;">
    <strong style="color: #007bff;">ğŸ”µ ì „ê³µ/ììœ </strong>
    <ul style="list-style: none; padding-left: 0; margin: 8px 0;">
         {create_course_list(others, "")}
</ul>
</div>"""
            
            response += """</div>""" 
        
        response += """</div>"""

    # í•˜ë‹¨ íŒ ë©”ì‹œì§€
    if is_md:
        response += create_tip_box(f"ğŸ’¡ {actual_name}ì— ëŒ€í•´ ë” ì•Œê³  ì‹¶ìœ¼ì‹œë©´ '{actual_name} ì„¤ëª…í•´ì¤˜'ë¼ê³  ë¬¼ì–´ë³´ì„¸ìš”!")
    else:
        response += create_tip_box(f"ğŸ’¡ ë” ìì„¸í•œ ì‚¬í•­ì´ ê¶ê¸ˆí•˜ì‹œë©´ ì™¼ìª½ ë©”ë‰´ì˜ 'ë‹¤ì „ê³µ ì œë„ ì•ˆë‚´'ë¥¼ ì°¸ê³ í•´ ì£¼ì„¸ìš”!")
    
    response += create_contact_box()
    
    return response, "COURSE_SEARCH"

def handle_contact_search(user_input, extracted_info, data_dict):
    """ì—°ë½ì²˜ ê²€ìƒ‰ - ë§ˆì´í¬ë¡œë””ê·¸ë¦¬ëŠ” microdegree_info ì‚¬ìš©"""
    entity = extracted_info.get('entity') or extracted_info.get('major')
    entity_type = extracted_info.get('entity_type')
    
    majors_info = data_dict.get('majors', MAJORS_INFO)
    microdegree_info = data_dict.get('microdegree', MICRODEGREE_INFO)
    
    # ğŸ”¥ ì—”í‹°í‹°ê°€ ì—†ìœ¼ë©´ ìƒˆë¡œ ì¶”ì¶œ
    if not entity:
        entity, entity_type = extract_entity_from_text(user_input)
    
    # ì—”í‹°í‹°ê°€ ì—¬ì „íˆ ì—†ìœ¼ë©´ ì•ˆë‚´
    if not entity:
        response = create_header_card("ì—°ë½ì²˜ ì¡°íšŒ", "ğŸ“", "#667eea")
        response += create_simple_card("<p style='margin:0;'>ì–´ë–¤ ì „ê³µ/ê³¼ì •ì˜ ì—°ë½ì²˜ë¥¼ ì°¾ìœ¼ì‹œë‚˜ìš”?</p>", "#f0f4ff", "#667eea")
        category_majors = get_majors_by_category()
        if category_majors and len(category_majors) > 1:
            response += "<div style='margin-top: 12px;'><strong>ğŸ“š ê³„ì—´ë³„ ì „ê³µ ëª©ë¡</strong></div>"
            response += format_majors_by_category_html(category_majors)
        response += create_tip_box("ì˜ˆì‹œ: \"ê²½ì˜í•™ì „ê³µ ì—°ë½ì²˜ ì•Œë ¤ì¤˜\", \"ì‹í’ˆí’ˆì§ˆê´€ë¦¬ MD ì „í™”ë²ˆí˜¸\"")
        response += create_contact_box()
        return response, "CONTACT_SEARCH"
    
    # ğŸ”¥ ë§ˆì´í¬ë¡œë””ê·¸ë¦¬ ê³¼ì •ì¸ ê²½ìš° - microdegree_info ì‚¬ìš©
    if entity_type == 'microdegree' and not microdegree_info.empty:
        keyword = entity.replace('MD', '').replace('md', '').replace(' ', '').strip()
        result = microdegree_info[microdegree_info['ê³¼ì •ëª…'].str.contains(keyword, case=False, na=False, regex=False)]
        
        if not result.empty:
            row = result.iloc[0]
            
            response = create_header_card(f"{row['ê³¼ì •ëª…']} ì—°ë½ì²˜", "ğŸ“", "#11998e")
            response += f"""
<div style="background: white; border-left: 4px solid #11998e; border-radius: 8px; padding: 16px; margin: 8px 0; box-shadow: 0 2px 4px rgba(0,0,0,0.1);">
    <p style="margin: 8px 0; color: #333;"><strong>ğŸ“ ê³¼ì •ëª…:</strong> {row['ê³¼ì •ëª…']}</p>
    <p style="margin: 8px 0; color: #333;"><strong>ğŸ« êµìœ¡ìš´ì˜ì „ê³µ:</strong> {row.get('êµìœ¡ìš´ì˜ì „ê³µ', '-')}</p>
    <p style="margin: 8px 0; color: #333;"><strong>ğŸ“± ì—°ë½ì²˜:</strong> {row.get('ì—°ë½ì²˜', '-')}</p>
    <p style="margin: 8px 0; color: #333;"><strong>ğŸ“ ìœ„ì¹˜:</strong> {row.get('ìœ„ì¹˜', '-')}</p>
</div>
"""
            return response, "CONTACT_SEARCH"
    
    # ğŸ”¥ ì¼ë°˜ ì „ê³µì¸ ê²½ìš° - majors_info ì‚¬ìš©
    if not majors_info.empty:
        keyword = entity.replace('ì „ê³µ', '').replace('(', '').replace(')', '').replace(' ', '').strip()
        result = majors_info[majors_info['ì „ê³µëª…'].str.contains(keyword, case=False, na=False, regex=False)]
        
        if not result.empty:
            row = result.iloc[0]
            response = create_header_card(f"{row['ì „ê³µëª…']} ì—°ë½ì²˜", "ğŸ“", "#11998e")

            response += f"""
<div style="background: white; border-left: 4px solid #11998e; border-radius: 8px; padding: 16px; margin: 8px 0; box-shadow: 0 2px 4px rgba(0,0,0,0.1);">
    <p style="margin: 8px 0; color: #333;"><strong>ğŸ“ ì „ê³µëª…:</strong> {row['ì „ê³µëª…']}</p>
    <p style="margin: 8px 0; color: #333;"><strong>ğŸ“± ì—°ë½ì²˜:</strong> {row.get('ì—°ë½ì²˜', '-')}</p>
    <p style="margin: 8px 0; color: #333;"><strong>ğŸ“ ìœ„ì¹˜:</strong> {row.get('ìœ„ì¹˜', row.get('ì‚¬ë¬´ì‹¤ìœ„ì¹˜', '-'))}</p>
"""
            
            homepage = row.get('í™ˆí˜ì´ì§€', '-')
            if homepage and homepage != '-' and str(homepage).startswith('http'):
                response += f'    <p style="margin: 8px 0; color: #333;"><strong>ğŸŒ í™ˆí˜ì´ì§€:</strong> <a href="{homepage}" target="_blank" style="color: #e83e8c; text-decoration: none;">{homepage} ğŸ”—</a></p>\n'
            else:
                response += f'    <p style="margin: 8px 0; color: #333;"><strong>ğŸŒ í™ˆí˜ì´ì§€:</strong> {homepage}</p>\n'
            
            response += "</div>"
            return response, "CONTACT_SEARCH"
    
    # ì°¾ì§€ ëª»í•œ ê²½ìš°
    response = create_header_card("ì—°ë½ì²˜ ì¡°íšŒ", "ğŸ“", "#ff6b6b")
    response += create_warning_box(f"'{entity}' ì—°ë½ì²˜ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    response += create_contact_box()
    return response, "ERROR"


def handle_recommendation(user_input, extracted_info, data_dict):
    year_match = re.search(r'(\d{4})í•™ë²ˆ', user_input)
    major_match = re.search(r'([ê°€-í£]+ì „ê³µ)', user_input)
    required_match = re.search(r'ì „í•„\s*(\d+)í•™ì ', user_input)
    elective_match = re.search(r'ì „ì„ \s*(\d+)í•™ì ', user_input)
    
    if not (year_match and major_match and (required_match or elective_match)):
        response = create_header_card("ë§ì¶¤í˜• ë‹¤ì „ê³µ ì¶”ì²œ", "ğŸ¯", "#f093fb")
        response += create_simple_card("<p style='margin:0; font-size: 0.95rem;'>ì •í™•í•œ ì¶”ì²œì„ ìœ„í•´ ì•„ë˜ ì •ë³´ê°€ í•„ìš”í•©ë‹ˆë‹¤</p>", "#fef0f5", "#f5576c")
        response += create_info_card("í•„ìš”í•œ ì •ë³´", [
            "ğŸ“… ê¸°ì¤€í•™ë²ˆ (ì˜ˆ: 2022í•™ë²ˆ)",
            "ğŸ“ í˜„ì¬ ë³¸ì „ê³µ (ì˜ˆ: ê²½ì˜í•™ì „ê³µ)",
            "ğŸ“Š ì´ìˆ˜í•œ ì „ê³µí•„ìˆ˜/ì „ê³µì„ íƒ í•™ì "
        ], "#f093fb", "ğŸ“‹")
        response += create_tip_box("ì˜ˆì‹œ: \"2022í•™ë²ˆ ê²½ì˜í•™ì „ê³µ ì „í•„ 15í•™ì  ì „ì„  12í•™ì  ì´ìˆ˜í–ˆì–´. ì¶”ì²œí•´ì¤˜\"")
        response += create_contact_box()
        return response, "RECOMMENDATION"
    
    admission_year = int(year_match.group(1))
    primary_major = major_match.group(1)
    completed_required = int(required_match.group(1)) if required_match else 0
    completed_elective = int(elective_match.group(1)) if elective_match else 0
    total_credits = completed_required + completed_elective
    
    response = create_header_card("ë§ì¶¤í˜• ë‹¤ì „ê³µ ì¶”ì²œ", "ğŸ¯", "#f093fb")
    
    response += create_info_card("ì…ë ¥í•˜ì‹  ì •ë³´", [
        f"ğŸ“… í•™ë²ˆ: {admission_year}í•™ë²ˆ",
        f"ğŸ“ ë³¸ì „ê³µ: {primary_major}",
        f"ğŸ“Š ì´ìˆ˜í•™ì : ì „í•„ {completed_required}í•™ì , ì „ì„  {completed_elective}í•™ì  (ì´ {total_credits}í•™ì )"
    ], "#667eea", "ğŸ“‹")
    
    # í•™ì  ê¸°ì¤€ ì¶”ì²œ
    if total_credits < 20:
        recommendation = "ì†Œë‹¨ìœ„ì „ê³µê³¼ì •(ë§ˆì´í¬ë¡œë””ê·¸ë¦¬) ë˜ëŠ” ë¶€ì „ê³µ"
        reason = "í˜„ì¬ ì´ìˆ˜í•™ì ì´ ì ì–´ ë¶€ë‹´ì´ ì ì€ ì œë„ë¥¼ ì¶”ì²œë“œë¦½ë‹ˆë‹¤."
    elif total_credits < 40:
        recommendation = "ë¶€ì „ê³µ ë˜ëŠ” ìœµí•©ë¶€ì „ê³µ"
        reason = "ì ì ˆí•œ í•™ì ì„ ì´ìˆ˜í•˜ì…¨ìŠµë‹ˆë‹¤. ë¶€ì „ê³µ ë„ì „ì„ ì¶”ì²œë“œë¦½ë‹ˆë‹¤."
    else:
        recommendation = "ë³µìˆ˜ì „ê³µ ë˜ëŠ” ìœµí•©ì „ê³µ"
        reason = "ì¶©ë¶„í•œ í•™ì ì„ ì´ìˆ˜í•˜ì…¨ìŠµë‹ˆë‹¤. ë³µìˆ˜ì „ê³µ ë„ì „ ê°€ëŠ¥í•©ë‹ˆë‹¤!"
    
    response += f"""
<div style="background: linear-gradient(135deg, #f093fb15 0%, #f5576c15 100%); border-left: 4px solid #f093fb; border-radius: 12px; padding: 16px; margin: 16px 0;">
    <h4 style="margin: 0 0 10px 0; color: #f093fb;">ğŸ¯ ì¶”ì²œ ë‹¤ì „ê³µ</h4>
    <p style="font-size: 1.1rem; font-weight: bold; color: #333; margin: 8px 0;">{recommendation}</p>
    <p style="color: #666; font-size: 0.9rem; margin: 8px 0;">ğŸ’¡ {reason}</p>
</div>
"""
    
    response += create_tip_box("ì™¼ìª½ 'ë‹¤ì „ê³µ ì œë„ ì•ˆë‚´' ë©”ë‰´ì—ì„œ ìƒì„¸ ì •ë³´ë¥¼ í™•ì¸í•˜ì„¸ìš”!")
    response += create_contact_box()
    
    return response, "RECOMMENDATION"

def handle_major_info(user_input, extracted_info, data_dict):
    """ì „ê³µ/ê³¼ì • ì„¤ëª… ì œê³µ - ë§ˆì´í¬ë¡œë””ê·¸ë¦¬ëŠ” microdegree_info ì‚¬ìš©"""
    entity = extracted_info.get('entity') or extracted_info.get('major')
    entity_type = extracted_info.get('entity_type')
    
    majors_info = data_dict.get('majors', MAJORS_INFO)
    microdegree_info = data_dict.get('microdegree', MICRODEGREE_INFO)
    
    # ì—”í‹°í‹°ê°€ ì—†ìœ¼ë©´ ìƒˆë¡œ ì¶”ì¶œ
    if not entity:
        entity, entity_type = extract_entity_from_text(user_input)
    
    # ì—”í‹°í‹°ê°€ ì—¬ì „íˆ ì—†ìœ¼ë©´ ì•ˆë‚´
    if not entity:
        response = create_header_card("ì „ê³µ/ê³¼ì • ì •ë³´", "ğŸ“", "#667eea")
        response += create_simple_card("<p style='margin:0;'>ì–´ë–¤ ì „ê³µì´ë‚˜ ê³¼ì •ì— ëŒ€í•´ ì•Œê³  ì‹¶ìœ¼ì‹ ê°€ìš”?</p>", "#f0f4ff", "#667eea")
        
        category_majors = get_majors_by_category()
        if category_majors and len(category_majors) > 1:
            response += "<div style='margin-top: 12px;'><strong>ğŸ“š ê³„ì—´ë³„ ì „ê³µ ëª©ë¡</strong></div>"
            response += format_majors_by_category_html(category_majors)
        
        response += create_tip_box("ì˜ˆì‹œ: \"ê²½ì˜í•™ì „ê³µ ì•Œë ¤ì¤˜\", \"ì‹í’ˆí’ˆì§ˆê´€ë¦¬ MD ì†Œê°œ\"")
        response += create_contact_box()
        return response, "MAJOR_INFO"
    
    # ğŸ”¥ ë§ˆì´í¬ë¡œë””ê·¸ë¦¬ ê³¼ì •ì¸ ê²½ìš° - ê°œì„ ëœ ê²€ìƒ‰
    if entity_type == 'microdegree' and not microdegree_info.empty:
        print(f"[DEBUG handle_major_info] ë§ˆì´í¬ë¡œë””ê·¸ë¦¬ ê²€ìƒ‰: {entity}")
        
        result = pd.DataFrame()
        
        # 1ì°¨: ì •í™•í•œ ë§¤ì¹­ (ëŒ€ì†Œë¬¸ì, ë„ì–´ì“°ê¸° ë¬´ì‹œ)
        entity_clean = entity.replace(' ', '').lower()
        for idx, row in microdegree_info.iterrows():
            course_name = str(row.get('ê³¼ì •ëª…', ''))
            course_clean = course_name.replace(' ', '').lower()
            
            if course_clean == entity_clean:
                result = microdegree_info.iloc[[idx]]
                print(f"[DEBUG] âœ… ì •í™• ë§¤ì¹­: {course_name}")
                break
        
        # 2ì°¨: ê³¼ì •ëª…ì´ ì—”í‹°í‹°ë¥¼ í¬í•¨
        if result.empty:
            for idx, row in microdegree_info.iterrows():
                course_name = str(row.get('ê³¼ì •ëª…', ''))
                course_clean = course_name.replace(' ', '').lower()
                
                if entity_clean in course_clean or course_clean in entity_clean:
                    result = microdegree_info.iloc[[idx]]
                    print(f"[DEBUG] âœ… ë¶€ë¶„ ë§¤ì¹­: {course_name}")
                    break
        
        # 3ì°¨: í‚¤ì›Œë“œ ê²€ìƒ‰ (MD ì œê±°)
        if result.empty:
            keyword = entity.replace('MD', '').replace('md', '').replace(' ', '').strip()
            print(f"[DEBUG] í‚¤ì›Œë“œ ê²€ìƒ‰: {keyword}")
            
            # í‚¤ì›Œë“œê°€ ê³¼ì •ëª…ì— í¬í•¨ë˜ëŠ”ì§€ í™•ì¸
            result = microdegree_info[
                microdegree_info['ê³¼ì •ëª…'].apply(
                    lambda x: keyword.lower() in str(x).replace(' ', '').lower()
                )
            ]
            
            if not result.empty:
                print(f"[DEBUG] âœ… í‚¤ì›Œë“œ ë§¤ì¹­: {result.iloc[0]['ê³¼ì •ëª…']}")
        
        # ê²€ìƒ‰ ì„±ê³µ
        if not result.empty:
            row = result.iloc[0]
            course_name = row.get('ê³¼ì •ëª…', entity)
            
            response = create_header_card(f"{course_name} ì†Œê°œ", "ğŸ“", "#a8edea")
            
            # ê³¼ì • ì„¤ëª…
            description = row.get('ê³¼ì •ì„¤ëª…', '')
            if description and pd.notna(description):
                response += f"""
<div style="background: white; border-left: 4px solid #a8edea; border-radius: 8px; padding: 16px; margin: 8px 0; box-shadow: 0 2px 4px rgba(0,0,0,0.1);">
    <div style="color: #11998e; font-weight: 600; margin-bottom: 8px;">ğŸ“– ê³¼ì • ì†Œê°œ</div>
    <p style="margin: 0; color: #333; line-height: 1.6;">{description}</p>
</div>
"""
            
            # ê¸°ë³¸ ì •ë³´
            response += f"""
<div style="background: white; border-left: 4px solid #11998e; border-radius: 8px; padding: 16px; margin: 8px 0; box-shadow: 0 2px 4px rgba(0,0,0,0.1);">
    <div style="color: #11998e; font-weight: 600; margin-bottom: 12px;">â„¹ï¸ ê¸°ë³¸ ì •ë³´</div>
"""
            
            # ì†Œì† ê³„ì—´
            category = row.get('ê³„ì—´', '-')
            if category and category != '-' and pd.notna(category):
                response += f'    <p style="margin: 8px 0; color: #333;"><strong>ğŸ›ï¸ ì†Œì†:</strong> {category}</p>\n'
            
            # ì œë„ìœ í˜•
            program_types = row.get('ì œë„ìœ í˜•', '')
            if program_types and pd.notna(program_types):
                response += f'    <p style="margin: 8px 0; color: #333;"><strong>ğŸ“‹ ì‹ ì²­ ê°€ëŠ¥ ì œë„:</strong> {program_types}</p>\n'
            
            # êµìœ¡ìš´ì˜ì „ê³µ
            edu_major = row.get('êµìœ¡ìš´ì˜ì „ê³µ', '')
            if edu_major and pd.notna(edu_major):
                response += f'    <p style="margin: 8px 0; color: #333;"><strong>ğŸ“ êµìœ¡ìš´ì˜ì „ê³µ:</strong> {edu_major}</p>\n'
            
            # ì—°ë½ì²˜
            contact = row.get('ì—°ë½ì²˜', '-')
            if contact and contact != '-' and pd.notna(contact):
                response += f'    <p style="margin: 8px 0; color: #333;"><strong>ğŸ“± ì—°ë½ì²˜:</strong> {contact}</p>\n'
            
            # ìœ„ì¹˜
            location = row.get('ìœ„ì¹˜', row.get('ì‚¬ë¬´ì‹¤ìœ„ì¹˜', '-'))
            if location and location != '-' and pd.notna(location):
                response += f'    <p style="margin: 8px 0; color: #333;"><strong>ğŸ“ ìœ„ì¹˜:</strong> {location}</p>\n'
            
            # í™ˆí˜ì´ì§€
            homepage = row.get('í™ˆí˜ì´ì§€', '-')
            if homepage and homepage != '-' and pd.notna(homepage) and str(homepage).startswith('http'):
                response += f'    <p style="margin: 8px 0; color: #333;"><strong>ğŸŒ í™ˆí˜ì´ì§€:</strong> <a href="{homepage}" target="_blank" style="color: #667eea; text-decoration: none;">{homepage} ğŸ”—</a></p>\n'
            
            response += "</div>"
            
            # ğŸ”¥ ìˆ˜ì •: course_name ì‚¬ìš©, ë§ˆì´í¬ë¡œë””ê·¸ë¦¬ ì „ìš© íŒ
            response += create_tip_box(f"ğŸ’¡ {course_name}ì˜ êµê³¼ëª©ì´ ê¶ê¸ˆí•˜ì‹œë©´ '{course_name} êµê³¼ëª© ì•Œë ¤ì¤˜'ë¼ê³  ë¬¼ì–´ë³´ì„¸ìš”!")
            response += create_contact_box()
            
            return response, "MAJOR_INFO"
        
        # ğŸ”¥ ë§ˆì´í¬ë¡œë””ê·¸ë¦¬ì—ì„œ ì°¾ì§€ ëª»í•œ ê²½ìš°
        else:
            response = create_header_card("ì „ê³µ/ê³¼ì • ì •ë³´", "ğŸ“", "#ff6b6b")
            response += create_warning_box(f"'{entity}' ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            response += create_contact_box()
            return response, "ERROR"
    
    # ğŸ”¥ ì¼ë°˜ ì „ê³µì¸ ê²½ìš° - majors_info ì‚¬ìš©
    if not majors_info.empty:
        search_keyword = entity.replace('ì „ê³µ', '').replace('ê³¼', '').replace('(', '').replace(')', '').replace(' ', '').strip()
        result = majors_info[majors_info['ì „ê³µëª…'].str.contains(search_keyword, case=False, na=False, regex=False)]
        
        if not result.empty:
            row = result.iloc[0]
            major_name = row['ì „ê³µëª…']
            
            response = create_header_card(f"{major_name} ì†Œê°œ", "ğŸ“", "#667eea")
            
            # ì „ê³µ ì„¤ëª…
            description = row.get('ì „ê³µì„¤ëª…', row.get('ì„¤ëª…', '-'))
            if description and description != '-' and pd.notna(description):
                response += f"""
<div style="background: white; border-left: 4px solid #667eea; border-radius: 8px; padding: 16px; margin: 8px 0; box-shadow: 0 2px 4px rgba(0,0,0,0.1);">
    <div style="color: #667eea; font-weight: 600; margin-bottom: 8px;">ğŸ“– ì „ê³µ ì†Œê°œ</div>
    <p style="margin: 0; color: #333; line-height: 1.6;">{description}</p>
</div>
"""
            
            # ê¸°ë³¸ ì •ë³´
            response += f"""
<div style="background: white; border-left: 4px solid #11998e; border-radius: 8px; padding: 16px; margin: 8px 0; box-shadow: 0 2px 4px rgba(0,0,0,0.1);">
    <div style="color: #11998e; font-weight: 600; margin-bottom: 12px;">â„¹ï¸ ê¸°ë³¸ ì •ë³´</div>
"""
            
            # ì†Œì† ê³„ì—´
            category = row.get('ê³„ì—´', '-')
            if category and category != '-' and pd.notna(category):
                response += f'    <p style="margin: 8px 0; color: #333;"><strong>ğŸ›ï¸ ì†Œì†:</strong> {category}</p>\n'
            
            # ì œë„ìœ í˜•
            program_types = row.get('ì œë„ìœ í˜•', '')
            if program_types and pd.notna(program_types):
                response += f'    <p style="margin: 8px 0; color: #333;"><strong>ğŸ“‹ ì‹ ì²­ ê°€ëŠ¥ ì œë„:</strong> {program_types}</p>\n'
            
            # ì—°ë½ì²˜
            contact = row.get('ì—°ë½ì²˜', '-')
            if contact and contact != '-' and pd.notna(contact):
                response += f'    <p style="margin: 8px 0; color: #333;"><strong>ğŸ“± ì—°ë½ì²˜:</strong> {contact}</p>\n'
            
            # ìœ„ì¹˜
            location = row.get('ìœ„ì¹˜', row.get('ì‚¬ë¬´ì‹¤ìœ„ì¹˜', '-'))
            if location and location != '-' and pd.notna(location):
                response += f'    <p style="margin: 8px 0; color: #333;"><strong>ğŸ“ ìœ„ì¹˜:</strong> {location}</p>\n'
            
            # í™ˆí˜ì´ì§€
            homepage = row.get('í™ˆí˜ì´ì§€', '-')
            if homepage and homepage != '-' and pd.notna(homepage) and str(homepage).startswith('http'):
                response += f'    <p style="margin: 8px 0; color: #333;"><strong>ğŸŒ í™ˆí˜ì´ì§€:</strong> <a href="{homepage}" target="_blank" style="color: #667eea; text-decoration: none;">{homepage} ğŸ”—</a></p>\n'
            
            response += "</div>"
            
            # ğŸ”¥ ì¼ë°˜ ì „ê³µìš© íŒ
            response += create_tip_box(f"ğŸ’¡ {major_name}ì„(ë¥¼) ë³µìˆ˜ì „ê³µ/ë¶€ì „ê³µìœ¼ë¡œ ì‹ ì²­í•˜ê³  ì‹¶ìœ¼ì‹œë‹¤ë©´ 'ë³µìˆ˜ì „ê³µ ì‹ ì²­ ë°©ë²•'ì„ ë¬¼ì–´ë³´ì„¸ìš”!")
            response += create_contact_box()
            
            return response, "MAJOR_INFO"
    
    # ì°¾ì§€ ëª»í•œ ê²½ìš°
    response = create_header_card("ì „ê³µ/ê³¼ì • ì •ë³´", "ğŸ“", "#ff6b6b")
    response += create_warning_box(f"'{entity}' ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    response += create_contact_box()
    return response, "ERROR"


def handle_major_search(user_input, extracted_info, data_dict):
    """ì „ê³µ/ê³¼ì • ê²€ìƒ‰ ë° ëª©ë¡ ì œê³µ - ë§ˆì´í¬ë¡œë””ê·¸ë¦¬ëŠ” microdegree_info ì‚¬ìš©"""
    majors_info = data_dict.get('majors', MAJORS_INFO)
    microdegree_info = data_dict.get('microdegree', MICRODEGREE_INFO)
    
    # í”„ë¡œê·¸ë¨ ì¶”ì¶œ
    program = extracted_info.get('program') or extract_program_from_text(user_input)
    
    # ğŸ”¥ ë§ˆì´í¬ë¡œë””ê·¸ë¦¬ ëª©ë¡ ìš”ì²­ - microdegree_info ì‚¬ìš©
    if program in ['ì†Œë‹¨ìœ„ì „ê³µê³¼ì •', 'ë§ˆì´í¬ë¡œë””ê·¸ë¦¬'] or 'ë§ˆì´í¬ë¡œë””ê·¸ë¦¬' in user_input.lower() or 'md' in user_input.lower():
        if not microdegree_info.empty and 'ê³¼ì •ëª…' in microdegree_info.columns:
            response = create_header_card("ì†Œë‹¨ìœ„ì „ê³µê³¼ì •(ë§ˆì´í¬ë¡œë””ê·¸ë¦¬) ëª©ë¡", "ğŸ“š", "#a8edea")
            
            # ê³„ì—´ë³„ ê·¸ë£¹í™”
            category_courses = get_majors_by_category("ë§ˆì´í¬ë¡œë””ê·¸ë¦¬")
            
            if category_courses:
                response += format_majors_by_category_html(category_courses)
            else:
                response += """
<div style="background: white; border-radius: 8px; padding: 16px; margin: 8px 0;">
    <p style="margin-bottom: 12px; color: #555;">ë§ˆì´í¬ë¡œë””ê·¸ë¦¬ ê³¼ì • ëª©ë¡ì…ë‹ˆë‹¤:</p>
    <ul style="list-style: none; padding: 0;">
"""
                for _, row in microdegree_info.iterrows():
                    course_name = row.get('ê³¼ì •ëª…', '')
                    description = row.get('ê³¼ì •ì„¤ëª…', '')
                    if description and pd.notna(description) and len(str(description)) > 50:
                        description = str(description)[:50] + "..."
                    
                    response += f"""
        <li style="margin: 8px 0; padding: 12px; background: #f8f9fa; border-radius: 6px;">
            <strong style="color: #11998e;">â€¢ {course_name}</strong>
            {f'<br><span style="font-size: 0.9em; color: #666;">{description}</span>' if description and pd.notna(description) else ''}
        </li>
"""
                response += """
    </ul>
</div>
"""
            
            response += create_tip_box("ğŸ’¡ ê° ê³¼ì •ì— ëŒ€í•´ ë” ì•Œê³  ì‹¶ìœ¼ì‹œë‹¤ë©´ 'ì‹í’ˆí’ˆì§ˆê´€ë¦¬ MD ì•Œë ¤ì¤˜'ì²˜ëŸ¼ ê³¼ì •ëª…ì„ ë¬¼ì–´ë³´ì„¸ìš”!")
            response += create_contact_box()
            
            return response, "MAJOR_SEARCH"
    
    # ì¼ë°˜ ì „ê³µ ê²€ìƒ‰ (ë³µìˆ˜ì „ê³µ, ë¶€ì „ê³µ ë“±)
    if program:
        category_majors = get_majors_by_category(program)
        
        if category_majors:
            response = create_header_card(f"{program} ì „ê³µ ëª©ë¡", "ğŸ“š", "#667eea")
            response += format_majors_by_category_html(category_majors)
            response += create_contact_box()
            return response, "MAJOR_SEARCH"
    
    # ì „ì²´ ì „ê³µ ëª©ë¡
    response = create_header_card("ì „ê³µ ëª©ë¡", "ğŸ“š", "#667eea")
    category_majors = get_majors_by_category()
    
    if category_majors:
        response += format_majors_by_category_html(category_majors)
    else:
        response += create_warning_box("ì „ê³µ ëª©ë¡ì„ ë¶ˆëŸ¬ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    
    response += create_contact_box()
    
    return response, "MAJOR_SEARCH"

def handle_greeting(user_input, extracted_info, data_dict):
    response = create_header_card("ì•ˆë…•í•˜ì„¸ìš”!", "ğŸ‘‹", "#667eea")
    response += create_simple_card("<p style='margin:0; font-size: 1rem;'><strong>ë‹¤ì „ê³µ ì•ˆë‚´ AIê¸°ë°˜ ì±—ë´‡</strong>ì…ë‹ˆë‹¤ ğŸ˜Š</p>", "#f0f4ff", "#667eea")
    
    response += """
<div style="background: white; border-radius: 12px; padding: 16px; margin: 12px 0; box-shadow: 0 2px 10px rgba(0,0,0,0.08);">
    <h4 style="margin: 0 0 12px 0; color: #333;">ğŸ¯ ë¬´ì—‡ì„ ë„ì™€ë“œë¦´ê¹Œìš”?</h4>
    <div style="display: grid; grid-template-columns: repeat(2, 1fr); gap: 10px;">
        <div style="background: #e3f2fd; padding: 10px; border-radius: 8px;">
            <strong style="color: #1565c0;">ğŸ“ ì‹ ì²­</strong><br>
            <span style="font-size: 0.85rem; color: #666;">"ì‹ ì²­ ìê²©ì´ ë­ì•¼?"</span>
        </div>
        <div style="background: #e8f5e9; padding: 10px; border-radius: 8px;">
            <strong style="color: #2e7d32;">ğŸ“Š ë¹„êµ</strong><br>
            <span style="font-size: 0.85rem; color: #666;">"ë³µìˆ˜ì „ê³µ vs ë¶€ì „ê³µ"</span>
        </div>
        <div style="background: #fff3e0; padding: 10px; border-radius: 8px;">
            <strong style="color: #ef6c00;">ğŸ“– í•™ì </strong><br>
            <span style="font-size: 0.85rem; color: #666;">"ëª‡ í•™ì  í•„ìš”í•´?"</span>
        </div>
        <div style="background: #fce4ec; padding: 10px; border-radius: 8px;">
            <strong style="color: #c2185b;">ğŸ¯ ì¶”ì²œ</strong><br>
            <span style="font-size: 0.85rem; color: #666;">"ë‹¤ì „ê³µ ì¶”ì²œí•´ì¤˜"</span>
        </div>
    </div>
</div>
"""
    
    response += create_tip_box("ìœ„ì˜ <strong>'ğŸ’¡ ì–´ë–¤ ì§ˆë¬¸ì„ í•´ì•¼ í• ì§€ ëª¨ë¥´ê² ë‚˜ìš”?'</strong>ë¥¼ í´ë¦­í•´ë³´ì„¸ìš”!")
    
    return response, "GREETING"

def handle_blocked(user_input, extracted_info, data_dict):
    response = create_header_card("ì ê¹ë§Œìš”!", "âš ï¸", "#ff6b6b")
    response += create_warning_box("ë¶€ì ì ˆí•œ í‘œí˜„ì´ ê°ì§€ë˜ì—ˆì–´ìš”.")
    response += create_simple_card("<p style='margin:0;'>ë‹¤ì „ê³µ ê´€ë ¨ ì§ˆë¬¸ì„ í•´ì£¼ì‹œë©´ ì¹œì ˆí•˜ê²Œ ë‹µë³€ë“œë¦´ê²Œìš”! ğŸ˜Š</p>", "#f0f7ff", "#007bff")
    return response, "BLOCKED"


def handle_out_of_scope(user_input, extracted_info, data_dict):
    response = create_header_card("ë²”ìœ„ ì™¸ ì§ˆë¬¸", "ğŸš«", "#636e72")
    response += create_simple_card("<p style='margin:0;'>ì €ëŠ” <strong>ë‹¤ì „ê³µ ì•ˆë‚´ AIê¸°ë°˜ ì±—ë´‡</strong>ì´ì—ìš”.</p>", "#f8f9fa", "#6c757d")
    
    response += """
<div style="background: white; border-radius: 12px; padding: 16px; margin: 12px 0; box-shadow: 0 2px 10px rgba(0,0,0,0.08);">
    <h4 style="margin: 0 0 12px 0; color: #333;">ğŸ’¬ ì´ëŸ° ì§ˆë¬¸ì€ ë‹µë³€í•  ìˆ˜ ìˆì–´ìš”!</h4>
    <div style="display: grid; grid-template-columns: repeat(2, 1fr); gap: 8px; font-size: 0.9rem;">
        <div style="padding: 8px; background: #e3f2fd; border-radius: 6px;">ğŸ“ ë‹¤ì „ê³µ ì‹ ì²­ ê¸°ê°„ ì•Œë ¤ì¤˜</div>
        <div style="padding: 8px; background: #e3f2fd; border-radius: 6px;">ğŸ“ ë³µìˆ˜ì „ê³µì´ ë­ì•¼</div>
        <div style="padding: 8px; background: #e8f5e9; border-radius: 6px;">ğŸ“Š ìœµí•©ì „ê³µ, ìœµí•©ë¶€ì „ê³µ ë¹„êµí•´ì¤˜</div>
        <div style="padding: 8px; background: #fce4ec; border-radius: 6px;">ğŸ“– ì‘ìš©ìˆ˜í•™ì „ê³µ ì†Œê°œí•´ì¤˜</div>
        <div style="padding: 8px; background: #fce4ec; border-radius: 6px;">ğŸ“– ì „ìê³µí•™ì „ê³µ êµê³¼ëª© ì•Œë ¤ì¤˜</div>
        <div style="padding: 8px; background: #fce4ec; border-radius: 6px;">ğŸ“ ê²½ì˜í•™ì „ê³µ ì—°ë½ì²˜ ë­ì•¼?</div>
        <div style="padding: 8px; background: #fce4ec; border-radius: 6px;">ğŸ“– ë§ˆì´í¬ë¡œë””ê·¸ë¦¬ ê³¼ì • ëª©ë¡ ì•Œë ¤ì¤˜</div>
        <div style="padding: 8px; background: #fce4ec; border-radius: 6px;">ğŸ“– ë°˜ë ¤ë™ë¬¼ MD êµê³¼ëª© ì•Œë ¤ì¤˜</div>
</div>
</div>
"""
    
    response += create_tip_box("ìœ„ì˜ <strong>'ğŸ’¡ ì–´ë–¤ ì§ˆë¬¸ì„ í•´ì•¼ í• ì§€ ëª¨ë¥´ê² ë‚˜ìš”?'</strong>ë¥¼ í´ë¦­í•´ë³´ì„¸ìš”!")
    
    return response, "OUT_OF_SCOPE"


def handle_general(user_input, extracted_info, data_dict):
    return f"ì£„ì†¡í•©ë‹ˆë‹¤. ë‹µë³€ì„ ìƒì„±í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.\n{CONTACT_MESSAGE}", "ERROR"


# í•¸ë“¤ëŸ¬ ë§¤í•‘ (FAQë¡œ ì²˜ë¦¬ë˜ì§€ ì•ŠëŠ” ê²½ìš° ì‚¬ìš©)
FALLBACK_HANDLERS = {
    'COURSE_SEARCH': handle_course_search,
    'CONTACT_SEARCH': handle_contact_search,
    'MAJOR_SEARCH': handle_major_search,
    'MAJOR_INFO': handle_major_info,
    'RECOMMENDATION': handle_recommendation,
    'GREETING': handle_greeting,
    'BLOCKED': handle_blocked,
    'OUT_OF_SCOPE': handle_out_of_scope,
    'GENERAL': handle_general,
}


# ============================================================
# ğŸ¤– í†µí•© ì‘ë‹µ ìƒì„± í•¨ìˆ˜
# ============================================================

def save_previous_question(user_input):
    """ì„¸ì…˜ ìƒíƒœì— ì´ì „ ì§ˆë¬¸ ì €ì¥"""
    if 'previous_question' not in st.session_state:
        st.session_state.previous_question = None
    
    st.session_state.previous_question = user_input
    
def generate_ai_response(user_input, chat_history, data_dict):
    """
    í†µí•© ì‘ë‹µ ìƒì„± í•¨ìˆ˜
    1. FAQ ë§¤í•‘ ê²€ìƒ‰ (ìš°ì„ )
    2. Semantic Router + í•¸ë“¤ëŸ¬
    3. AI Fallback
    """
    start_time = time.time()
    faq_df = data_dict.get('faq_mapping', FAQ_MAPPING)

    # 1. ì˜ë„ ë¶„ë¥˜
    intent, method, extracted_info = classify_intent(user_input)
    
    # ì°¨ë‹¨ëœ ê²½ìš° ë°”ë¡œ ì²˜ë¦¬
    if intent == 'BLOCKED':
        response, response_type = handle_blocked(user_input, extracted_info, data_dict)
        log_to_sheets(
            st.session_state.get('session_id', 'unknown'),
            user_input, response, 'blocked', 
            time.time() - start_time,
            st.session_state.get('page', 'AIì±—ë´‡ ìƒë‹´')
        )
        return response, response_type
    
    # ì¸ì‚¬ë§ ì²˜ë¦¬
    if intent == 'GREETING':
        response, response_type = handle_greeting(user_input, extracted_info, data_dict)
        log_to_sheets(
            st.session_state.get('session_id', 'unknown'),
            user_input, response, 'greeting', 
            time.time() - start_time,
            st.session_state.get('page', 'AIì±—ë´‡ ìƒë‹´')
        )
        return response, response_type
    
    # 2. FAQ ë§¤í•‘ ê²€ìƒ‰
    faq_match, score = search_faq_mapping(user_input, faq_df)
    
    if faq_match is not None and score >= 10:
        # FAQ ë§¤ì¹­ ì„±ê³µ
        raw_answer = faq_match.get('answer', '')
        program = faq_match.get('program', '')
        
        # AIë¡œ ëŒ€í™”ì²´ ë³€í™˜
        conversational_answer = generate_conversational_response(raw_answer, user_input, program)
        
        # HTML í¬ë§·íŒ…
        formatted_response = format_faq_response_html(conversational_answer, program)
        formatted_response += create_contact_box()
        
        response_type = f"FAQ_{faq_match.get('intent', 'UNKNOWN')}"
        log_to_sheets(
            st.session_state.get('session_id', 'unknown'),
            user_input, formatted_response, 'faq', 
            time.time() - start_time,
            st.session_state.get('page', 'AIì±—ë´‡ ìƒë‹´')
        )
        return formatted_response, response_type
    
    # 3. íŠ¹ìˆ˜ í•¸ë“¤ëŸ¬ í•„ìš”í•œ ê²½ìš° (ì—°ë½ì²˜, ê³¼ëª© ê²€ìƒ‰, ì¶”ì²œ)
    if intent in FALLBACK_HANDLERS:
        response, response_type = FALLBACK_HANDLERS[intent](user_input, extracted_info, data_dict)
        log_to_sheets(
            st.session_state.get('session_id', 'unknown'),
            user_input, response, 'semantic_router', 
            time.time() - start_time,
            st.session_state.get('page', 'AIì±—ë´‡ ìƒë‹´')
        )
        return response, response_type
    
    # 4. AI Fallback - ì¼ë°˜ ë‹¤ì „ê³µ ì§ˆë¬¸
    try:
        # ğŸ”¥ [ì¶”ê°€] ê´€ë ¨ FAQ ì°¾ê¸°
        related_faqs = []
        user_clean = user_input.lower().replace(' ', '')
    
        for _, row in faq_df.iterrows():
            program = str(row.get('program', '')).replace(' ', '')
            keywords = str(row.get('keyword', '')).split(',')
        
            # í”„ë¡œê·¸ë¨ëª…ì´ë‚˜ í‚¤ì›Œë“œê°€ ì§ˆë¬¸ì— í¬í•¨ë˜ë©´
            if program in user_clean:
                keyword_match = any(kw.strip().replace(' ', '').lower() in user_clean 
                                for kw in keywords if kw.strip())
                if keyword_match:
                    related_faqs.append(row)
    
        # ğŸ”¥ FAQ ì»¨í…ìŠ¤íŠ¸ ìƒì„±
        faq_context = ""
        if related_faqs:
            faq_context = "\n\n[ì°¸ê³  FAQ ì •ë³´]\n"
            for faq in related_faqs[:3]:  # ìµœëŒ€ 3ê°œ
                faq_context += f"""
    **{faq.get('program', '')} - {faq.get('intent', '')}**
    {faq.get('answer', '')}
    ---
    """
    
        # í”„ë¡œê·¸ë¨ ì •ë³´ ì»¨í…ìŠ¤íŠ¸ ìƒì„±
        context_parts = []
        programs = data_dict.get('programs', {})

        if programs:
            for prog_name, prog_info in programs.items():
                context_parts.append(f"[{prog_name}]\n- ì„¤ëª…: {prog_info.get('description', '')}\n- ì´ìˆ˜í•™ì : {prog_info.get('credits_multi', '')}\n- ì‹ ì²­ìê²©: {prog_info.get('qualification', '')}")
    
        context = "\n\n".join(context_parts[:5])  # ìƒìœ„ 5ê°œë§Œ
    
        # ğŸ”¥ í”„ë¡¬í”„íŠ¸ì— FAQ ì •ë³´ ì¶”ê°€
        prompt = f"""ë‹¹ì‹ ì€ í•œê²½êµ­ë¦½ëŒ€í•™êµ ë‹¤ì „ê³µ ì•ˆë‚´ AIì±—ë´‡ì…ë‹ˆë‹¤.
    ë‹¤ìŒ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ í•™ìƒ ì§ˆë¬¸ì— ì¹œì ˆí•˜ê²Œ ë‹µë³€í•˜ì„¸ìš”.

    [í”„ë¡œê·¸ë¨ ì •ë³´]
    {context}

    {faq_context}

    [í•™ìƒ ì§ˆë¬¸]
    {user_input}

    [ì§€ì¹¨]
    1. ìœ„ FAQ ì •ë³´ê°€ ìˆë‹¤ë©´ ë°˜ë“œì‹œ ê·¸ ë‚´ìš©ì„ ê¸°ë°˜ìœ¼ë¡œ ë‹µë³€í•˜ì„¸ìš”
    2. ì§ˆë¬¸ì—ì„œ ì—¬ëŸ¬ í”„ë¡œê·¸ë¨ì„ ë¬¼ì–´ë³´ë©´ ê°ê° êµ¬ë¶„í•´ì„œ ë‹µë³€
    3. "~í•©ë‹ˆë‹¤", "~í•´ì£¼ì„¸ìš”" ë“± ì •ì¤‘í•œ ì¢…ê²°ì–´ë¯¸ ì‚¬ìš©
    4. ì¹œê·¼í•˜ê³  ê³µì†í•œ ë§íˆ¬ ì‚¬ìš©
    5. í•µì‹¬ ì •ë³´ë¥¼ ëª…í™•í•˜ê²Œ ì „ë‹¬
    6. ê° í”„ë¡œê·¸ë¨ë³„ë¡œ ëª…í™•íˆ êµ¬ë¶„í•˜ì—¬ ì„¤ëª…
    7. ëª¨ë¥´ëŠ” ë‚´ìš©ì€ í•™ì‚¬ì§€ì›íŒ€(031-670-5035) ë¬¸ì˜ ì•ˆë‚´
    8. ì´ëª¨ì§€ ì ì ˆíˆ ì‚¬ìš© (ğŸ“…, ğŸ“‹, âœ… ë“±)
    9. í•™ì‚¬ê³µì§€ ë§í¬: {ACADEMIC_NOTICE_URL}
    """
        
        response = client.models.generate_content(
            model='gemini-2.0-flash-exp',
            contents=prompt,
            config={'temperature': 0.7, 'max_output_tokens': 1500}
        )
        
        ai_response = response.text.strip()
        
        # ë‹µë³€ ì‹¤íŒ¨ ê°ì§€
        failure_keywords = ['ì˜ ëª¨ë¥´ê² ìŠµë‹ˆë‹¤', 'í™•ì¸í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤', 'ì£„ì†¡í•©ë‹ˆë‹¤', 'ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤']
        if len(ai_response) < 10 or any(kw in ai_response.lower() for kw in failure_keywords):
            log_failed_to_sheets(
                st.session_state.get('session_id', 'unknown'),
                user_input, ai_response, "AIê°€ ì ì ˆí•œ ë‹µë³€ì„ ìƒì„±í•˜ì§€ ëª»í•¨"
            )
        
        formatted_response = f"""
<div style="background: linear-gradient(135deg, #667eea15 0%, #764ba215 100%); border-left: 4px solid #667eea; border-radius: 12px; padding: 16px; margin: 12px 0;">
    {ai_response}
</div>
"""
        formatted_response += create_contact_box()
        
        log_to_sheets(
            st.session_state.get('session_id', 'unknown'),
            user_input, formatted_response, 'ai', 
            time.time() - start_time,
            st.session_state.get('page', 'AIì±—ë´‡ ìƒë‹´')
        )
        return formatted_response, "AI_RESPONSE"
        
    except Exception as e:
        response, response_type = handle_out_of_scope(user_input, extracted_info, data_dict)
        log_to_sheets(
            st.session_state.get('session_id', 'unknown'),
            user_input, response, 'failed', 
            time.time() - start_time,
            st.session_state.get('page', 'AIì±—ë´‡ ìƒë‹´')
        )
        log_failed_to_sheets(
            st.session_state.get('session_id', 'unknown'),
            user_input, str(e), "ì˜ˆì™¸ ë°œìƒ"
        )
        return response, response_type
        
        return formatted_response, "AI_RESPONSE"
        
    except Exception as e:
        return handle_out_of_scope(user_input, extracted_info, data_dict)


# ============================================================
# ğŸ“Š ì´ìˆ˜ì²´ê³„ë„ ë° ê³¼ëª© í‘œì‹œ í•¨ìˆ˜
# ============================================================

def display_curriculum_image(major, program_type):
    """ì´ìˆ˜ì²´ê³„ë„/ê³¼ì • ì•ˆë‚´ ì´ë¯¸ì§€ í‘œì‹œ"""
    if not major or major == "ì„ íƒ ì•ˆ í•¨":
        return
    
    is_fusion = program_type == "ìœµí•©ì „ê³µ"
    is_micro = "ì†Œë‹¨ìœ„" in program_type or "ë§ˆì´í¬ë¡œ" in program_type
    
    if not is_fusion and not is_micro:
        return
    
    if CURRICULUM_MAPPING.empty:
        return
    
    def match_program_type_for_image(type_value):
        type_str = str(type_value).strip().lower()
        if is_fusion:
            return "ìœµí•©ì „ê³µ" in type_str and "ìœµí•©ë¶€ì „ê³µ" not in type_str
        if is_micro:
            return any(kw in type_str for kw in ['ì†Œë‹¨ìœ„', 'ë§ˆì´í¬ë¡œ', 'md'])
        return False
    
    clean_major = major
    if major.endswith(')') and '(' in major:
        last_open_paren = major.rfind('(')
        if last_open_paren > 0:
            clean_major = major[:last_open_paren].strip()
    
    search_keyword = clean_major.replace('ì „ê³µ', '').replace('ê³¼ì •', '').replace('ì „ë¬¸ê°€', '').replace('MD', '').replace('(', '').replace(')', '').replace(' ', '').strip()
    
    type_matched = CURRICULUM_MAPPING[CURRICULUM_MAPPING['ì œë„ìœ í˜•'].apply(match_program_type_for_image)]
    
    if type_matched.empty:
        return
    
    filtered = type_matched[type_matched['ì „ê³µëª…'] == clean_major]
    
    if filtered.empty:
        filtered = type_matched[type_matched['ì „ê³µëª…'] == major]
    
    if filtered.empty:
        clean_major_no_space = clean_major.replace(' ', '')
        for _, row in type_matched.iterrows():
            cm_major = str(row['ì „ê³µëª…'])
            cm_major_no_space = cm_major.replace(' ', '')
            if clean_major_no_space == cm_major_no_space:
                filtered = type_matched[type_matched['ì „ê³µëª…'] == cm_major]
                break
    
    if filtered.empty and len(search_keyword) >= 2:
        for _, row in type_matched.iterrows():
            cm_major = str(row['ì „ê³µëª…'])
            cm_keyword = cm_major.replace('ì „ê³µ', '').replace('ê³¼ì •', '').replace('ì „ë¬¸ê°€', '').replace('MD', '').replace('(', '').replace(')', '').replace(' ', '').strip()
            if len(cm_keyword) >= 2 and len(search_keyword) >= 2:
                if search_keyword in cm_keyword or cm_keyword in search_keyword:
                    filtered = type_matched[type_matched['ì „ê³µëª…'] == cm_major]
                    break
    
    if not filtered.empty:
        images_shown = 0
        missing_files = []
        total_images = len(filtered)
        
        for idx, row in filtered.iterrows():
            filename = row['íŒŒì¼ëª…']
            
            if pd.notna(filename) and str(filename).strip():
                filename_str = str(filename).strip()
                
                if ',' in filename_str:
                    file_list = [f.strip() for f in filename_str.split(',')]
                    for file in file_list:
                        image_path = f"{CURRICULUM_IMAGES_PATH}/{file}"
                        if os.path.exists(image_path):
                            if is_fusion:
                                caption = f"{clean_major} ì´ìˆ˜ì²´ê³„ë„"
                            else:
                                caption = f"{clean_major} ê³¼ì • ì•ˆë‚´ ({images_shown + 1})"
                            st.image(image_path, caption=caption)
                            images_shown += 1
                        else:
                            missing_files.append(file)
                else:
                    image_path = f"{CURRICULUM_IMAGES_PATH}/{filename_str}"
                    
                    if os.path.exists(image_path):
                        if is_fusion:
                            caption = f"{clean_major} ì´ìˆ˜ì²´ê³„ë„"
                        else:
                            if total_images > 1:
                                caption = f"{clean_major} ê³¼ì • ì•ˆë‚´ ({images_shown + 1}/{total_images})"
                            else:
                                caption = f"{clean_major} ê³¼ì • ì•ˆë‚´"
                        st.image(image_path, caption=caption)
                        images_shown += 1
                    else:
                        missing_files.append(filename_str)
        
        if missing_files:
            st.warning(f"âš ï¸ ë‹¤ìŒ ì´ë¯¸ì§€ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤:")
            for missing_file in missing_files:
                st.caption(f"   â€¢ `{CURRICULUM_IMAGES_PATH}/{missing_file}`")
        
        if images_shown == 0 and not missing_files:
            st.caption("ğŸ“· ì´ë¯¸ì§€ íŒŒì¼ ì¤€ë¹„ ì¤‘ì…ë‹ˆë‹¤.")
    else:
        st.info(f"ğŸ’¡ '{major}' ë˜ëŠ” '{clean_major}'ì— í•´ë‹¹í•˜ëŠ” ì´ë¯¸ì§€ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")


def render_course_list(df, is_micro):
    for idx, row in df.iterrows():
        course_name = row.get('ê³¼ëª©ëª…', '')
        credit = f"{int(row.get('í•™ì ', 0))}í•™ì " if pd.notna(row.get('í•™ì ')) else ""
        desc = row.get('êµê³¼ëª©ê°œìš”')

        title = f"ğŸ“˜ {course_name} ({credit})"

        with st.expander(title):
            if desc and pd.notna(desc) and str(desc).strip():
                st.write(desc)
            else:
                st.info("êµê³¼ëª© ê°œìš” ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤.")

            edu_dept = row.get('êµìœ¡ ìš´ì˜ì „ê³µ') or row.get('êµìœ¡ìš´ì˜ì „ê³µ', '')
            if is_micro and pd.notna(edu_dept) and str(edu_dept).strip():
                st.caption(f"ğŸ« ìš´ì˜ì „ê³µ: {str(edu_dept).strip()}")


def display_courses(major, program_type):
    """ê³¼ëª© ì •ë³´ í‘œì‹œ - ìˆ˜ì • ë²„ì „"""
    if not major or major == "ì„ íƒ ì•ˆ í•¨":
        return False
    
    if COURSES_DATA.empty:
        st.info("êµê³¼ëª© ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return False
    
    is_micro = "ì†Œë‹¨ìœ„" in program_type or "ë§ˆì´í¬ë¡œ" in program_type
    
    def match_program_type_for_courses(type_value):
        """ì œë„ìœ í˜• ë§¤ì¹­ - ê°œì„  ë²„ì „"""
        type_str = str(type_value).strip()
        type_list = [t.strip() for t in type_str.split(',')]
        
        if is_micro:
            return any(kw in type_str.lower() for kw in ['ì†Œë‹¨ìœ„', 'ë§ˆì´í¬ë¡œ', 'md'])
        
        if program_type == "ë¶€ì „ê³µ":
            return "ë¶€ì „ê³µ" in type_list and "ìœµí•©ë¶€ì „ê³µ" not in type_list
        
        if program_type == "ìœµí•©ì „ê³µ":
            return "ìœµí•©ì „ê³µ" in type_list
        
        if program_type == "ìœµí•©ë¶€ì „ê³µ":
            return "ìœµí•©ë¶€ì „ê³µ" in type_list
        
        if program_type == "ì—°ê³„ì „ê³µ":
            return "ì—°ê³„ì „ê³µ" in type_list
        
        return program_type in type_list
    
    clean_major = major
    display_major = major
    
    if major.endswith(')') and '(' in major:
        last_open_paren = major.rfind('(')
        if last_open_paren > 0:
            clean_major = major[:last_open_paren].strip()
            display_major = clean_major
    
    courses = COURSES_DATA[
        (COURSES_DATA['ì „ê³µëª…'] == clean_major) & 
        (COURSES_DATA['ì œë„ìœ í˜•'].apply(match_program_type_for_courses))
    ]
    
    if courses.empty and is_micro:
        keyword = clean_major.replace('ì „ê³µ', '').replace('ê³¼ì •', '').replace('ì „ë¬¸ê°€', '').replace('MD', '').replace(' ', '').strip()
        type_matched = COURSES_DATA[COURSES_DATA['ì œë„ìœ í˜•'].apply(match_program_type_for_courses)]
        
        for course_major in type_matched['ì „ê³µëª…'].unique():
            cm_str = str(course_major)
            if 'MD' in cm_str or 'md' in cm_str.lower():
                cm_keyword = cm_str.replace('MD', '').replace('md', '').replace(' ', '').strip()
                if len(keyword) >= 2 and len(cm_keyword) >= 2:
                    if keyword[:2] in cm_keyword or cm_keyword[:2] in keyword:
                        courses = type_matched[type_matched['ì „ê³µëª…'] == course_major]
                        display_major = cm_str
                        break

    if courses.empty:
        keyword = clean_major.replace('ì „ê³µ', '').replace('ê³¼ì •', '').replace('(', '').replace(')', '')[:4]
        if keyword:
            courses = COURSES_DATA[
                (COURSES_DATA['ì „ê³µëª…'].str.contains(keyword, na=False, regex=False)) & 
                (COURSES_DATA['ì œë„ìœ í˜•'].apply(match_program_type_for_courses))
            ]
            if not courses.empty:
                display_major = courses['ì „ê³µëª…'].iloc[0]
    
    display_program_type = "ì†Œë‹¨ìœ„ì „ê³µê³¼ì •(ë§ˆì´í¬ë¡œë””ê·¸ë¦¬)" if is_micro else program_type
    
    if not courses.empty:
        st.subheader(f"ğŸ“š êµê³¼ëª© ì•ˆë‚´")
        
        years = sorted([int(y) for y in courses['í•™ë…„'].unique() if pd.notna(y)])
        
        if years:
            tabs = st.tabs([f"{year}í•™ë…„" for year in years])
            
            for idx, year in enumerate(years):
                with tabs[idx]:
                    year_courses = courses[courses['í•™ë…„'] == year]
                    semesters = sorted([int(s) for s in year_courses['í•™ê¸°'].unique() if pd.notna(s)])
                    
                    for semester in semesters:
                        st.markdown(f"#### ğŸ“… {semester}í•™ê¸°")
                        semester_courses = year_courses[year_courses['í•™ê¸°'] == semester]
                        
                        required = semester_courses[semester_courses['ì´ìˆ˜êµ¬ë¶„'].str.contains('í•„ìˆ˜', na=False)]
                        elective = semester_courses[semester_courses['ì´ìˆ˜êµ¬ë¶„'].str.contains('ì„ íƒ', na=False)]
                        
                        col1, col2 = st.columns(2)
                        
                        with col1:
                            if not required.empty:
                                st.markdown("**ğŸ”´ ì „ê³µí•„ìˆ˜**")
                                render_course_list(required, is_micro)
                                                                    
                        with col2:
                            if not elective.empty:
                                st.markdown("**ğŸŸ¢ ì „ê³µì„ íƒ**")
                                render_course_list(elective, is_micro)
                        
                        st.divider()
        else:
            semesters = sorted([int(s) for s in courses['í•™ê¸°'].unique() if pd.notna(s)])
            
            if semesters:
                for semester in semesters:
                    st.markdown(f"#### ğŸ“… {semester}í•™ê¸°")
                    semester_courses = courses[courses['í•™ê¸°'] == semester]
                    
                    has_required = not semester_courses[semester_courses['ì´ìˆ˜êµ¬ë¶„'].str.contains('í•„ìˆ˜', na=False)].empty
                    has_elective = not semester_courses[semester_courses['ì´ìˆ˜êµ¬ë¶„'].str.contains('ì„ íƒ', na=False)].empty
                    
                    if has_required or has_elective:
                        col1, col2 = st.columns(2)
                        
                        with col1:
                            required = semester_courses[semester_courses['ì´ìˆ˜êµ¬ë¶„'].str.contains('í•„ìˆ˜', na=False)]
                            if not required.empty:
                                st.markdown("**ğŸ”´ ì „ê³µí•„ìˆ˜**")
                                render_course_list(required, is_micro)
                        
                        with col2:
                            elective = semester_courses[semester_courses['ì´ìˆ˜êµ¬ë¶„'].str.contains('ì„ íƒ', na=False)]
                            if not elective.empty:
                                st.markdown("**ğŸŸ¢ ì „ê³µì„ íƒ**")
                                render_course_list(elective, is_micro)
                    
                    # ğŸ”¥ ìˆ˜ì •: else ë¸”ë¡ì—ì„œë„ render_course_list ì‚¬ìš©!
                    else:
                        st.markdown("**ğŸ“š êµê³¼ëª© ëª©ë¡**")
                        render_course_list(semester_courses, is_micro)
                    
                    st.divider()
            else:
                # ğŸ”¥ ìˆ˜ì •: ì—¬ê¸°ì„œë„ render_course_list ì‚¬ìš©!
                st.markdown("**ğŸ“š êµê³¼ëª© ëª©ë¡**")
                render_course_list(courses, is_micro)
        
        st.markdown("---")
        display_major_contact(display_major, program_type)
        return True
    else:
        st.info(f"'{display_major}' êµê³¼ëª© ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return False

def display_major_contact(major, program_type="ì „ê³µ"):
    """ì „ê³µ ì—°ë½ì²˜ í‘œì‹œ - ë§ˆì´í¬ë¡œë””ê·¸ë¦¬ ì§€ì›"""
    
    # ğŸ”¥ ë§ˆì´í¬ë¡œë””ê·¸ë¦¬ ì²´í¬
    is_micro = "ì†Œë‹¨ìœ„" in program_type or "ë§ˆì´í¬ë¡œ" in program_type
    
    # ë§ˆì´í¬ë¡œë””ê·¸ë¦¬ì¸ ê²½ìš° MICRODEGREE_INFOì—ì„œ ì°¾ê¸°
    if is_micro and not MICRODEGREE_INFO.empty:
        clean_major = major
        
        # ê´„í˜¸ ì œê±°
        if major.endswith(')') and '(' in major:
            last_open_paren = major.rfind('(')
            if last_open_paren > 0:
                clean_major = major[:last_open_paren].strip()
        
        # MD ì œê±°
        clean_major = clean_major.replace(' MD', '').replace('MD', '').strip()
        
        # ğŸ”¥ MICRODEGREE_INFOì—ì„œ ê²€ìƒ‰
        contact_row = pd.DataFrame()
        
        # 1ì°¨: ì •í™•í•œ ê³¼ì •ëª… ë§¤ì¹­
        if 'ê³¼ì •ëª…' in MICRODEGREE_INFO.columns:
            contact_row = MICRODEGREE_INFO[MICRODEGREE_INFO['ê³¼ì •ëª…'] == major]
        
        # 2ì°¨: ê´„í˜¸ ì œê±° í›„ ë§¤ì¹­
        if contact_row.empty:
            contact_row = MICRODEGREE_INFO[MICRODEGREE_INFO['ê³¼ì •ëª…'] == clean_major]
        
        # 3ì°¨: ë¶€ë¶„ ë§¤ì¹­
        if contact_row.empty:
            keyword = clean_major.replace('ì „ê³µ', '').replace('ê³¼ì •', '').replace('ì „ë¬¸ê°€', '')
            if keyword:
                contact_row = MICRODEGREE_INFO[
                    MICRODEGREE_INFO['ê³¼ì •ëª…'].str.contains(keyword, na=False, regex=False)
                ]
        
        # ë§ˆì´í¬ë¡œë””ê·¸ë¦¬ ì •ë³´ í‘œì‹œ
        if not contact_row.empty:
            row = contact_row.iloc[0]
            
            course_name = row.get('ê³¼ì •ëª…', major)
            edu_major = row.get('êµìœ¡ìš´ì˜ì „ê³µ', '')
            phone = row.get('ì—°ë½ì²˜', '')
            location = row.get('ìœ„ì¹˜', row.get('ì‚¬ë¬´ì‹¤ìœ„ì¹˜', ''))
            
            contact_parts = [f"ğŸ“ **ê³¼ì •ëª…**: {course_name}"]
            
            if pd.notna(edu_major) and str(edu_major).strip():
                contact_parts.append(f"ğŸ›ï¸ **êµìœ¡ìš´ì˜ì „ê³µ**: {edu_major}")
            
            if pd.notna(phone) and str(phone).strip():
                contact_parts.append(f"ğŸ“ **ì—°ë½ì²˜**: {phone}")
            
            if pd.notna(location) and str(location).strip():
                contact_parts.append(f"ğŸ“ **ì‚¬ë¬´ì‹¤ ìœ„ì¹˜**: {location}")
            
            st.info(f"**ğŸ“‹ ì†Œë‹¨ìœ„ì „ê³µê³¼ì • ë¬¸ì˜ì²˜**\n\n" + "\n\n".join(contact_parts))
            return
    
    # ì¼ë°˜ ì „ê³µì¸ ê²½ìš° MAJORS_INFOì—ì„œ ì°¾ê¸°
    if MAJORS_INFO.empty:
        st.info(f"ğŸ“ **ë¬¸ì˜**: í•™ì‚¬ì§€ì›íŒ€ 031-670-5035")
        return
    
    edu_major = None
    clean_major = major
    if major.endswith(')') and '(' in major:
        last_open_paren = major.rfind('(')
        if last_open_paren > 0:
            edu_major = major[last_open_paren+1:-1].strip()
            clean_major = major[:last_open_paren].strip()
    
    clean_major = clean_major.replace(' MD', '').replace('MD', '').strip()
    
    contact_row = pd.DataFrame()
    if edu_major:
        contact_row = MAJORS_INFO[MAJORS_INFO['ì „ê³µëª…'] == edu_major]

    if contact_row.empty:
        contact_row = MAJORS_INFO[MAJORS_INFO['ì „ê³µëª…'] == clean_major]
    
    if contact_row.empty:
        keyword = clean_major.replace('ì „ê³µ', '').replace('ê³¼ì •', '').replace('(', '').replace(')', '')[:4]
        if keyword:
            contact_row = MAJORS_INFO[MAJORS_INFO['ì „ê³µëª…'].str.contains(keyword, na=False, regex=False)]
    
    if not contact_row.empty:
        row = contact_row.iloc[0]
        major_name = row.get('ì „ê³µëª…', major)
        phone = row.get('ì—°ë½ì²˜', '')
        location = row.get('ì‚¬ë¬´ì‹¤ìœ„ì¹˜', row.get('ìœ„ì¹˜', ''))
        
        contact_title = f"{program_type} ë¬¸ì˜ì²˜"
        
        contact_parts = [f"ğŸ“ **ì „ê³µëª…**: {major_name}"]
        if pd.notna(phone) and str(phone).strip():
            contact_parts.append(f"ğŸ“ **ì—°ë½ì²˜**: {phone}")
        if pd.notna(location) and str(location).strip():
            contact_parts.append(f"ğŸ“ **ì‚¬ë¬´ì‹¤ ìœ„ì¹˜**: {location}")
        
        st.info(f"**ğŸ“‹ {contact_title}**\n\n" + "\n\n".join(contact_parts))
    else:
        st.info(f"ğŸ“ **ë¬¸ì˜**: í•™ì‚¬ì§€ì›íŒ€ 031-670-5035")


def render_question_buttons(questions, key_prefix, cols=5):
    btn_cols = st.columns(cols)
    for i, q in enumerate(questions):
        if btn_cols[i % cols].button(q, key=f"{key_prefix}_{i}", use_container_width=True):
            st.session_state.chat_history.append({"role": "user", "content": q})
            response_text, res_type = generate_ai_response(q, st.session_state.chat_history[:-1], ALL_DATA)
            st.session_state.chat_history.append({"role": "assistant", "content": response_text, "response_type": res_type})
            st.rerun()


# ============================================================
# ğŸ–¥ï¸ ë©”ì¸ UI
# ============================================================

def main():
    initialize_session_state()
    
    # ì‚¬ì´ë“œë°”
    with st.sidebar:
        st.markdown("""
        <div style='text-align: center; padding: 10px 0;'>
            <h1 style='font-size: 3rem; margin-bottom: 0;'>ğŸ“</h1>
            <h3 style='margin-top: 0;'>HKNU ë‹¤ì „ê³µ</h3>
        </div>
        """, unsafe_allow_html=True)
        
        menu = option_menu(
            menu_title=None,
            options=["AIì±—ë´‡ ìƒë‹´", "ë‹¤ì „ê³µ ì œë„ ì•ˆë‚´", "ë‹¤ì „ê³µ ë¹„êµ ë¶„ì„"], 
            icons=["chat-dots-fill", "journal-bookmark-fill", "calculator-fill"],
            default_index=0,
            styles={
                "container": {"padding": "0!important", "background-color": "#fafafa"},
                "icon": {"color": "orange", "font-size": "18px"}, 
                "nav-link": {"font-size": "15px", "text-align": "left", "margin":"0px"},
                "nav-link-selected": {"background-color": "#0091FF"},
            }
        )
        
        st.divider()
        
        # AIì±—ë´‡ ì†Œê°œ
        st.markdown("""
        <div style="background-color: #f8f9fa; border-left: 4px solid #667eea; 
                    padding: 15px; border-radius: 8px; margin-bottom: 10px;">
            <h4 style="color: #333; margin: 0 0 10px 0; font-size: 0.95rem; font-weight: 600;">
                ğŸ¤– ì±—ë´‡ ì†Œê°œ
            </h4>
            <p style="color: #555; font-size: 0.82rem; margin: 0 0 8px 0; line-height: 1.6;">
                í•œê²½êµ­ë¦½ëŒ€ ë‹¤ì „ê³µ ì œë„ì— ê´€í•œ<br>
                ê¶ê¸ˆí•œ ì‚¬í•­ì„ AIê¸°ë°˜ ì±—ë´‡ì´<br>
                ì¹œì ˆí•˜ê²Œ ë‹µë³€í•´ë“œë¦½ë‹ˆë‹¤!
            </p>
            <p style="color: #999; font-size: 0.7rem; margin: 0; font-style: italic;">
                âš ï¸ ë³¸ ì±—ë´‡ì€ ë‹¨ìˆœ ì°¸ê³ ìš©ì…ë‹ˆë‹¤.
            </p>
        </div>
        """, unsafe_allow_html=True)
        
        # ë‹¤ì „ê³µ ì œë„ ì†Œê°œ
        st.markdown("""
        <div style="background-color: #f0f8f5; border-left: 4px solid #11998e; 
                    padding: 15px; border-radius: 8px; margin-bottom: 10px;">
            <h4 style="color: #333; margin: 0 0 10px 0; font-size: 0.95rem; font-weight: 600;">
                ğŸ“š ë‹¤ì „ê³µ ì œë„ë€?
            </h4>
            <p style="color: #555; font-size: 0.82rem; margin: 0; line-height: 1.6;">
                ì£¼ì „ê³µ ì™¸ì— ë³µìˆ˜, ìœµí•©ì „ê³µ ë“±<br>
                ë‹¤ì–‘í•œ í•™ìœ„ë¥¼ ì·¨ë“í•˜ì—¬<br>
                ìœµí•©í˜• ì¸ì¬ë¡œ ì„±ì¥í•  ìˆ˜ ìˆë„ë¡<br>
                ì§€ì›í•˜ëŠ” ìœ ì—°í•™ì‚¬ì œë„ì…ë‹ˆë‹¤.
            </p>
        </div>
        """, unsafe_allow_html=True)
        
        # í•™ì‚¬ì§€ì›íŒ€ ì—°ë½ì²˜
        st.markdown("""
        <div style="background-color: #fff3e0; border-left: 4px solid #ff9800; 
                    padding: 12px; border-radius: 8px; margin-bottom: 12px;">
            <p style="color: #333; font-size: 0.8rem; margin: 0; line-height: 1.5;">
                ğŸ“ <strong>í•™ì‚¬ì§€ì›íŒ€</strong><br>
                <span style="color: #555; font-size: 0.75rem;">031-670-5035</span>
            </p>
        </div>
        """, unsafe_allow_html=True)
        
        # Powered by ì •ë³´
        st.markdown("""
        <div style="text-align: left; padding: 8px 0;">
            <p style="color: #999; font-size: 0.7rem; margin: 0 0 4px 0;">
                âš¡ Powered by <strong>Gemini 2.0</strong>
            </p>
        """, unsafe_allow_html=True)
        
        if SEMANTIC_ROUTER is not None:
            st.markdown("""
            <p style="color: #aaa; font-size: 0.65rem; margin: 0;">
                ğŸ§  Semantic Router í™œì„±í™”
            </p>
            """, unsafe_allow_html=True)
        
        st.markdown("</div>", unsafe_allow_html=True)
    
    # ë©”ì¸ ì½˜í…ì¸ 
    if menu == "AIì±—ë´‡ ìƒë‹´":
        st.subheader("ğŸ’¬ ì±—ë´‡ê³¼ ëŒ€í™”í•˜ê¸°")

        with st.expander("ğŸ’¡ ì–´ë–¤ ì§ˆë¬¸ì„ í•´ì•¼ í• ì§€ ëª¨ë¥´ê² ë‚˜ìš”? **(í´ë¦­)**", expanded=False):

            # ì§ˆë¬¸ ë²„íŠ¼ íƒ­
            tab_apply, tab_program, tab_credit, tab_etc = st.tabs(
                ["ğŸ“‹ ì‹ ì²­", "ğŸ“š ì œë„", "ğŸ“ í•™ì ", "ğŸ¯ ì „ê³µ/ ğŸ“ ì—°ë½ì²˜"]
            )
            
            with tab_apply:
                q_apply = [
                    "ë‹¤ì „ê³µ ì‹ ì²­ìê²©ì€?",
                    "ë³µìˆ˜ì „ê³µ ì‹ ì²­ ê¸°ê°„ì€?",
                    "ìœµí•©ì „ê³µ ì‹ ì²­ ë°©ë²•ì€ ë­ì•¼?",
                    "ë‹¤ì „ê³µì„ ë³€ê²½í•˜ë ¤ë©´?",
                ]
                render_question_buttons(q_apply, "qa", cols=2)

            with tab_program:
                q_program = [
                    "ë‹¤ì „ê³µ ì œë„ê°€ ë­ì•¼?",
                    "ë³µìˆ˜ì „ê³µì€ ë­ì•¼?",
                    "ë§ˆì´í¬ë¡œë””ê·¸ë¦¬ëŠ” ì–´ë–¤ ê³¼ì •ì´ ìˆì–´?",
                    "ë³µìˆ˜Â·ë¶€ì „ê³µ ì°¨ì´ëŠ” ë­ì•¼?",
                ]
                render_question_buttons(q_program, "qp", cols=2)

            with tab_credit:
                q_credit = [
                    "ë‹¤ì „ê³µë³„ ì´ìˆ˜í•™ì ì€?",
                    "ë³µìˆ˜ì „ê³µ ì´ìˆ˜í•™ì  ì•Œë ¤ì¤˜",
                    "ìœµí•©ì „ê³µì˜ ì¡¸ì—…í•™ì ì€?",
                    "ë§ˆì´í¬ë¡œë””ê·¸ë¦¬ ê³¼ì •ì˜ ì´ìˆ˜í•™ì ì€?",
                ]
                render_question_buttons(q_credit, "qc", cols=2)

            with tab_etc:
                q_etc = [
                    "ê²½ì˜í•™ì „ê³µ ì—°ë½ì²˜ ì•Œë ¤ì¤˜",
                    "ì‘ìš©ìˆ˜í•™ì „ê³µ ì‚¬ë¬´ì‹¤ì€ ì–´ë””ì•¼?",
                    "ê¸°ê³„ê³µí•™ì „ê³µ êµê³¼ëª©ì€?",
                    "AIë¹…ë°ì´í„°ìœµí•©ì „ê³µ êµê³¼ëª© ì•Œë ¤ì¤˜",
                ]
                render_question_buttons(q_etc, "qe", cols=2)

            st.divider()
        
        # ì±„íŒ… íˆìŠ¤í† ë¦¬ í‘œì‹œ
        for chat in st.session_state.chat_history:
            avatar = "ğŸ§‘â€ğŸ“" if chat["role"] == "user" else "ğŸ¤–"
            with st.chat_message(chat["role"], avatar=avatar):
                st.markdown(chat["content"], unsafe_allow_html=True)
        
        # ì±„íŒ… ì…ë ¥
        if prompt := st.chat_input("ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”..."):
            st.session_state.chat_history.append({"role": "user", "content": prompt})
            with st.chat_message("user", avatar="ğŸ§‘â€ğŸ“"):
                st.markdown(prompt)
            
            with st.chat_message("assistant", avatar="ğŸ¤–"):
                with st.spinner("AIê°€ ë‹µë³€ì„ ìƒì„± ì¤‘ì…ë‹ˆë‹¤..."):
                    response_text, res_type = generate_ai_response(prompt, st.session_state.chat_history[:-1], ALL_DATA)
                    st.markdown(response_text, unsafe_allow_html=True)
            
            st.session_state.chat_history.append({"role": "assistant", "content": response_text, "response_type": res_type})
            scroll_to_bottom()
    
    elif menu == "ë‹¤ì „ê³µ ì œë„ ì•ˆë‚´":
        st.markdown("""
        <h1 style="font-size: 2rem; margin-bottom: 20px; color: #1f2937;">
            ğŸ“Š ì œë„ í•œëˆˆì— ë¹„êµ
        </h1>
        """, unsafe_allow_html=True)
        
        # ì œë„ ë¹„êµ ì¹´ë“œ
        if 'programs' in ALL_DATA and ALL_DATA['programs']:
            cols = st.columns(3)
            for idx, (program, info) in enumerate(ALL_DATA['programs'].items()):
                with cols[idx % 3]:
                    desc = info.get('description', '')[:50] + '...' if len(info.get('description', '')) > 50 else info.get('description', '-')
                    qual = info.get('qualification', '-')[:30] + '...' if len(str(info.get('qualification', '-'))) > 30 else info.get('qualification', '-')
                    
                    html = f"""<div style="border: 1px solid #e5e7eb; border-radius: 12px; padding: 14px; background: white; box-shadow: 0 2px 4px rgba(0,0,0,0.05); min-height: 400px; margin-bottom: 12px;"><h3 style="margin: 0 0 8px 0; color: #1f2937; font-size: 1rem;">ğŸ“ {program}</h3><p style="color: #6b7280; font-size: 11px; margin-bottom: 10px; line-height: 1.4;">{desc}</p><hr style="margin: 8px 0; border-top: 1px solid #e5e7eb;"><div style="font-size: 12px; margin-bottom: 8px;"><strong>ğŸ“– ì´ìˆ˜í•™ì </strong><br><span style="font-size: 11px; line-height: 1.6;">â€¢ ë³¸ì „ê³µ: {info.get('credits_primary', '-')}<br>â€¢ ë‹¤ì „ê³µ: {info.get('credits_multi', '-')}</span></div><div style="font-size: 12px; margin-bottom: 6px;"><strong>âœ… ì‹ ì²­ìê²©</strong><br><span style="font-size: 11px; color: #4b5563;">{qual}</span></div><div style="font-size: 12px; margin-bottom: 6px;"><strong>ğŸ“ ì¡¸ì—…ìš”ê±´</strong><br><span style="font-size: 11px;">ì¡¸ì—…ì¸ì¦: {info.get('graduation_certification', '-')}<br>ì¡¸ì—…ì‹œí—˜: {info.get('graduation_exam', '-')}</span></div><div style="font-size: 12px; margin-bottom: 6px;"><strong>ğŸ“œ í•™ìœ„í‘œê¸°</strong><br><span style="font-size: 11px; color: #2563eb;">{str(info.get('degree', '-'))[:30]}</span></div><div style="text-align: right; margin-top: 10px;"><span style="font-size: 11px;">ë‚œì´ë„: </span><span style="color: #f59e0b;">{info.get('difficulty', 'â­â­â­')}</span></div></div>"""
                    st.markdown(html, unsafe_allow_html=True)
        
        st.divider()
        st.subheader("ğŸ” ìƒì„¸ ì •ë³´ ì¡°íšŒ")
        
        prog_keys = list(ALL_DATA['programs'].keys()) if 'programs' in ALL_DATA else []
        selected_program = st.selectbox("ì œë„ ì„ íƒ", prog_keys)
        
        if selected_program:
            info = ALL_DATA['programs'][selected_program]
            
            tab1, tab2 = st.tabs(["ğŸ“ ê¸°ë³¸ ì •ë³´", "âœ… íŠ¹ì§•"])
            with tab1:
                col1, col2 = st.columns([2, 1])
                with col1:
                    st.info(f"**ê°œìš”**\n\n{info.get('description', '-')}")
                    
                    credits_text = f"""**ì´ìˆ˜í•™ì **
- êµì–‘: {info.get('credits_general', '-')}
- ì›ì „ê³µ: {info.get('credits_primary', '-')}
- ë‹¤ì „ê³µ: {info.get('credits_multi', '-')}"""
                    st.markdown(credits_text)
                    
                    graduation_text = f"""**ì¡¸ì—…ìš”ê±´**
- ì¡¸ì—…ì¸ì¦: {info.get('graduation_certification', '-')}
- ì¡¸ì—…ì‹œí—˜: {info.get('graduation_exam', '-')}"""
                    st.markdown(graduation_text)
                with col2:
                    st.success(f"**ì‹ ì²­ìê²©**\n\n{info.get('qualification', '-')}")
                    st.write(f"**í•™ìœ„í‘œê¸°**: {info.get('degree', '-')}")
            with tab2:
                for f in info.get('features', []):
                    st.write(f"âœ”ï¸ {f}")
                if info.get('notes'):
                    st.warning(f"ğŸ’¡ {info['notes']}")
            
            st.divider()
            
            # ì „ê³µ ëª©ë¡
            available_majors = {}
            
            def match_program_type(type_value, selected_prog):
                type_str = str(type_value).strip()
                if "ì†Œë‹¨ìœ„" in selected_prog or "ë§ˆì´í¬ë¡œ" in selected_prog:
                    return any(kw in type_str.lower() for kw in ['ì†Œë‹¨ìœ„', 'ë§ˆì´í¬ë¡œ', 'md'])
                if selected_prog == "ë¶€ì „ê³µ":
                    return "ë¶€ì „ê³µ" in type_str and "ìœµí•©ë¶€ì „ê³µ" not in type_str
                if selected_prog == "ìœµí•©ì „ê³µ":
                    return "ìœµí•©ì „ê³µ" in type_str
                return selected_prog in type_str
            
            if not COURSES_DATA.empty and 'ì œë„ìœ í˜•' in COURSES_DATA.columns:
                mask = COURSES_DATA['ì œë„ìœ í˜•'].apply(lambda x: match_program_type(x, selected_program))
                for major in COURSES_DATA[mask]['ì „ê³µëª…'].unique():
                    available_majors[major] = None
            
            if not MAJORS_INFO.empty and 'ì œë„ìœ í˜•' in MAJORS_INFO.columns:
                mask = MAJORS_INFO['ì œë„ìœ í˜•'].apply(lambda x: match_program_type(x, selected_program))
                for _, row in MAJORS_INFO[mask].iterrows():
                    if selected_program == "ìœµí•©ë¶€ì „ê³µ":
                        continue
                    major_name = row['ì „ê³µëª…']
                    edu_major = row.get('êµìœ¡ìš´ì˜ì „ê³µ')
                    if pd.notna(edu_major) and str(edu_major).strip():
                        available_majors[major_name] = str(edu_major).strip()
                    elif major_name not in available_majors:
                        available_majors[major_name] = None
            
            if available_majors:
                target_programs = ["ë³µìˆ˜ì „ê³µ", "ë¶€ì „ê³µ", "ìœµí•©ì „ê³µ", "ìœµí•©ë¶€ì „ê³µ", "ì—°ê³„ì „ê³µ"]
    
                # ğŸ”¥ êµ¬ë¶„ ëª…í™•íˆ
                is_microdegree = any(sp in selected_program for sp in ["ì†Œë‹¨ìœ„", "ë§ˆì´í¬ë¡œ"])
                is_linked = "ì—°ê³„ì „ê³µ" in selected_program
                is_convergence = any(sp in selected_program for sp in ["ìœµí•©ì „ê³µ", "ìœµí•©ë¶€ì „ê³µ"])
    
                # [ìˆ˜ì •] ì¹´í…Œê³ ë¦¬ ì„¤ì • ë¡œì§ ë³€ê²½
                category_majors = {}

                if is_microdegree or is_convergence:
                    # ìœµí•©ì „ê³µ, ë§ˆì´í¬ë¡œëŠ” 'ì „ì²´' í•˜ë‚˜ë¡œ í†µì¼
                    category_majors = {"ì „ì²´": sorted(available_majors.keys())}
                elif is_linked:
                    # ğŸ”¥ [í•µì‹¬ ìˆ˜ì •] ì—°ê³„ì „ê³µì„ 'ê³„ì—´' ë³„ë¡œ ë¶„ë¥˜í•˜ëŠ” ë¡œì§ ì¶”ê°€
                    target_col = 'ê³„ì—´' if 'ê³„ì—´' in MAJORS_INFO.columns else ('ë‹¨ê³¼ëŒ€í•™' if 'ë‹¨ê³¼ëŒ€í•™' in MAJORS_INFO.columns else None)
                
                    if target_col:
                        for major_name in available_majors.keys():
                            # MAJORS_INFOì—ì„œ í•´ë‹¹ ì „ê³µì˜ í–‰ì„ ì°¾ìŒ
                            major_row = MAJORS_INFO[MAJORS_INFO['ì „ê³µëª…'] == major_name]
                        
                            if not major_row.empty:
                                # í•´ë‹¹ ì „ê³µì˜ ê³„ì—´ ì •ë³´ë¥¼ ê°€ì ¸ì˜´ (ì—¬ëŸ¬ ê°œì¼ ê²½ìš° ì²« ë²ˆì§¸ ê²ƒ ì‚¬ìš©)
                                cat_val = major_row.iloc[0].get(target_col)
                                category = str(cat_val).strip() if pd.notna(cat_val) else "ê¸°íƒ€"
                            else:
                                category = "ê¸°íƒ€"
                        
                            if category not in category_majors:
                                category_majors[category] = []
                            category_majors[category].append(major_name)
                    
                        # ë”•ì…”ë„ˆë¦¬ í‚¤ ì •ë ¬ (ê°€ë‚˜ë‹¤ìˆœ)
                        category_majors = dict(sorted(category_majors.items()))
                    else:
                        # ê³„ì—´ ì»¬ëŸ¼ì„ ëª» ì°¾ìœ¼ë©´ ì „ì²´ë¡œ í‘œì‹œ
                        category_majors = {"ì „ì²´": sorted(available_majors.keys())}
                else:
                    category_majors = get_majors_by_category(selected_program)
    
                if selected_program in target_programs:
                    # ğŸ”¥ 1. ì—°ê³„ì „ê³µ: ë‹¨ì¼ ì»¬ëŸ¼ë§Œ
                    if is_linked:
                        major_options_with_dividers = ["ì„ íƒ ì•ˆ í•¨"]

                        for category in sorted(category_majors.keys()):
                            divider = f"â”â”â”â”â”â” {category} â”â”â”â”â”â”"
                            major_options_with_dividers.append(divider)
                            for major in sorted(category_majors[category]):
                                major_options_with_dividers.append(major)

                        selected_major = st.selectbox(
                        f"ğŸ“ ì´ìˆ˜í•˜ë ¤ëŠ” {selected_program}",
                        major_options_with_dividers
                        )

                        # [ìˆ˜ì • 3] êµ¬ë¶„ì„  ì„ íƒ ì‹œ ê²½ê³  ë° null ì²˜ë¦¬
                        if selected_major and "â”â”â”" in selected_major:
                            st.warning("âš ï¸ ê³„ì—´ êµ¬ë¶„ì„ ì´ ì•„ë‹Œ êµ¬ì²´ì ì¸ ì „ê³µëª…ì„ ì„ íƒí•´ì£¼ì„¸ìš”.")
                            selected_major = None
                            
                        my_primary = "ì„ íƒ ì•ˆ í•¨"
                        admission_year = datetime.now().year
        
                    # ğŸ”¥ 2. ìœµí•©ì „ê³µ: ì „ê³µ + ë³¸ì „ê³µ + í•™ë²ˆ
                    elif is_convergence or len(category_majors) <= 1:
                        col_m1, col_m2, col_m3 = st.columns([3, 3, 1.5])
                        with col_m1:
                            all_majors = []
                            for majors in category_majors.values():
                                all_majors.extend(majors)
                            selected_major = st.selectbox(f"ì´ìˆ˜í•˜ë ¤ëŠ” {selected_program}", sorted(set(all_majors)))
                        with col_m2:
                            primary_categories = get_majors_by_category("ë³µìˆ˜ì „ê³µ")
                            if len(primary_categories) > 1:
                                primary_options_with_dividers = ["ì„ íƒ ì•ˆ í•¨"]
                                for category in sorted(primary_categories.keys()):
                                    divider = f"â”â”â”â”â”â” {category} â”â”â”â”â”â”"
                                    primary_options_with_dividers.append(divider)
                                    for major in sorted(primary_categories[category]):
                                        primary_options_with_dividers.append(major)
                                my_primary = st.selectbox(
                                    "ë‚˜ì˜ ë³¸ì „ê³µ",
                                    primary_options_with_dividers,
                                    key=f"special_primary_{selected_program}"
                                )
                                if my_primary and "â”â”â”" in my_primary:
                                    st.warning("âš ï¸ ê³„ì—´ êµ¬ë¶„ì„ ì´ ì•„ë‹Œ êµ¬ì²´ì ì¸ ì „ê³µëª…ì„ ì„ íƒí•´ì£¼ì„¸ìš”.")
                                    my_primary = "ì„ íƒ ì•ˆ í•¨"
                            else:
                                primary_list = []
                                if not PRIMARY_REQ.empty:
                                    primary_list = sorted(PRIMARY_REQ['ì „ê³µëª…'].unique().tolist())
                                my_primary = st.selectbox("ë‚˜ì˜ ë³¸ì „ê³µ", ["ì„ íƒ ì•ˆ í•¨"] + primary_list)
                        with col_m3:
                            admission_year = st.number_input(
                                "ğŸ“… ë³¸ì¸ í•™ë²ˆ",
                                min_value=2020,
                                max_value=datetime.now().year,
                                value=datetime.now().year,
                                key=f"special_admission_year_{selected_program}"
                            )
        
                    # ğŸ”¥ 3. ë³µìˆ˜ì „ê³µ/ë¶€ì „ê³µ: ì¼ë°˜ ì²˜ë¦¬ (ê¸°ì¡´ ì½”ë“œ)
                    else:
                        major_options_with_dividers = ["ì„ íƒ ì•ˆ í•¨"]
                        major_to_category = {}
            
                        for category in sorted(category_majors.keys()):
                            divider = f"â”â”â”â”â”â” {category} â”â”â”â”â”â”"
                            major_options_with_dividers.append(divider)
                            for major in sorted(category_majors[category]):
                                major_options_with_dividers.append(major)
                                major_to_category[major] = category
            
                        primary_categories = get_majors_by_category("ë³µìˆ˜ì „ê³µ")
                        primary_options_with_dividers = ["ì„ íƒ ì•ˆ í•¨"]
            
                        for category in sorted(primary_categories.keys()):
                            divider = f"â”â”â”â”â”â” {category} â”â”â”â”â”â”"
                            primary_options_with_dividers.append(divider)
                            for major in sorted(primary_categories[category]):
                                primary_options_with_dividers.append(major)
            
                        col1, col2, col3 = st.columns([3, 3, 1.5])
            
                        with col1:
                            selected_major = st.selectbox(
                                f"ğŸ“ ì´ìˆ˜í•˜ë ¤ëŠ” {selected_program}",
                                major_options_with_dividers,
                                key=f"major_select_{selected_program}"
                            )
            
                        with col2:
                            my_primary = st.selectbox(
                                "ğŸ  ë‚˜ì˜ ë³¸ì „ê³µ",
                                primary_options_with_dividers,
                                key=f"primary_select_{selected_program}"
                            )
            
                        with col3:
                            admission_year = st.number_input(
                                "ğŸ“… ë³¸ì¸ í•™ë²ˆ",
                                min_value=2020,
                                max_value=datetime.now().year,
                                value=datetime.now().year,
                                key=f"admission_year_{selected_program}"
                            )
            
                        if selected_major and "â”â”â”" in selected_major:
                            st.warning("âš ï¸ ê³„ì—´ êµ¬ë¶„ì„ ì´ ì•„ë‹Œ êµ¬ì²´ì ì¸ ì „ê³µëª…ì„ ì„ íƒí•´ì£¼ì„¸ìš”.")
                            selected_major = None
            
                        if my_primary and "â”â”â”" in my_primary:
                            st.warning("âš ï¸ ê³„ì—´ êµ¬ë¶„ì„ ì´ ì•„ë‹Œ êµ¬ì²´ì ì¸ ì „ê³µëª…ì„ ì„ íƒí•´ì£¼ì„¸ìš”.")
                            my_primary = "ì„ íƒ ì•ˆ í•¨"
        
                else:
                    # ğŸ”¥ ì†Œë‹¨ìœ„ì „ê³µê³¼ì •(ë§ˆì´í¬ë¡œë””ê·¸ë¦¬) - MICRODEGREE_INFO ì‚¬ìš©
                    field_majors = {}
                    major_to_edu_major = {}
                    
                    if not MICRODEGREE_INFO.empty and 'ê³¼ì •ëª…' in MICRODEGREE_INFO.columns:
                        group_column = 'ê³„ì—´' if 'ê³„ì—´' in MICRODEGREE_INFO.columns else None
                        
                        for _, row in MICRODEGREE_INFO.iterrows():
                            if group_column:
                                field = row.get(group_column, 'ê¸°íƒ€')
                                if pd.isna(field) or str(field).strip() == '':
                                    field = 'ê¸°íƒ€'
                                field = str(field).strip()
                            else:
                                field = 'ì „ì²´'
                            
                            course_name = row.get('ê³¼ì •ëª…', '')
                            edu_major = row.get('êµìœ¡ìš´ì˜ì „ê³µ', '')
                            
                            if pd.notna(edu_major) and str(edu_major).strip():
                                display_name = f"{course_name}({str(edu_major).strip()})"
                                major_to_edu_major[display_name] = str(edu_major).strip()
                            else:
                                display_name = course_name
                                major_to_edu_major[display_name] = course_name
                            
                            if field not in field_majors:
                                field_majors[field] = []
                            if display_name not in field_majors[field]:
                                field_majors[field].append(display_name)
                    
                    if field_majors and len(field_majors) > 1:
                        major_options_with_dividers = ["ì„ íƒ ì•ˆ í•¨"]
                        
                        for field in sorted(field_majors.keys()):
                            divider = f"â”â”â”â”â”â” {field} â”â”â”â”â”â”"
                            major_options_with_dividers.append(divider)
                            for major in sorted(field_majors[field]):
                                major_options_with_dividers.append(major)
                        
                        selected_major = st.selectbox(
                            f"ğŸ“ ì´ìˆ˜í•˜ë ¤ëŠ” {selected_program}",
                            major_options_with_dividers,
                            key=f"micro_major_{selected_program}"
                        )
                        
                        if selected_major and "â”â”â”" in selected_major:
                            st.warning("âš ï¸ ë¶„ì•¼ êµ¬ë¶„ì„ ì´ ì•„ë‹Œ êµ¬ì²´ì ì¸ ì „ê³µëª…ì„ ì„ íƒí•´ì£¼ì„¸ìš”.")
                            selected_major = None
                    elif field_majors:
                        all_majors = []
                        for majors in field_majors.values():
                            all_majors.extend(majors)
                        
                        selected_major = st.selectbox(
                            f"ğŸ“ ì´ìˆ˜í•˜ë ¤ëŠ” {selected_program}",
                            ["ì„ íƒ ì•ˆ í•¨"] + sorted(all_majors),
                            key=f"micro_major_{selected_program}"
                        )
                    else:
                        if category_majors and category_majors.get("ì „ì²´"):
                            all_majors = category_majors["ì „ì²´"]
                        else:
                            all_majors = sorted(available_majors.keys())
                        
                        if all_majors:
                            selected_major = st.selectbox(
                                f"ğŸ“ ì´ìˆ˜í•˜ë ¤ëŠ” {selected_program}",
                                all_majors,
                                key=f"micro_major_{selected_program}"
                            )
                        else:
                            st.warning(f"âš ï¸ {selected_program}ì— í•´ë‹¹í•˜ëŠ” ì „ê³µì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                            selected_major = None
                    
                    my_primary = "ì„ íƒ ì•ˆ í•¨"
                    admission_year = datetime.now().year
                
                if selected_major:
                    if selected_program in target_programs and "ì—°ê³„ì „ê³µ" not in selected_program:
                        col_l, col_r = st.columns(2)
                        with col_l:
                            st.subheader(f"ğŸ¯ {selected_program} ì´ìˆ˜í•™ì ")
                            if not GRADUATION_REQ.empty:
                                req_data = GRADUATION_REQ[
                                    (GRADUATION_REQ['ì „ê³µëª…'] == selected_major) & 
                                    (GRADUATION_REQ['ì œë„ìœ í˜•'].str.contains(selected_program, na=False))
                                ].copy()
                                if not req_data.empty:
                                    req_data['ê¸°ì¤€í•™ë²ˆ'] = pd.to_numeric(req_data['ê¸°ì¤€í•™ë²ˆ'], errors='coerce')
                                    applicable = req_data[req_data['ê¸°ì¤€í•™ë²ˆ'] <= admission_year].sort_values('ê¸°ì¤€í•™ë²ˆ', ascending=False)
                                    if not applicable.empty:
                                        row = applicable.iloc[0]
                                        st.write(f"ì „ê³µí•„ìˆ˜: **{int(row.get('ë‹¤ì „ê³µ_ì „ê³µí•„ìˆ˜', 0))}**í•™ì ")
                                        st.write(f"ì „ê³µì„ íƒ: **{int(row.get('ë‹¤ì „ê³µ_ì „ê³µì„ íƒ', 0))}**í•™ì ")
                                        st.markdown(f"#### ğŸ‘‰ í•©ê³„ {int(row.get('ë‹¤ì „ê³µ_ê³„', 0))}í•™ì ")
                        
                        with col_r:
                            st.subheader(f"ğŸ  ë³¸ì „ê³µ ì´ìˆ˜í•™ì  ë³€í™”")
                            if my_primary != "ì„ íƒ ì•ˆ í•¨" and not PRIMARY_REQ.empty:
                                pri_data = PRIMARY_REQ[PRIMARY_REQ['ì „ê³µëª…'] == my_primary].copy()
                                if not pri_data.empty:
                                    pri_data['ê¸°ì¤€í•™ë²ˆ'] = pd.to_numeric(pri_data['ê¸°ì¤€í•™ë²ˆ'], errors='coerce')
                                    pri_valid = pri_data[pri_data['ê¸°ì¤€í•™ë²ˆ'] <= admission_year].sort_values('ê¸°ì¤€í•™ë²ˆ', ascending=False)
                                    
                                    found_req = False

                                    for _, p_row in pri_valid.iterrows():
                                        if selected_program in str(p_row['ì œë„ìœ í˜•']):
                                            # âœ… [ìˆ˜ì • í•µì‹¬] NaN(ë¹ˆê°’) ì²˜ë¦¬ë¥¼ ìœ„í•œ ì•ˆì „í•œ ë³€í™˜ ë¡œì§
                                            def safe_int(val):
                                                try:
                                                    # ê°’ì´ ì—†ê±°ë‚˜ NaNì´ë©´ 0 ë°˜í™˜
                                                    if pd.isna(val) or str(val).strip() == "":
                                                        return 0
                                                    # ì‹¤ìˆ˜í˜•(3.0)ë„ ì •ìˆ˜(3)ë¡œ ë³€í™˜
                                                    return int(float(val))
                                                except:
                                                    return 0

                                            p_req = safe_int(p_row.get('ë³¸ì „ê³µë³€í™”_ì „ê³µí•„ìˆ˜'))
                                            p_sel = safe_int(p_row.get('ë³¸ì „ê³µë³€í™”_ì „ê³µì„ íƒ'))
                                            p_total = safe_int(p_row.get('ë³¸ì „ê³µë³€í™”_ê³„'))

                                            st.write(f"ì „ê³µí•„ìˆ˜: **{p_req}**í•™ì ")
                                            st.write(f"ì „ê³µì„ íƒ: **{p_sel}**í•™ì ")
                                            st.markdown(f"#### ğŸ‘‰ í•©ê³„ {p_total}í•™ì ")
                                            found_req = True
                                            break
                                    
                                    if not found_req:
                                        st.info("í•´ë‹¹ í•™ë²ˆ/ê³¼ì •ì— ëŒ€í•œ ë³¸ì „ê³µ ìš”ê±´ ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤.")
                            else:
                                st.info("ë³¸ì „ê³µì„ ì„ íƒí•˜ë©´ ë³€ë™ í•™ì ì„ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
                    
                    st.divider()

                    if not MAJORS_INFO.empty and 'ì „ê³µì„¤ëª…' in MAJORS_INFO.columns:
                        # ì„ íƒëœ ì „ê³µì— í•´ë‹¹í•˜ëŠ” í–‰ ì°¾ê¸°
                        desc_row = MAJORS_INFO[MAJORS_INFO['ì „ê³µëª…'] == selected_major]
                        
                        if not desc_row.empty:
                            # ì „ê³µì„¤ëª… ê°’ ê°€ì ¸ì˜¤ê¸°
                            description = desc_row.iloc[0].get('ì „ê³µì„¤ëª…')
                            
                            # ë‚´ìš©ì´ ë¹„ì–´ìˆì§€ ì•Šë‹¤ë©´(NaNì´ë‚˜ ë¹ˆ ë¬¸ìì—´ì´ ì•„ë‹ˆë©´) ì¶œë ¥
                            if pd.notna(description) and str(description).strip():
                                st.markdown(f"### ğŸ“˜ ({selected_program}) {selected_major} ì „ê³µ ì†Œê°œ")
                                st.info(str(description).strip())

                    if selected_program == "ìœµí•©ì „ê³µ":
                        st.subheader("ğŸ“‹ ì´ìˆ˜ì²´ê³„ë„")
                        display_curriculum_image(selected_major, selected_program)
                        display_courses(selected_major, selected_program)
                    elif "ì†Œë‹¨ìœ„" in selected_program or "ë§ˆì´í¬ë¡œ" in selected_program:
                        st.subheader("ğŸ–¼ï¸ ê³¼ì • ì•ˆë‚´ ì´ë¯¸ì§€")
                        display_curriculum_image(selected_major, selected_program)
                        display_courses(selected_major, selected_program)
                    else:
                        display_courses(selected_major, selected_program)
            else:
                st.warning(f"âš ï¸ {selected_program}ì— í•´ë‹¹í•˜ëŠ” ì „ê³µ ëª©ë¡ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                st.info("ğŸ’¡ ë°ì´í„° íŒŒì¼ì— í•´ë‹¹ ì œë„ì˜ ì „ê³µ ì •ë³´ê°€ ìˆëŠ”ì§€ í™•ì¸í•´ì£¼ì„¸ìš”.")

    # ğŸ¯ ë‹¤ì „ê³µ ë¹„êµ ë¶„ì„
    elif menu == "ë‹¤ì „ê³µ ë¹„êµ ë¶„ì„":
        from simulation import render_simulation_page
        render_simulation_page()

if __name__ == "__main__":
    initialize_session_state()
    main()
